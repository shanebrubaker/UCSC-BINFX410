{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02 - Feature Engineering and Feature Store Setup\n",
    "\n",
    "This notebook demonstrates:\n",
    "- Loading and validating raw data\n",
    "- Setting up the feature store\n",
    "- Registering features\n",
    "- Computing and storing features\n",
    "- Exploring feature lineage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from feature_store import FeatureStore\n",
    "from data_validators import RawDataValidator\n",
    "from features import ClinicalFeatureEngineer, get_feature_lineage, get_feature_descriptions\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the synthetic data we generated\n",
    "raw_data = pd.read_csv('../data/raw/synthetic_patients.csv')\n",
    "\n",
    "print(f\"Loaded {len(raw_data)} patient records\")\n",
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Validate Raw Data\n",
    "\n",
    "Before ingesting into the feature store, we validate to catch data quality issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize validator\n",
    "validator = RawDataValidator()\n",
    "\n",
    "# Run validation\n",
    "validation_report = validator.validate(raw_data)\n",
    "\n",
    "# Print report\n",
    "validation_report.print_report()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The validation catches our intentional errors! Let's clean the data before proceeding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows with invalid data\n",
    "clean_data = raw_data[\n",
    "    (raw_data['age'] >= 0) & (raw_data['age'] <= 120) &\n",
    "    (raw_data['tmb_score'] <= 100) &\n",
    "    (raw_data['comorbidity_count'] <= 10)\n",
    "]\n",
    "\n",
    "print(f\"Removed {len(raw_data) - len(clean_data)} invalid records\")\n",
    "print(f\"Clean dataset: {len(clean_data)} patients\")\n",
    "\n",
    "# Re-validate\n",
    "clean_report = validator.validate(clean_data)\n",
    "clean_report.print_report()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Initialize Feature Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create feature store instance\n",
    "fs = FeatureStore(\n",
    "    db_path='../data/feature_store.duckdb',\n",
    "    config_dir='../config'\n",
    ")\n",
    "\n",
    "print(\"Feature store initialized!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Register Features\n",
    "\n",
    "Register features from our configuration file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register all features from config\n",
    "fs.register_features_from_config()\n",
    "\n",
    "# List registered features\n",
    "features_df = fs.list_features()\n",
    "print(f\"\\nRegistered {len(features_df)} features\")\n",
    "features_df[['feature_name', 'feature_type', 'category', 'version']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Ingest Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ingest clean data into feature store\n",
    "fs.ingest_raw_data(clean_data, validate=True, data_version=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Compute Features\n",
    "\n",
    "Apply feature engineering pipeline to create ML-ready features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute all features\n",
    "features = fs.compute_features(feature_version=1, validate=True)\n",
    "\n",
    "print(f\"\\nComputed features for {len(features)} patients\")\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Explore Computed Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize scaled features (should be mean~0, std~1)\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "axes[0].hist(features['age_scaled'], bins=30, edgecolor='black')\n",
    "axes[0].set_xlabel('Age (scaled)')\n",
    "axes[0].set_ylabel('Count')\n",
    "axes[0].set_title(f'Scaled Age: mean={features[\"age_scaled\"].mean():.3f}, std={features[\"age_scaled\"].std():.3f}')\n",
    "axes[0].axvline(0, color='red', linestyle='--', label='Mean=0')\n",
    "axes[0].legend()\n",
    "\n",
    "axes[1].hist(features['tmb_score_scaled'], bins=30, edgecolor='black')\n",
    "axes[1].set_xlabel('TMB Score (scaled)')\n",
    "axes[1].set_ylabel('Count')\n",
    "axes[1].set_title(f'Scaled TMB: mean={features[\"tmb_score_scaled\"].mean():.3f}, std={features[\"tmb_score_scaled\"].std():.3f}')\n",
    "axes[1].axvline(0, color='red', linestyle='--', label='Mean=0')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize derived features\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
    "\n",
    "# Mutation burden\n",
    "mutation_counts = features['mutation_burden'].value_counts().sort_index()\n",
    "axes[0].bar(mutation_counts.index, mutation_counts.values)\n",
    "axes[0].set_xlabel('Number of Mutations')\n",
    "axes[0].set_ylabel('Count')\n",
    "axes[0].set_title('Mutation Burden Distribution')\n",
    "axes[0].set_xticks([0, 1, 2, 3])\n",
    "\n",
    "# Clinical risk score\n",
    "axes[1].hist(features['clinical_risk_score'], bins=30, edgecolor='black')\n",
    "axes[1].set_xlabel('Clinical Risk Score')\n",
    "axes[1].set_ylabel('Count')\n",
    "axes[1].set_title('Clinical Risk Score Distribution')\n",
    "axes[1].axvline(20, color='red', linestyle='--', label='High risk threshold')\n",
    "axes[1].legend()\n",
    "\n",
    "# Age groups\n",
    "age_group_counts = features['age_group'].value_counts()\n",
    "axes[2].bar(age_group_counts.index, age_group_counts.values)\n",
    "axes[2].set_xlabel('Age Group')\n",
    "axes[2].set_ylabel('Count')\n",
    "axes[2].set_title('Age Group Distribution')\n",
    "axes[2].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nHigh-risk patients: {(features['high_risk_patient']==1).sum()} ({(features['high_risk_patient']==1).mean()*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Feature Lineage\n",
    "\n",
    "Understand which raw columns created which features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature lineage\n",
    "lineage = get_feature_lineage()\n",
    "descriptions = get_feature_descriptions()\n",
    "\n",
    "print(\"Feature Lineage:\\n\")\n",
    "for feature_name, source_cols in lineage.items():\n",
    "    print(f\"{feature_name}:\")\n",
    "    print(f\"  Sources: {', '.join(source_cols)}\")\n",
    "    print(f\"  Description: {descriptions[feature_name]}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Retrieve Features from Store\n",
    "\n",
    "Show how to retrieve features for specific patients or feature sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get features for specific patients\n",
    "patient_ids = clean_data['patient_id'].head(10).tolist()\n",
    "patient_features = fs.get_features(patient_ids=patient_ids, feature_version=1)\n",
    "\n",
    "print(f\"Retrieved features for {len(patient_features)} patients\")\n",
    "patient_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get specific features for all patients\n",
    "specific_features = fs.get_features(\n",
    "    feature_list=['mutation_burden', 'clinical_risk_score', 'high_risk_patient'],\n",
    "    feature_version=1\n",
    ")\n",
    "\n",
    "print(f\"Retrieved {len(specific_features)} rows with selected features\")\n",
    "specific_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Data Quality History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data quality history\n",
    "quality_history = fs.get_data_quality_history(limit=10)\n",
    "\n",
    "print(\"Recent data quality checks:\")\n",
    "quality_history[['check_timestamp', 'check_type', 'passed', 'error_count', 'warning_count']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook we:\n",
    "1. Validated raw clinical data\n",
    "2. Set up a feature store with DuckDB\n",
    "3. Registered features with metadata\n",
    "4. Computed and stored features\n",
    "5. Explored feature lineage\n",
    "6. Retrieved features for ML\n",
    "\n",
    "Next: `03_model_training_demo.ipynb` - Train a model using the feature store!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close feature store connection\n",
    "fs.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## End of Notebook ##"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
