{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03 - Model Training with Feature Store\n",
    "\n",
    "This notebook demonstrates:\n",
    "- Creating training datasets from the feature store\n",
    "- Training ML models for treatment response prediction\n",
    "- Evaluating model performance\n",
    "- Understanding feature importance\n",
    "- Benefits of feature store for ML workflows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from feature_store import FeatureStore\n",
    "from utils import split_train_test, calculate_feature_importance\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Connect to Feature Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize feature store\n",
    "fs = FeatureStore(\n",
    "    db_path='../data/feature_store.duckdb',\n",
    "    config_dir='../config'\n",
    ")\n",
    "\n",
    "print(\"Connected to feature store!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create Training Dataset\n",
    "\n",
    "Select features for predicting treatment response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define feature set for model\n",
    "feature_list = [\n",
    "    'age_scaled',\n",
    "    'tmb_score_scaled',\n",
    "    'mutation_burden',\n",
    "    'clinical_risk_score',\n",
    "    'wbc_imputed',\n",
    "    'hemoglobin_imputed',\n",
    "    'platelet_imputed'\n",
    "]\n",
    "\n",
    "# Create training dataset\n",
    "# Target: response_status (1 = responder, 0 = non-responder)\n",
    "training_data = fs.create_training_dataset(\n",
    "    feature_list=feature_list,\n",
    "    target='response_status',\n",
    "    include_metadata=False\n",
    ")\n",
    "\n",
    "print(f\"Training dataset shape: {training_data.shape}\")\n",
    "print(f\"Features: {feature_list}\")\n",
    "print(f\"Target: response_status\")\n",
    "print(f\"\\nClass balance: {training_data['response_status'].value_counts(normalize=True)}\")\n",
    "\n",
    "training_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Split Data\n",
    "\n",
    "Split into train and test sets with stratification to maintain class balance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target\n",
    "X = training_data[feature_list]\n",
    "y = training_data['response_status']\n",
    "\n",
    "# Split with stratification\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Training set: {X_train.shape}\")\n",
    "print(f\"Test set: {X_test.shape}\")\n",
    "print(f\"\\nTrain class balance: {y_train.value_counts(normalize=True)}\")\n",
    "print(f\"Test class balance: {y_test.value_counts(normalize=True)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train Models\n",
    "\n",
    "Train multiple models and compare performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize models\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "}\n",
    "\n",
    "# Train and evaluate each model\n",
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nTraining {name}...\")\n",
    "    \n",
    "    # Train\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # Cross-validation score\n",
    "    cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='roc_auc')\n",
    "    \n",
    "    # Store results\n",
    "    results[name] = {\n",
    "        'model': model,\n",
    "        'y_pred': y_pred,\n",
    "        'y_pred_proba': y_pred_proba,\n",
    "        'cv_auc': cv_scores.mean(),\n",
    "        'test_auc': roc_auc_score(y_test, y_pred_proba)\n",
    "    }\n",
    "    \n",
    "    print(f\"  CV AUC: {cv_scores.mean():.3f} (+/- {cv_scores.std():.3f})\")\n",
    "    print(f\"  Test AUC: {results[name]['test_auc']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Compare Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ROC curves\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "for name, result in results.items():\n",
    "    fpr, tpr, _ = roc_curve(y_test, result['y_pred_proba'])\n",
    "    ax.plot(fpr, tpr, label=f\"{name} (AUC={result['test_auc']:.3f})\")\n",
    "\n",
    "ax.plot([0, 1], [0, 1], 'k--', label='Random')\n",
    "ax.set_xlabel('False Positive Rate')\n",
    "ax.set_ylabel('True Positive Rate')\n",
    "ax.set_title('ROC Curves - Treatment Response Prediction')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select best model (highest test AUC)\n",
    "best_model_name = max(results.items(), key=lambda x: x[1]['test_auc'])[0]\n",
    "best_model = results[best_model_name]['model']\n",
    "best_predictions = results[best_model_name]['y_pred']\n",
    "\n",
    "print(f\"Best Model: {best_model_name}\")\n",
    "print(f\"Test AUC: {results[best_model_name]['test_auc']:.3f}\")\n",
    "print(f\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, best_predictions, target_names=['Non-Responder', 'Responder']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, best_predictions)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Non-Responder', 'Responder'],\n",
    "            yticklabels=['Non-Responder', 'Responder'])\n",
    "ax.set_ylabel('True Label')\n",
    "ax.set_xlabel('Predicted Label')\n",
    "ax.set_title(f'Confusion Matrix - {best_model_name}')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Feature Importance\n",
    "\n",
    "Understand which features are most predictive of treatment response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importance (using Random Forest for interpretability)\n",
    "rf_model = results['Random Forest']['model']\n",
    "importance_df = calculate_feature_importance(rf_model, feature_list)\n",
    "\n",
    "print(\"Feature Importance (Random Forest):\")\n",
    "print(importance_df)\n",
    "\n",
    "# Plot feature importance\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.barh(importance_df['feature'], importance_df['importance'])\n",
    "ax.set_xlabel('Importance')\n",
    "ax.set_title('Feature Importance for Treatment Response Prediction')\n",
    "ax.invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Feature Store Benefits\n",
    "\n",
    "### Key Benefits Demonstrated:\n",
    "\n",
    "1. **Centralized Features**: All features computed once and stored for reuse\n",
    "2. **Consistent Transformations**: Same features used in training and future predictions\n",
    "3. **Version Control**: Can track which feature version was used for each model\n",
    "4. **Lineage Tracking**: Know which raw data created which features\n",
    "5. **Quality Assurance**: Validation ensures only clean features are used\n",
    "6. **Easy Experimentation**: Can quickly try different feature combinations\n",
    "\n",
    "### Production ML Workflow:\n",
    "\n",
    "```\n",
    "Raw Data → Validation → Feature Store → Training Dataset → Model\n",
    "    ↓                         ↓              ↓               ↓\n",
    "Quality Checks         Feature Versioning  Reproducibility  Deployment\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Create Another Model with Different Features\n",
    "\n",
    "Show how easy it is to experiment with the feature store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try a genomics-focused model\n",
    "genomic_features = [\n",
    "    'mutation_burden',\n",
    "    'tmb_score_scaled',\n",
    "    'age_scaled'\n",
    "]\n",
    "\n",
    "# Create dataset (instantly, features already computed!)\n",
    "genomic_data = fs.create_training_dataset(\n",
    "    feature_list=genomic_features,\n",
    "    target='response_status',\n",
    "    include_metadata=False\n",
    ")\n",
    "\n",
    "X_genomic = genomic_data[genomic_features]\n",
    "y_genomic = genomic_data['response_status']\n",
    "\n",
    "# Train simple model\n",
    "X_train_g, X_test_g, y_train_g, y_test_g = train_test_split(\n",
    "    X_genomic, y_genomic, test_size=0.2, random_state=42, stratify=y_genomic\n",
    ")\n",
    "\n",
    "rf_genomic = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_genomic.fit(X_train_g, y_train_g)\n",
    "y_pred_g = rf_genomic.predict_proba(X_test_g)[:, 1]\n",
    "\n",
    "auc_genomic = roc_auc_score(y_test_g, y_pred_g)\n",
    "print(f\"Genomics-only model AUC: {auc_genomic:.3f}\")\n",
    "print(f\"Full feature model AUC: {results['Random Forest']['test_auc']:.3f}\")\n",
    "print(f\"\\nImprovement from adding clinical features: {(results['Random Forest']['test_auc'] - auc_genomic):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook we:\n",
    "1. Created training datasets from the feature store\n",
    "2. Trained and compared multiple ML models\n",
    "3. Achieved strong predictive performance for treatment response\n",
    "4. Understood feature importance\n",
    "5. Demonstrated feature store benefits for ML workflows\n",
    "\n",
    "Next: `04_monitoring_report.ipynb` - Monitor data quality over time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close feature store\n",
    "fs.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## End of Notebook ##"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
