{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "header"
   },
   "source": [
    "# Proteomics Data Analysis: From Raw Data to Disease Prediction\n",
    "\n",
    "## üß¨ Welcome to Bioinformatics Machine Learning!\n",
    "\n",
    "### Learning Objectives\n",
    "In this notebook, you will learn:\n",
    "1. **Data Quality Issues** in proteomics: missing values, batch effects, outliers\n",
    "2. **Data Cleaning Strategies**: filtering, imputation, outlier detection\n",
    "3. **Normalization Methods**: when and why to use different approaches\n",
    "4. **Batch Effect Correction**: identifying and removing technical artifacts\n",
    "5. **Machine Learning**: building classifiers for disease prediction\n",
    "6. **Feature Importance**: identifying which proteins matter most\n",
    "\n",
    "### The Biological Context\n",
    "You're analyzing protein expression data from patient samples to predict disease status. Proteomics data is notoriously messy:\n",
    "- Proteins have vastly different abundance levels (6+ orders of magnitude!)\n",
    "- Missing values are common (proteins below detection limit)\n",
    "- Technical variation (batch effects) can obscure biological signal\n",
    "- Proper preprocessing is CRITICAL for meaningful results\n",
    "\n",
    "---\n",
    "\n",
    "## üìã How to Use This Notebook in Google Colab\n",
    "\n",
    "### Option 1: Upload to Google Colab\n",
    "1. Go to [Google Colab](https://colab.research.google.com/)\n",
    "2. Click **File ‚Üí Upload notebook**\n",
    "3. Choose this `.ipynb` file from your computer\n",
    "4. The notebook will open in Colab\n",
    "\n",
    "### Option 2: Open from GitHub (if hosted there)\n",
    "1. Go to [Google Colab](https://colab.research.google.com/)\n",
    "2. Click **File ‚Üí Open notebook ‚Üí GitHub**\n",
    "3. Enter the repository URL\n",
    "\n",
    "### Running the Notebook\n",
    "- **Run a cell**: Click the play button (‚ñ∂Ô∏è) or press `Shift+Enter`\n",
    "- **Run all cells**: Click **Runtime ‚Üí Run all**\n",
    "- **Restart runtime**: Click **Runtime ‚Üí Restart runtime** if you need to start fresh\n",
    "\n",
    "### Saving Your Work\n",
    "- Colab auto-saves to Google Drive\n",
    "- Download: **File ‚Üí Download ‚Üí Download .ipynb**\n",
    "- Your changes won't affect the original file unless you explicitly save over it\n",
    "\n",
    "### Tips\n",
    "- Look for **TODO** comments - these are exercises for you to complete!\n",
    "- Read the markdown explanations before running code cells\n",
    "- Try modifying parameters to see how results change\n",
    "- If you get stuck, restart the runtime and run all cells from the top\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup"
   },
   "source": [
    "## 1. Setup and Library Installation\n",
    "\n",
    "First, let's import all the libraries we'll need. No special proteomics libraries required - we'll use standard scientific Python tools!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "imports"
   },
   "outputs": [],
   "source": [
    "# Data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import KNNImputer, SimpleImputer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
    "\n",
    "# Utilities\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Set plot style\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "\n",
    "print(\"‚úì All libraries imported successfully!\")\n",
    "print(\"‚úì Random seed set to 42 for reproducibility\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dataset-creation"
   },
   "source": [
    "## 2. Dataset Generation\n",
    "\n",
    "### Understanding Proteomics Data\n",
    "\n",
    "We're simulating a realistic proteomics experiment:\n",
    "- **100 samples**: 50 healthy controls, 50 disease patients\n",
    "- **500 proteins**: each with expression values\n",
    "- **2 technical batches**: samples processed on different days\n",
    "- **Realistic issues**: missing values, different protein abundances, batch effects, outliers\n",
    "\n",
    "### Key Challenges We're Simulating:\n",
    "1. **Missing values (15-20%)**: Some proteins aren't detected in all samples\n",
    "2. **Dynamic range**: Proteins have different baseline expression levels\n",
    "3. **Batch effects**: Technical variation between processing batches\n",
    "4. **Outliers**: A few samples with unusual patterns (technical failures)\n",
    "5. **Biological signal**: Disease-related changes in specific proteins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "generate-data"
   },
   "outputs": [],
   "source": [
    "def generate_proteomics_data():\n",
    "    \"\"\"\n",
    "    Generate realistic simulated proteomics data with common data quality issues.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    df : DataFrame with protein expression values\n",
    "    metadata : DataFrame with sample information (disease status, batch)\n",
    "    \"\"\"\n",
    "    \n",
    "    n_samples = 100\n",
    "    n_proteins = 500\n",
    "    \n",
    "    # Create sample metadata\n",
    "    sample_ids = [f'Sample_{i:03d}' for i in range(n_samples)]\n",
    "    disease_status = ['Healthy'] * 50 + ['Disease'] * 50\n",
    "    batch = ['Batch1'] * 50 + ['Batch2'] * 50  # Samples split into 2 batches\n",
    "    \n",
    "    metadata = pd.DataFrame({\n",
    "        'Sample_ID': sample_ids,\n",
    "        'Disease_Status': disease_status,\n",
    "        'Batch': batch\n",
    "    })\n",
    "    \n",
    "    # Create protein names\n",
    "    protein_names = [f'Protein_{i:03d}' for i in range(n_proteins)]\n",
    "    \n",
    "    # Generate base expression data\n",
    "    # Different proteins have different mean expression levels (simulating abundance)\n",
    "    protein_means = np.random.uniform(5, 15, n_proteins)  # Different baseline levels\n",
    "    protein_stds = np.random.uniform(0.5, 2.5, n_proteins)  # Different variability\n",
    "    \n",
    "    data = np.zeros((n_samples, n_proteins))\n",
    "    \n",
    "    for i in range(n_proteins):\n",
    "        data[:, i] = np.random.normal(protein_means[i], protein_stds[i], n_samples)\n",
    "    \n",
    "    # Add disease signal to specific proteins (first 50 proteins are disease-related)\n",
    "    disease_proteins = 50\n",
    "    for i in range(disease_proteins):\n",
    "        # Disease samples (last 50) have higher expression of these proteins\n",
    "        effect_size = np.random.uniform(1.5, 3.0)  # Fold change\n",
    "        data[50:, i] += effect_size\n",
    "    \n",
    "    # Add batch effect (Batch2 has systematic shift)\n",
    "    batch_effect_size = 1.5\n",
    "    data[50:, :] += batch_effect_size  # Batch2 samples have higher overall signal\n",
    "    \n",
    "    # Create outlier samples (2-3 samples with unusual patterns)\n",
    "    outlier_indices = [10, 35, 87]\n",
    "    for idx in outlier_indices:\n",
    "        # Add random large deviations\n",
    "        data[idx, :] += np.random.normal(0, 3, n_proteins)\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(data, index=sample_ids, columns=protein_names)\n",
    "    \n",
    "    # Introduce missing values (15-20% missing)\n",
    "    # More likely to be missing for low-abundance proteins\n",
    "    missing_rate = 0.175  # 17.5% missing\n",
    "    \n",
    "    for i, protein in enumerate(protein_names):\n",
    "        # Lower abundance proteins have more missing values\n",
    "        protein_missing_rate = missing_rate * (1 + (15 - protein_means[i]) / 10)\n",
    "        protein_missing_rate = np.clip(protein_missing_rate, 0.05, 0.40)\n",
    "        \n",
    "        # Randomly set values to NaN\n",
    "        missing_mask = np.random.random(n_samples) < protein_missing_rate\n",
    "        df.loc[missing_mask, protein] = np.nan\n",
    "    \n",
    "    # Make some proteins very sparse (>50% missing) - these should be filtered out\n",
    "    very_sparse_proteins = np.random.choice(protein_names, 20, replace=False)\n",
    "    for protein in very_sparse_proteins:\n",
    "        missing_mask = np.random.random(n_samples) < 0.65  # 65% missing\n",
    "        df.loc[missing_mask, protein] = np.nan\n",
    "    \n",
    "    # Make some samples very sparse (>30% missing) - these should be filtered out\n",
    "    very_sparse_samples = [sample_ids[5], sample_ids[73]]\n",
    "    for sample in very_sparse_samples:\n",
    "        missing_mask = np.random.choice([True, False], n_proteins, p=[0.45, 0.55])\n",
    "        df.loc[sample, missing_mask] = np.nan\n",
    "    \n",
    "    return df, metadata\n",
    "\n",
    "# Generate the data\n",
    "print(\"Generating proteomics dataset...\")\n",
    "df_raw, metadata = generate_proteomics_data()\n",
    "\n",
    "print(f\"\\n‚úì Dataset generated successfully!\")\n",
    "print(f\"  - Samples: {df_raw.shape[0]}\")\n",
    "print(f\"  - Proteins: {df_raw.shape[1]}\")\n",
    "print(f\"  - Missing values: {df_raw.isna().sum().sum()} ({100*df_raw.isna().sum().sum()/(df_raw.shape[0]*df_raw.shape[1]):.1f}%)\")\n",
    "print(f\"\\nMetadata:\")\n",
    "print(metadata.head())\n",
    "print(f\"\\nExpression data (first 5 samples, first 5 proteins):\")\n",
    "print(df_raw.iloc[:5, :5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "data-exploration"
   },
   "source": [
    "## 3. Data Exploration\n",
    "\n",
    "Before cleaning, let's understand our data quality issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "explore-data"
   },
   "outputs": [],
   "source": [
    "# Basic statistics\n",
    "print(\"=\" * 60)\n",
    "print(\"DATA QUALITY ASSESSMENT\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Missing values per sample\n",
    "missing_per_sample = df_raw.isna().sum(axis=1)\n",
    "print(f\"\\nMissing values per sample:\")\n",
    "print(f\"  Mean: {missing_per_sample.mean():.1f} proteins ({100*missing_per_sample.mean()/df_raw.shape[1]:.1f}%)\")\n",
    "print(f\"  Max: {missing_per_sample.max()} proteins ({100*missing_per_sample.max()/df_raw.shape[1]:.1f}%)\")\n",
    "print(f\"  Samples with >30% missing: {(missing_per_sample > 0.3*df_raw.shape[1]).sum()}\")\n",
    "\n",
    "# Missing values per protein\n",
    "missing_per_protein = df_raw.isna().sum(axis=0)\n",
    "print(f\"\\nMissing values per protein:\")\n",
    "print(f\"  Mean: {missing_per_protein.mean():.1f} samples ({100*missing_per_protein.mean()/df_raw.shape[0]:.1f}%)\")\n",
    "print(f\"  Max: {missing_per_protein.max()} samples ({100*missing_per_protein.max()/df_raw.shape[0]:.1f}%)\")\n",
    "print(f\"  Proteins with >50% missing: {(missing_per_protein > 0.5*df_raw.shape[0]).sum()}\")\n",
    "\n",
    "# Visualizations\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# 1. Distribution of expression values\n",
    "ax = axes[0, 0]\n",
    "sample_data = df_raw.iloc[0, :].dropna()  # First sample\n",
    "ax.hist(sample_data, bins=50, edgecolor='black', alpha=0.7)\n",
    "ax.set_xlabel('Expression Value')\n",
    "ax.set_ylabel('Frequency')\n",
    "ax.set_title('Distribution of Protein Expression (Sample 1)')\n",
    "ax.axvline(sample_data.mean(), color='red', linestyle='--', label=f'Mean: {sample_data.mean():.2f}')\n",
    "ax.legend()\n",
    "\n",
    "# 2. Missing values per sample\n",
    "ax = axes[0, 1]\n",
    "ax.bar(range(len(missing_per_sample)), missing_per_sample.values, alpha=0.7)\n",
    "ax.axhline(y=0.3*df_raw.shape[1], color='red', linestyle='--', label='30% threshold')\n",
    "ax.set_xlabel('Sample Index')\n",
    "ax.set_ylabel('Number of Missing Proteins')\n",
    "ax.set_title('Missing Values per Sample')\n",
    "ax.legend()\n",
    "\n",
    "# 3. Missing values per protein (histogram)\n",
    "ax = axes[1, 0]\n",
    "ax.hist(missing_per_protein.values, bins=30, edgecolor='black', alpha=0.7)\n",
    "ax.axvline(x=0.5*df_raw.shape[0], color='red', linestyle='--', label='50% threshold')\n",
    "ax.set_xlabel('Number of Missing Samples')\n",
    "ax.set_ylabel('Number of Proteins')\n",
    "ax.set_title('Distribution of Missing Values Across Proteins')\n",
    "ax.legend()\n",
    "\n",
    "# 4. Expression range across proteins (boxplot of means)\n",
    "ax = axes[1, 1]\n",
    "protein_means = df_raw.mean(axis=0)\n",
    "ax.hist(protein_means, bins=50, edgecolor='black', alpha=0.7)\n",
    "ax.set_xlabel('Mean Expression Level')\n",
    "ax.set_ylabel('Number of Proteins')\n",
    "ax.set_title('Distribution of Mean Protein Expression Levels\\n(Shows Dynamic Range)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n‚úì Exploration complete! Notice the data quality issues we need to address.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "data-cleaning"
   },
   "source": [
    "## 4. Data Cleaning Pipeline\n",
    "\n",
    "### Why Data Cleaning Matters\n",
    "\n",
    "In proteomics, **garbage in = garbage out**. We need to:\n",
    "1. Remove unreliable measurements (too many missing values)\n",
    "2. Handle remaining missing values appropriately\n",
    "3. Detect outlier samples that might be technical failures\n",
    "\n",
    "### The Cleaning Strategy\n",
    "1. **Filter proteins** with >50% missing (unreliable)\n",
    "2. **Filter samples** with >30% missing (poor quality)\n",
    "3. **Impute** remaining missing values\n",
    "4. **Detect outliers** using PCA\n",
    "5. **Decide** whether to remove outliers\n",
    "\n",
    "Let's go step by step!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "step1-missingness"
   },
   "source": [
    "### Step 1: Visualize Missingness Pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "visualize-missing"
   },
   "outputs": [],
   "source": [
    "# Create a missingness heatmap (sample every 5th protein to make it visible)\n",
    "fig, ax = plt.subplots(figsize=(15, 8))\n",
    "\n",
    "# Sample proteins for visualization\n",
    "protein_subset = df_raw.columns[::10]  # Every 10th protein\n",
    "missing_matrix = df_raw[protein_subset].isna().astype(int)\n",
    "\n",
    "sns.heatmap(missing_matrix.T, cmap='RdYlGn_r', cbar_kws={'label': 'Missing (1) vs Present (0)'},\n",
    "            yticklabels=True, xticklabels=False, ax=ax)\n",
    "ax.set_xlabel('Samples')\n",
    "ax.set_ylabel('Proteins (every 10th shown)')\n",
    "ax.set_title('Missingness Pattern\\n(Red = Missing, Green = Present)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Notice:\")\n",
    "print(\"  - Some proteins (rows) are mostly red = sparse proteins to filter\")\n",
    "print(\"  - Some samples (columns) have many red streaks = poor quality samples\")\n",
    "print(\"  - Missing values are NOT random - this is realistic!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "step2-filter-proteins"
   },
   "source": [
    "### Step 2: Filter Proteins with >50% Missing Values\n",
    "\n",
    "**Why?** Proteins with too many missing values are unreliable. Imputing >50% of the data would introduce too much noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "filter-proteins"
   },
   "outputs": [],
   "source": [
    "# Calculate missing percentage per protein\n",
    "missing_pct_protein = df_raw.isna().sum(axis=0) / df_raw.shape[0]\n",
    "\n",
    "# Filter proteins\n",
    "threshold_protein = 0.50\n",
    "proteins_to_keep = missing_pct_protein[missing_pct_protein <= threshold_protein].index\n",
    "df_filtered_proteins = df_raw[proteins_to_keep].copy()\n",
    "\n",
    "print(f\"Protein Filtering (>{threshold_protein*100:.0f}% missing):\")\n",
    "print(f\"  - Original proteins: {df_raw.shape[1]}\")\n",
    "print(f\"  - Proteins removed: {df_raw.shape[1] - df_filtered_proteins.shape[1]}\")\n",
    "print(f\"  - Proteins retained: {df_filtered_proteins.shape[1]}\")\n",
    "print(f\"  - Retention rate: {100*df_filtered_proteins.shape[1]/df_raw.shape[1]:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "step3-filter-samples"
   },
   "source": [
    "### Step 3: Filter Samples with >30% Missing Values\n",
    "\n",
    "**Why?** Samples with too many missing values likely had technical problems during processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "filter-samples"
   },
   "outputs": [],
   "source": [
    "# Calculate missing percentage per sample\n",
    "missing_pct_sample = df_filtered_proteins.isna().sum(axis=1) / df_filtered_proteins.shape[1]\n",
    "\n",
    "# Filter samples\n",
    "threshold_sample = 0.30\n",
    "samples_to_keep = missing_pct_sample[missing_pct_sample <= threshold_sample].index\n",
    "df_filtered_both = df_filtered_proteins.loc[samples_to_keep].copy()\n",
    "\n",
    "# Update metadata\n",
    "metadata_filtered = metadata[metadata['Sample_ID'].isin(samples_to_keep)].copy()\n",
    "metadata_filtered.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(f\"Sample Filtering (>{threshold_sample*100:.0f}% missing):\")\n",
    "print(f\"  - Original samples: {df_filtered_proteins.shape[0]}\")\n",
    "print(f\"  - Samples removed: {df_filtered_proteins.shape[0] - df_filtered_both.shape[0]}\")\n",
    "print(f\"  - Samples retained: {df_filtered_both.shape[0]}\")\n",
    "print(f\"  - Retention rate: {100*df_filtered_both.shape[0]/df_filtered_proteins.shape[0]:.1f}%\")\n",
    "\n",
    "print(f\"\\nAfter filtering:\")\n",
    "print(f\"  - Dataset shape: {df_filtered_both.shape}\")\n",
    "print(f\"  - Remaining missing values: {df_filtered_both.isna().sum().sum()} ({100*df_filtered_both.isna().sum().sum()/(df_filtered_both.shape[0]*df_filtered_both.shape[1]):.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "step4-imputation"
   },
   "source": [
    "### Step 4: Impute Remaining Missing Values\n",
    "\n",
    "**Imputation Methods:**\n",
    "1. **Mean imputation**: Replace missing with column mean (simple, but ignores sample similarity)\n",
    "2. **Median imputation**: More robust to outliers than mean\n",
    "3. **KNN imputation**: Use k-nearest neighbors (considers sample similarity)\n",
    "\n",
    "**Which to use?** KNN is usually best for proteomics, but computationally expensive. Let's compare!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "imputation"
   },
   "outputs": [],
   "source": [
    "def impute_data(df, method='mean', n_neighbors=5):\n",
    "    \"\"\"\n",
    "    Impute missing values using specified method.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : DataFrame\n",
    "    method : str, one of 'mean', 'median', 'knn'\n",
    "    n_neighbors : int, for KNN imputation\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    df_imputed : DataFrame with no missing values\n",
    "    \"\"\"\n",
    "    if method == 'mean':\n",
    "        imputer = SimpleImputer(strategy='mean')\n",
    "    elif method == 'median':\n",
    "        imputer = SimpleImputer(strategy='median')\n",
    "    elif method == 'knn':\n",
    "        imputer = KNNImputer(n_neighbors=n_neighbors)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown method: {method}\")\n",
    "    \n",
    "    data_imputed = imputer.fit_transform(df)\n",
    "    df_imputed = pd.DataFrame(data_imputed, index=df.index, columns=df.columns)\n",
    "    \n",
    "    return df_imputed\n",
    "\n",
    "# Try all three methods\n",
    "print(\"Imputing missing values with different methods...\\n\")\n",
    "\n",
    "df_imputed_mean = impute_data(df_filtered_both, method='mean')\n",
    "print(\"‚úì Mean imputation complete\")\n",
    "\n",
    "df_imputed_median = impute_data(df_filtered_both, method='median')\n",
    "print(\"‚úì Median imputation complete\")\n",
    "\n",
    "df_imputed_knn = impute_data(df_filtered_both, method='knn', n_neighbors=5)\n",
    "print(\"‚úì KNN imputation complete\")\n",
    "\n",
    "# Verify no missing values\n",
    "print(f\"\\nMissing values after imputation:\")\n",
    "print(f\"  - Mean: {df_imputed_mean.isna().sum().sum()}\")\n",
    "print(f\"  - Median: {df_imputed_median.isna().sum().sum()}\")\n",
    "print(f\"  - KNN: {df_imputed_knn.isna().sum().sum()}\")\n",
    "\n",
    "# Compare imputation methods by looking at variance introduced\n",
    "print(f\"\\nMean expression level (should be similar):\")\n",
    "print(f\"  - Mean imputation: {df_imputed_mean.values.mean():.3f}\")\n",
    "print(f\"  - Median imputation: {df_imputed_median.values.mean():.3f}\")\n",
    "print(f\"  - KNN imputation: {df_imputed_knn.values.mean():.3f}\")\n",
    "\n",
    "# We'll use KNN for subsequent analysis (generally best practice)\n",
    "df_imputed = df_imputed_knn.copy()\n",
    "print(\"\\n‚úì Using KNN imputation for subsequent analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "exercise-1"
   },
   "outputs": [],
   "source": [
    "# TODO: EXERCISE 1 - Try a different imputation method or parameter\n",
    "# \n",
    "# Try these experiments:\n",
    "# 1. Change n_neighbors in KNN imputation (try 3, 10, 15)\n",
    "# 2. Compare results using PCA plots (see Step 5 below for PCA code)\n",
    "# 3. Which method seems to preserve the data structure best?\n",
    "#\n",
    "# Your code here:\n",
    "# df_imputed_knn_k3 = impute_data(df_filtered_both, method='knn', n_neighbors=3)\n",
    "# ... compare with PCA ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "step5-outliers"
   },
   "source": [
    "### Step 5: Detect Outlier Samples Using PCA\n",
    "\n",
    "**Principal Component Analysis (PCA)** reduces our 500-dimensional data to 2D for visualization. \n",
    "\n",
    "**Outliers** will appear far from the main cluster. These could be:\n",
    "- Technical failures (sample degradation, processing errors)\n",
    "- Interesting biological samples (rare subtypes)\n",
    "\n",
    "**Decision:** Removing outliers improves model performance but loses information. We'll identify them, then decide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "detect-outliers"
   },
   "outputs": [],
   "source": [
    "# Perform PCA\n",
    "pca = PCA(n_components=2)\n",
    "pca_coords = pca.fit_transform(df_imputed)\n",
    "\n",
    "# Create PCA DataFrame\n",
    "pca_df = pd.DataFrame(pca_coords, columns=['PC1', 'PC2'], index=df_imputed.index)\n",
    "pca_df = pca_df.merge(metadata_filtered, left_index=True, right_on='Sample_ID')\n",
    "\n",
    "# Detect outliers using z-score method (>3 SD from mean)\n",
    "from scipy.stats import zscore\n",
    "z_scores = np.abs(zscore(pca_coords, axis=0))\n",
    "outlier_threshold = 3\n",
    "outliers = (z_scores > outlier_threshold).any(axis=1)\n",
    "\n",
    "pca_df['Is_Outlier'] = outliers\n",
    "\n",
    "print(f\"Outlier Detection:\")\n",
    "print(f\"  - Outliers detected: {outliers.sum()}\")\n",
    "print(f\"  - Outlier samples: {', '.join(pca_df[pca_df['Is_Outlier']]['Sample_ID'].values)}\")\n",
    "\n",
    "# Visualize PCA with outliers highlighted\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Plot 1: Colored by disease status\n",
    "ax = axes[0]\n",
    "for disease in ['Healthy', 'Disease']:\n",
    "    mask = pca_df['Disease_Status'] == disease\n",
    "    ax.scatter(pca_df[mask]['PC1'], pca_df[mask]['PC2'], \n",
    "               label=disease, alpha=0.6, s=100)\n",
    "\n",
    "# Highlight outliers\n",
    "outlier_data = pca_df[pca_df['Is_Outlier']]\n",
    "ax.scatter(outlier_data['PC1'], outlier_data['PC2'], \n",
    "           color='red', s=200, marker='x', linewidths=3, label='Outliers')\n",
    "\n",
    "ax.set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]*100:.1f}% variance)')\n",
    "ax.set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]*100:.1f}% variance)')\n",
    "ax.set_title('PCA: Outlier Detection\\n(Red X = Outliers)')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Colored by batch (to see batch effects)\n",
    "ax = axes[1]\n",
    "for batch in ['Batch1', 'Batch2']:\n",
    "    mask = pca_df['Batch'] == batch\n",
    "    ax.scatter(pca_df[mask]['PC1'], pca_df[mask]['PC2'], \n",
    "               label=batch, alpha=0.6, s=100)\n",
    "\n",
    "ax.scatter(outlier_data['PC1'], outlier_data['PC2'], \n",
    "           color='red', s=200, marker='x', linewidths=3, label='Outliers')\n",
    "\n",
    "ax.set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]*100:.1f}% variance)')\n",
    "ax.set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]*100:.1f}% variance)')\n",
    "ax.set_title('PCA: Batch Effect Visible\\n(Notice batch separation!)')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nObservations:\")\n",
    "print(\"  - Left plot: Can you see disease separation?\")\n",
    "print(\"  - Right plot: Notice how batches cluster separately?\")\n",
    "print(\"  - This batch effect needs correction!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "step6-remove-outliers"
   },
   "source": [
    "### Step 6: (Optional) Remove Outliers\n",
    "\n",
    "**Decision time!** Should we remove outliers?\n",
    "\n",
    "**Pros:** Better model performance, cleaner patterns  \n",
    "**Cons:** Lose potentially interesting samples, reduce sample size\n",
    "\n",
    "For this exercise, we'll keep them to maintain sample size, but you can experiment!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "remove-outliers"
   },
   "outputs": [],
   "source": [
    "# Option to remove outliers (set to False to keep them)\n",
    "REMOVE_OUTLIERS = False\n",
    "\n",
    "if REMOVE_OUTLIERS:\n",
    "    # Remove outliers\n",
    "    non_outlier_samples = pca_df[~pca_df['Is_Outlier']]['Sample_ID'].values\n",
    "    df_cleaned = df_imputed.loc[non_outlier_samples].copy()\n",
    "    metadata_cleaned = metadata_filtered[metadata_filtered['Sample_ID'].isin(non_outlier_samples)].copy()\n",
    "    print(f\"‚úì Outliers removed. Remaining samples: {df_cleaned.shape[0]}\")\n",
    "else:\n",
    "    df_cleaned = df_imputed.copy()\n",
    "    metadata_cleaned = metadata_filtered.copy()\n",
    "    print(f\"‚úì Outliers kept. Total samples: {df_cleaned.shape[0]}\")\n",
    "\n",
    "print(f\"\\nFinal cleaned dataset:\")\n",
    "print(f\"  - Samples: {df_cleaned.shape[0]}\")\n",
    "print(f\"  - Proteins: {df_cleaned.shape[1]}\")\n",
    "print(f\"  - Missing values: {df_cleaned.isna().sum().sum()}\")\n",
    "print(f\"  - Disease distribution: {metadata_cleaned['Disease_Status'].value_counts().to_dict()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "exercise-2"
   },
   "outputs": [],
   "source": [
    "# TODO: EXERCISE 2 - Experiment with different filtering thresholds\n",
    "#\n",
    "# Try these experiments:\n",
    "# 1. Change protein filtering threshold (try 0.3, 0.4, 0.6)\n",
    "# 2. Change sample filtering threshold (try 0.2, 0.4)\n",
    "# 3. How does this affect your final dataset size?\n",
    "# 4. What's the trade-off between data quality and sample size?\n",
    "#\n",
    "# Your code here:\n",
    "# threshold_protein = 0.40\n",
    "# ... repeat filtering steps ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "normalization"
   },
   "source": [
    "## 5. Normalization Methods\n",
    "\n",
    "### Why Normalize?\n",
    "\n",
    "Proteins have vastly different expression levels (some are 1000x more abundant than others). Without normalization:\n",
    "- High-abundance proteins dominate ML algorithms\n",
    "- Sample-to-sample technical variation obscures biology\n",
    "- Distance-based methods (PCA, SVM) perform poorly\n",
    "\n",
    "### Methods We'll Compare:\n",
    "\n",
    "1. **Quantile Normalization**: Makes sample distributions identical (assumes most proteins don't change)\n",
    "2. **Z-score (per protein)**: Centers and scales each protein to mean=0, std=1 (makes proteins comparable)\n",
    "3. **Log2 + Scaling**: Log transform to reduce dynamic range, then scale (common in genomics)\n",
    "\n",
    "### When to Use Each:\n",
    "- **Quantile**: When you expect most proteins unchanged between groups\n",
    "- **Z-score**: When proteins have different dynamic ranges (most common)\n",
    "- **Log2**: When data is log-normally distributed (common in RNA-seq, proteomics)\n",
    "\n",
    "Let's implement and compare!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "normalization-functions"
   },
   "outputs": [],
   "source": [
    "def quantile_normalize(df):\n",
    "    \"\"\"\n",
    "    Quantile normalization: make all sample distributions identical.\n",
    "    \"\"\"\n",
    "    # Sort each column\n",
    "    sorted_df = pd.DataFrame(np.sort(df.values, axis=0), \n",
    "                             index=df.index, columns=df.columns)\n",
    "    # Calculate mean of each rank\n",
    "    rank_means = sorted_df.mean(axis=1)\n",
    "    # Get ranks of original data\n",
    "    ranks = df.rank(method='min').astype(int) - 1\n",
    "    # Replace with mean values\n",
    "    normalized = ranks.apply(lambda x: rank_means.iloc[x].values, axis=0)\n",
    "    return pd.DataFrame(normalized, index=df.index, columns=df.columns)\n",
    "\n",
    "def zscore_normalize(df):\n",
    "    \"\"\"\n",
    "    Z-score normalization per protein: mean=0, std=1.\n",
    "    \"\"\"\n",
    "    return df.apply(lambda x: (x - x.mean()) / x.std(), axis=0)\n",
    "\n",
    "def log2_normalize(df):\n",
    "    \"\"\"\n",
    "    Log2 transformation + standardization.\n",
    "    \"\"\"\n",
    "    # Add small constant to avoid log(0)\n",
    "    df_shifted = df - df.min().min() + 1\n",
    "    df_log = np.log2(df_shifted)\n",
    "    # Standardize\n",
    "    scaler = StandardScaler()\n",
    "    df_normalized = pd.DataFrame(scaler.fit_transform(df_log),\n",
    "                                  index=df.index, columns=df.columns)\n",
    "    return df_normalized\n",
    "\n",
    "print(\"Applying normalization methods...\\n\")\n",
    "\n",
    "# Apply all normalization methods\n",
    "df_quantile = quantile_normalize(df_cleaned)\n",
    "print(\"‚úì Quantile normalization complete\")\n",
    "\n",
    "df_zscore = zscore_normalize(df_cleaned)\n",
    "print(\"‚úì Z-score normalization complete\")\n",
    "\n",
    "df_log2 = log2_normalize(df_cleaned)\n",
    "print(\"‚úì Log2 normalization complete\")\n",
    "\n",
    "print(\"\\n‚úì All normalization methods applied!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "normalization-visualization"
   },
   "source": [
    "### Visualizing Normalization Effects\n",
    "\n",
    "Let's see how each method changes the data distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "visualize-normalization"
   },
   "outputs": [],
   "source": [
    "# Compare normalization methods\n",
    "fig, axes = plt.subplots(2, 4, figsize=(20, 10))\n",
    "\n",
    "datasets = [\n",
    "    ('Raw', df_cleaned),\n",
    "    ('Quantile', df_quantile),\n",
    "    ('Z-score', df_zscore),\n",
    "    ('Log2', df_log2)\n",
    "]\n",
    "\n",
    "# Row 1: Boxplots (sample distributions)\n",
    "for idx, (name, data) in enumerate(datasets):\n",
    "    ax = axes[0, idx]\n",
    "    # Sample 10 random samples for clarity\n",
    "    sample_subset = data.iloc[:10, :]\n",
    "    ax.boxplot([sample_subset.iloc[i, :] for i in range(10)], \n",
    "               labels=[f'S{i+1}' for i in range(10)])\n",
    "    ax.set_title(f'{name}\\nBoxplot Across Samples')\n",
    "    ax.set_xlabel('Sample')\n",
    "    ax.set_ylabel('Expression')\n",
    "    ax.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Row 2: Histograms (overall distribution)\n",
    "for idx, (name, data) in enumerate(datasets):\n",
    "    ax = axes[1, idx]\n",
    "    # Flatten all values\n",
    "    all_values = data.values.flatten()\n",
    "    ax.hist(all_values, bins=50, edgecolor='black', alpha=0.7)\n",
    "    ax.set_title(f'{name}\\nOverall Distribution')\n",
    "    ax.set_xlabel('Expression Value')\n",
    "    ax.set_ylabel('Frequency')\n",
    "    ax.axvline(np.mean(all_values), color='red', linestyle='--', \n",
    "               label=f'Mean: {np.mean(all_values):.2f}')\n",
    "    ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nObservations:\")\n",
    "print(\"  - Raw: Wide range, different medians per sample\")\n",
    "print(\"  - Quantile: All samples have identical distributions\")\n",
    "print(\"  - Z-score: Centered at 0, same scale across proteins\")\n",
    "print(\"  - Log2: Compressed dynamic range, normalized scale\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "batch-correction"
   },
   "source": [
    "## 6. Batch Effect Correction\n",
    "\n",
    "### What are Batch Effects?\n",
    "\n",
    "**Batch effects** = systematic technical differences between groups of samples processed together.\n",
    "\n",
    "In our data:\n",
    "- Batch 1: Samples 0-49 (processed on Day 1)\n",
    "- Batch 2: Samples 50-99 (processed on Day 2)\n",
    "\n",
    "**Problem:** Batch effects can be LARGER than biological effects!\n",
    "\n",
    "**Solution:** Statistical correction to remove batch effects while preserving biology.\n",
    "\n",
    "### Methods:\n",
    "1. **Mean centering**: Subtract batch-specific mean (simple, fast)\n",
    "2. **ComBat**: Empirical Bayes method (gold standard, but needs extra library)\n",
    "\n",
    "We'll use mean centering for simplicity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "batch-correction-viz"
   },
   "outputs": [],
   "source": [
    "# Visualize batch effect BEFORE correction\n",
    "def visualize_batch_effect(data, metadata, title_prefix=\"\"):\n",
    "    \"\"\"\n",
    "    Visualize batch effects using PCA.\n",
    "    \"\"\"\n",
    "    pca = PCA(n_components=2)\n",
    "    pca_coords = pca.fit_transform(data)\n",
    "    \n",
    "    pca_df = pd.DataFrame(pca_coords, columns=['PC1', 'PC2'])\n",
    "    pca_df['Batch'] = metadata['Batch'].values\n",
    "    pca_df['Disease'] = metadata['Disease_Status'].values\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    \n",
    "    # Plot by batch\n",
    "    ax = axes[0]\n",
    "    for batch in ['Batch1', 'Batch2']:\n",
    "        mask = pca_df['Batch'] == batch\n",
    "        ax.scatter(pca_df[mask]['PC1'], pca_df[mask]['PC2'], \n",
    "                   label=batch, alpha=0.6, s=100)\n",
    "    ax.set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]*100:.1f}%)')\n",
    "    ax.set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]*100:.1f}%)')\n",
    "    ax.set_title(f'{title_prefix}PCA by Batch')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot by disease\n",
    "    ax = axes[1]\n",
    "    for disease in ['Healthy', 'Disease']:\n",
    "        mask = pca_df['Disease'] == disease\n",
    "        ax.scatter(pca_df[mask]['PC1'], pca_df[mask]['PC2'], \n",
    "                   label=disease, alpha=0.6, s=100)\n",
    "    ax.set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]*100:.1f}%)')\n",
    "    ax.set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]*100:.1f}%)')\n",
    "    ax.set_title(f'{title_prefix}PCA by Disease Status')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return pca.explained_variance_ratio_\n",
    "\n",
    "# Before correction\n",
    "print(\"BEFORE Batch Correction:\")\n",
    "var_before = visualize_batch_effect(df_zscore, metadata_cleaned, \"BEFORE Correction: \")\n",
    "print(\"\\nNotice: Batch separation is visible in PC1!\")\n",
    "print(\"This means batch effects are a major source of variance.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "batch-correction-apply"
   },
   "outputs": [],
   "source": [
    "def batch_correct_mean_centering(data, metadata):\n",
    "    \"\"\"\n",
    "    Simple batch correction: subtract batch-specific mean for each protein.\n",
    "    \"\"\"\n",
    "    data_corrected = data.copy()\n",
    "    \n",
    "    for batch in metadata['Batch'].unique():\n",
    "        # Get samples in this batch\n",
    "        batch_samples = metadata[metadata['Batch'] == batch]['Sample_ID'].values\n",
    "        \n",
    "        # Calculate batch mean for each protein\n",
    "        batch_mean = data_corrected.loc[batch_samples].mean(axis=0)\n",
    "        \n",
    "        # Subtract batch mean\n",
    "        data_corrected.loc[batch_samples] -= batch_mean\n",
    "    \n",
    "    return data_corrected\n",
    "\n",
    "# Apply batch correction\n",
    "df_batch_corrected = batch_correct_mean_centering(df_zscore, metadata_cleaned)\n",
    "\n",
    "print(\"\\nAFTER Batch Correction:\")\n",
    "var_after = visualize_batch_effect(df_batch_corrected, metadata_cleaned, \"AFTER Correction: \")\n",
    "\n",
    "print(\"\\nNotice: Batch separation reduced!\")\n",
    "print(\"Disease signal is now more visible.\")\n",
    "print(f\"\\nVariance explained by PC1: Before={var_before[0]*100:.1f}%, After={var_after[0]*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ml-intro"
   },
   "source": [
    "## 7. Machine Learning: Disease Prediction\n",
    "\n",
    "### The Task\n",
    "\n",
    "Can we predict disease status from protein expression?\n",
    "\n",
    "### Models We'll Try:\n",
    "1. **Logistic Regression**: Linear model, interpretable, fast\n",
    "2. **Random Forest**: Ensemble of decision trees, handles non-linearity\n",
    "3. **SVM**: Support Vector Machine, good for high-dimensional data\n",
    "\n",
    "### Evaluation Strategy:\n",
    "- **Train/test split**: 70/30, stratified (maintain class balance)\n",
    "- **Cross-validation**: 5-fold CV on training set\n",
    "- **Metrics**: Accuracy, ROC-AUC, confusion matrix\n",
    "\n",
    "### Hypothesis:\n",
    "**Proper preprocessing should improve all models!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ml-setup"
   },
   "outputs": [],
   "source": [
    "def prepare_ml_data(data, metadata, test_size=0.3, random_state=42):\n",
    "    \"\"\"\n",
    "    Prepare data for machine learning.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    X_train, X_test, y_train, y_test\n",
    "    \"\"\"\n",
    "    # Features (protein expression)\n",
    "    X = data.values\n",
    "    \n",
    "    # Target (disease status: 0=Healthy, 1=Disease)\n",
    "    y = (metadata['Disease_Status'] == 'Disease').astype(int).values\n",
    "    \n",
    "    # Stratified split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=random_state, stratify=y\n",
    "    )\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def evaluate_model(model, X_train, X_test, y_train, y_test, model_name=\"Model\"):\n",
    "    \"\"\"\n",
    "    Train and evaluate a model.\n",
    "    \"\"\"\n",
    "    # Train\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Cross-validation on training set\n",
    "    cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='roc_auc')\n",
    "    \n",
    "    # Test set predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # Metrics\n",
    "    test_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    \n",
    "    return {\n",
    "        'model': model,\n",
    "        'model_name': model_name,\n",
    "        'cv_auc_mean': cv_scores.mean(),\n",
    "        'cv_auc_std': cv_scores.std(),\n",
    "        'test_auc': test_auc,\n",
    "        'y_pred': y_pred,\n",
    "        'y_pred_proba': y_pred_proba,\n",
    "        'y_test': y_test\n",
    "    }\n",
    "\n",
    "# Prepare data (using batch-corrected, normalized data)\n",
    "X_train, X_test, y_train, y_test = prepare_ml_data(df_batch_corrected, metadata_cleaned)\n",
    "\n",
    "print(\"Data prepared for machine learning:\")\n",
    "print(f\"  - Training samples: {X_train.shape[0]} (Healthy: {(y_train==0).sum()}, Disease: {(y_train==1).sum()})\")\n",
    "print(f\"  - Test samples: {X_test.shape[0]} (Healthy: {(y_test==0).sum()}, Disease: {(y_test==1).sum()})\")\n",
    "print(f\"  - Features: {X_train.shape[1]} proteins\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ml-train"
   },
   "source": [
    "### Training Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "train-models"
   },
   "outputs": [],
   "source": [
    "# Define models\n",
    "models = [\n",
    "    (LogisticRegression(max_iter=1000, random_state=42), \"Logistic Regression\"),\n",
    "    (RandomForestClassifier(n_estimators=100, random_state=42), \"Random Forest\"),\n",
    "    (SVC(kernel='rbf', probability=True, random_state=42), \"SVM (RBF)\")\n",
    "]\n",
    "\n",
    "# Train and evaluate all models\n",
    "results = []\n",
    "\n",
    "print(\"Training models...\\n\")\n",
    "for model, name in models:\n",
    "    print(f\"Training {name}...\")\n",
    "    result = evaluate_model(model, X_train, X_test, y_train, y_test, name)\n",
    "    results.append(result)\n",
    "    print(f\"  ‚úì CV AUC: {result['cv_auc_mean']:.3f} ¬± {result['cv_auc_std']:.3f}\")\n",
    "    print(f\"  ‚úì Test AUC: {result['test_auc']:.3f}\\n\")\n",
    "\n",
    "print(\"‚úì All models trained!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ml-results"
   },
   "source": [
    "### Model Performance Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "visualize-results"
   },
   "outputs": [],
   "source": [
    "# Create comprehensive results visualization\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# 1. ROC Curves\n",
    "ax = axes[0, 0]\n",
    "for result in results:\n",
    "    fpr, tpr, _ = roc_curve(result['y_test'], result['y_pred_proba'])\n",
    "    ax.plot(fpr, tpr, label=f\"{result['model_name']} (AUC={result['test_auc']:.3f})\")\n",
    "ax.plot([0, 1], [0, 1], 'k--', label='Random')\n",
    "ax.set_xlabel('False Positive Rate')\n",
    "ax.set_ylabel('True Positive Rate')\n",
    "ax.set_title('ROC Curves (Test Set)')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Performance Bar Chart\n",
    "ax = axes[0, 1]\n",
    "model_names = [r['model_name'] for r in results]\n",
    "cv_aucs = [r['cv_auc_mean'] for r in results]\n",
    "test_aucs = [r['test_auc'] for r in results]\n",
    "\n",
    "x = np.arange(len(model_names))\n",
    "width = 0.35\n",
    "\n",
    "ax.bar(x - width/2, cv_aucs, width, label='CV AUC (Train)', alpha=0.8)\n",
    "ax.bar(x + width/2, test_aucs, width, label='Test AUC', alpha=0.8)\n",
    "ax.set_xlabel('Model')\n",
    "ax.set_ylabel('AUC Score')\n",
    "ax.set_title('Model Performance Comparison')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(model_names, rotation=45, ha='right')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "ax.set_ylim([0.5, 1.0])\n",
    "\n",
    "# 3-4. Confusion Matrices for top 2 models\n",
    "for idx, result in enumerate(results[:2]):\n",
    "    ax = axes[1, idx]\n",
    "    cm = confusion_matrix(result['y_test'], result['y_pred'])\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax,\n",
    "                xticklabels=['Healthy', 'Disease'],\n",
    "                yticklabels=['Healthy', 'Disease'])\n",
    "    ax.set_ylabel('True Label')\n",
    "    ax.set_xlabel('Predicted Label')\n",
    "    ax.set_title(f'Confusion Matrix: {result[\"model_name\"]}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print detailed results\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DETAILED MODEL PERFORMANCE\")\n",
    "print(\"=\"*60)\n",
    "for result in results:\n",
    "    print(f\"\\n{result['model_name']}:\")\n",
    "    print(f\"  Cross-Validation AUC: {result['cv_auc_mean']:.3f} ¬± {result['cv_auc_std']:.3f}\")\n",
    "    print(f\"  Test Set AUC: {result['test_auc']:.3f}\")\n",
    "    print(\"\\n  Classification Report:\")\n",
    "    print(classification_report(result['y_test'], result['y_pred'], \n",
    "                                target_names=['Healthy', 'Disease']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "feature-importance"
   },
   "source": [
    "## 8. Feature Importance: Which Proteins Matter Most?\n",
    "\n",
    "Understanding **which proteins** drive the predictions helps with:\n",
    "- Biological interpretation\n",
    "- Biomarker discovery\n",
    "- Validating model decisions\n",
    "\n",
    "We'll examine feature importance from Random Forest (other models have different methods)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "feature-importance-analysis"
   },
   "outputs": [],
   "source": [
    "# Get Random Forest model\n",
    "rf_result = [r for r in results if 'Random Forest' in r['model_name']][0]\n",
    "rf_model = rf_result['model']\n",
    "\n",
    "# Get feature importances\n",
    "importances = rf_model.feature_importances_\n",
    "protein_names = df_batch_corrected.columns\n",
    "\n",
    "# Create DataFrame\n",
    "importance_df = pd.DataFrame({\n",
    "    'Protein': protein_names,\n",
    "    'Importance': importances\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "# Display top 20\n",
    "print(\"Top 20 Most Important Proteins:\")\n",
    "print(importance_df.head(20).to_string(index=False))\n",
    "\n",
    "# Visualize top 10\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Plot 1: Bar chart of top 15\n",
    "ax = axes[0]\n",
    "top_features = importance_df.head(15)\n",
    "ax.barh(range(len(top_features)), top_features['Importance'].values, alpha=0.7)\n",
    "ax.set_yticks(range(len(top_features)))\n",
    "ax.set_yticklabels(top_features['Protein'].values)\n",
    "ax.set_xlabel('Importance Score')\n",
    "ax.set_title('Top 15 Most Important Proteins')\n",
    "ax.invert_yaxis()\n",
    "ax.grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "# Plot 2: Cumulative importance\n",
    "ax = axes[1]\n",
    "cumulative_importance = np.cumsum(importance_df['Importance'].values)\n",
    "ax.plot(range(len(cumulative_importance)), cumulative_importance)\n",
    "ax.axhline(y=0.9, color='red', linestyle='--', label='90% of importance')\n",
    "ax.set_xlabel('Number of Proteins')\n",
    "ax.set_ylabel('Cumulative Importance')\n",
    "ax.set_title('Cumulative Feature Importance')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Find how many features explain 90% of importance\n",
    "n_features_90 = np.argmax(cumulative_importance >= 0.9) + 1\n",
    "ax.axvline(x=n_features_90, color='red', linestyle='--', alpha=0.5)\n",
    "ax.text(n_features_90, 0.5, f'{n_features_90} proteins\\nexplain 90%', \n",
    "        ha='left', va='center')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n‚úì {n_features_90} proteins explain 90% of the model's predictive power!\")\n",
    "print(f\"  (out of {len(protein_names)} total proteins)\")\n",
    "print(\"\\nThis suggests we could build a simpler model with fewer proteins!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "exercise-5"
   },
   "outputs": [],
   "source": [
    "# TODO: EXERCISE 5 - Visualize top 10 most important proteins\n",
    "#\n",
    "# Create boxplots showing expression levels of the top 10 proteins,\n",
    "# separated by disease status (Healthy vs Disease)\n",
    "#\n",
    "# Hints:\n",
    "# 1. Get top 10 protein names from importance_df\n",
    "# 2. Extract their expression values from df_batch_corrected\n",
    "# 3. Use seaborn.boxplot() or matplotlib to create side-by-side boxplots\n",
    "# 4. Color by disease status using metadata_cleaned\n",
    "#\n",
    "# Your code here:\n",
    "# top_10_proteins = importance_df.head(10)['Protein'].values\n",
    "# ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "student-exercises"
   },
   "source": [
    "## 9. Student Exercises\n",
    "\n",
    "Now it's your turn to experiment! Try these exercises to deepen your understanding.\n",
    "\n",
    "### Exercise 3: Feature Selection Before ML\n",
    "\n",
    "Instead of using all proteins, try selecting only the most informative ones before training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "exercise-3"
   },
   "outputs": [],
   "source": [
    "# TODO: EXERCISE 3 - Feature Selection\n",
    "#\n",
    "# Try these approaches:\n",
    "# 1. Use only top 50 proteins by variance (most variable across samples)\n",
    "# 2. Use SelectKBest from sklearn.feature_selection\n",
    "# 3. Compare model performance with all features vs selected features\n",
    "#\n",
    "# Hints:\n",
    "# - Calculate variance: df_batch_corrected.var(axis=0)\n",
    "# - SelectKBest: from sklearn.feature_selection import SelectKBest, f_classif\n",
    "# - Retrain models on reduced feature set\n",
    "#\n",
    "# Your code here:\n",
    "# from sklearn.feature_selection import SelectKBest, f_classif\n",
    "# ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "exercise-4-header"
   },
   "source": [
    "### Exercise 4: Different Train/Test Splits\n",
    "\n",
    "How does the train/test split ratio affect model performance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "exercise-4"
   },
   "outputs": [],
   "source": [
    "# TODO: EXERCISE 4 - Experiment with train/test splits\n",
    "#\n",
    "# Try different split ratios and compare results:\n",
    "# 1. 80/20 split\n",
    "# 2. 60/40 split  \n",
    "# 3. 50/50 split\n",
    "#\n",
    "# Questions to explore:\n",
    "# - How does test set performance change with less training data?\n",
    "# - Does cross-validation AUC differ significantly?\n",
    "# - What's the optimal split for this dataset size?\n",
    "#\n",
    "# Your code here:\n",
    "# test_sizes = [0.2, 0.4, 0.5]\n",
    "# for test_size in test_sizes:\n",
    "#     X_train, X_test, y_train, y_test = prepare_ml_data(df_batch_corrected, metadata_cleaned, test_size=test_size)\n",
    "#     ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "comparison"
   },
   "source": [
    "## 10. Impact Analysis: Why Preprocessing Matters\n",
    "\n",
    "### The Big Question: \n",
    "**What happens if we skip preprocessing steps?**\n",
    "\n",
    "Let's compare model performance with different preprocessing strategies:\n",
    "1. **No preprocessing**: Raw data with simple imputation\n",
    "2. **Only normalization**: Skip batch correction\n",
    "3. **Full pipeline**: All preprocessing steps\n",
    "\n",
    "This will show you **why each step matters**!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "comparison-analysis"
   },
   "outputs": [],
   "source": [
    "print(\"Comparing preprocessing strategies...\\n\")\n",
    "print(\"This may take a minute...\\n\")\n",
    "\n",
    "# Strategy 1: Minimal preprocessing (just impute, no normalization, no batch correction)\n",
    "df_minimal = df_filtered_both.copy()\n",
    "df_minimal = impute_data(df_minimal, method='mean')  # Simple mean imputation\n",
    "X_train_min, X_test_min, y_train_min, y_test_min = prepare_ml_data(df_minimal, metadata_cleaned)\n",
    "\n",
    "# Strategy 2: Normalization only (no batch correction)\n",
    "df_norm_only = zscore_normalize(df_cleaned)\n",
    "X_train_norm, X_test_norm, y_train_norm, y_test_norm = prepare_ml_data(df_norm_only, metadata_cleaned)\n",
    "\n",
    "# Strategy 3: Full pipeline (normalization + batch correction)\n",
    "X_train_full, X_test_full, y_train_full, y_test_full = X_train, X_test, y_train, y_test  # Already computed\n",
    "\n",
    "# Test all strategies with Random Forest (typically best performing)\n",
    "strategies = [\n",
    "    (\"Minimal (Raw + Mean Impute)\", X_train_min, X_test_min, y_train_min, y_test_min),\n",
    "    (\"Normalization Only\", X_train_norm, X_test_norm, y_train_norm, y_test_norm),\n",
    "    (\"Full Pipeline\", X_train_full, X_test_full, y_train_full, y_test_full)\n",
    "]\n",
    "\n",
    "strategy_results = []\n",
    "\n",
    "for strategy_name, X_tr, X_te, y_tr, y_te in strategies:\n",
    "    print(f\"Testing: {strategy_name}...\")\n",
    "    \n",
    "    # Train Random Forest\n",
    "    rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    result = evaluate_model(rf, X_tr, X_te, y_tr, y_te, strategy_name)\n",
    "    strategy_results.append(result)\n",
    "    \n",
    "    print(f\"  ‚úì Test AUC: {result['test_auc']:.3f}\\n\")\n",
    "\n",
    "# Visualize comparison\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Plot 1: AUC comparison\n",
    "ax = axes[0]\n",
    "strategy_names = [r['model_name'] for r in strategy_results]\n",
    "cv_aucs = [r['cv_auc_mean'] for r in strategy_results]\n",
    "test_aucs = [r['test_auc'] for r in strategy_results]\n",
    "\n",
    "x = np.arange(len(strategy_names))\n",
    "width = 0.35\n",
    "\n",
    "bars1 = ax.bar(x - width/2, cv_aucs, width, label='CV AUC', alpha=0.8)\n",
    "bars2 = ax.bar(x + width/2, test_aucs, width, label='Test AUC', alpha=0.8)\n",
    "\n",
    "ax.set_ylabel('AUC Score')\n",
    "ax.set_title('Impact of Preprocessing on Model Performance\\n(Random Forest)')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(strategy_names, rotation=15, ha='right')\n",
    "ax.legend()\n",
    "ax.set_ylim([0.5, 1.0])\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Add value labels on bars\n",
    "for bars in [bars1, bars2]:\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{height:.3f}', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "# Plot 2: ROC curves\n",
    "ax = axes[1]\n",
    "for result in strategy_results:\n",
    "    fpr, tpr, _ = roc_curve(result['y_test'], result['y_pred_proba'])\n",
    "    ax.plot(fpr, tpr, label=f\"{result['model_name']} (AUC={result['test_auc']:.3f})\", linewidth=2)\n",
    "ax.plot([0, 1], [0, 1], 'k--', label='Random', linewidth=1)\n",
    "ax.set_xlabel('False Positive Rate')\n",
    "ax.set_ylabel('True Positive Rate')\n",
    "ax.set_title('ROC Curves: Preprocessing Comparison')\n",
    "ax.legend(loc='lower right')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print summary\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"PREPROCESSING IMPACT SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "baseline_auc = strategy_results[0]['test_auc']\n",
    "for result in strategy_results:\n",
    "    improvement = result['test_auc'] - baseline_auc\n",
    "    print(f\"\\n{result['model_name']}:\")\n",
    "    print(f\"  Test AUC: {result['test_auc']:.3f}\")\n",
    "    print(f\"  Improvement over baseline: {improvement:+.3f} ({100*improvement/baseline_auc:+.1f}%)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"KEY TAKEAWAYS:\")\n",
    "print(\"=\"*70)\n",
    "print(\"1. Raw data performs poorly due to:\")\n",
    "print(\"   - Technical variation overwhelming biological signal\")\n",
    "print(\"   - Different protein scales confusing the model\")\n",
    "print(\"   - Batch effects creating false patterns\")\n",
    "print(\"\\n2. Normalization helps by:\")\n",
    "print(\"   - Making proteins comparable (same scale)\")\n",
    "print(\"   - Reducing technical noise\")\n",
    "print(\"\\n3. Batch correction is crucial:\")\n",
    "print(\"   - Removes systematic technical artifacts\")\n",
    "print(\"   - Reveals true biological differences\")\n",
    "print(\"\\n4. Full preprocessing pipeline maximizes:\")\n",
    "print(\"   - Predictive accuracy\")\n",
    "print(\"   - Biological interpretability\")\n",
    "print(\"   - Reproducibility across batches\")\n",
    "print(\"\\n‚ö†Ô∏è  NEVER skip preprocessing in real proteomics analysis!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "summary"
   },
   "source": [
    "## 11. Summary and Recommended Pipeline\n",
    "\n",
    "### What We Learned\n",
    "\n",
    "1. **Data Quality Issues** in proteomics are real and significant:\n",
    "   - Missing values (15-20% typical)\n",
    "   - Batch effects (can be larger than biology!)\n",
    "   - Outlier samples\n",
    "   - Different protein abundance levels\n",
    "\n",
    "2. **Preprocessing Steps Matter** - each improves results:\n",
    "   - Filtering unreliable proteins/samples\n",
    "   - KNN imputation > mean imputation\n",
    "   - Z-score normalization for cross-protein comparison\n",
    "   - Batch effect correction is critical\n",
    "\n",
    "3. **Model Selection**:\n",
    "   - Random Forest typically performs best\n",
    "   - All models benefit from proper preprocessing\n",
    "   - Feature importance reveals biological insights\n",
    "\n",
    "### Recommended Pipeline for Proteomics Data\n",
    "\n",
    "```\n",
    "Raw Data\n",
    "    ‚Üì\n",
    "Filter proteins (>50% missing)\n",
    "    ‚Üì\n",
    "Filter samples (>30% missing)\n",
    "    ‚Üì\n",
    "KNN imputation (k=5)\n",
    "    ‚Üì\n",
    "Z-score normalization\n",
    "    ‚Üì\n",
    "Batch effect correction\n",
    "    ‚Üì\n",
    "PCA visualization (QC check)\n",
    "    ‚Üì\n",
    "Machine Learning\n",
    "    ‚Üì\n",
    "Feature importance analysis\n",
    "```\n",
    "\n",
    "### Best Practices\n",
    "\n",
    "1. **Always visualize** before and after each step\n",
    "2. **Use cross-validation** to avoid overfitting\n",
    "3. **Check for batch effects** with PCA\n",
    "4. **Feature importance** helps biological interpretation\n",
    "5. **Compare multiple models** - no single best approach\n",
    "\n",
    "### Further Exploration\n",
    "\n",
    "Try these on real proteomics datasets:\n",
    "- **Advanced imputation**: MICE, missForest\n",
    "- **Advanced normalization**: ComBat, limma\n",
    "- **Feature selection**: LASSO, elastic net\n",
    "- **Deep learning**: neural networks for complex patterns\n",
    "- **Pathway analysis**: connect proteins to biological processes\n",
    "\n",
    "---\n",
    "\n",
    "## Congratulations! üéâ\n",
    "\n",
    "You've completed a full proteomics machine learning pipeline. These skills apply to:\n",
    "- RNA-seq analysis\n",
    "- Metabolomics\n",
    "- Clinical biomarker discovery\n",
    "- Any high-dimensional biological data\n",
    "\n",
    "**Remember:** In bioinformatics, **data quality determines results**. \n",
    "Spend time on preprocessing - it's not glamorous, but it's essential!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "final-notes"
   },
   "source": [
    "## Additional Resources\n",
    "\n",
    "### Python Libraries for Proteomics:\n",
    "- **pyteomics**: Proteomics data parsing\n",
    "- **biopython**: General bioinformatics\n",
    "- **scanpy**: Single-cell analysis (similar workflows)\n",
    "\n",
    "### Further Reading:\n",
    "- \"Normalization methods for proteomics data\" - review papers\n",
    "- ComBat batch correction documentation\n",
    "- sklearn documentation for machine learning\n",
    "\n",
    "### Next Steps:\n",
    "1. Try this pipeline on real proteomics data (e.g., from PRIDE database)\n",
    "2. Implement more sophisticated imputation methods\n",
    "3. Add pathway enrichment analysis\n",
    "4. Build a web app to share results\n",
    "\n",
    "---\n",
    "\n",
    "### Questions or Issues?\n",
    "\n",
    "If you encounter problems:\n",
    "1. Check that all cells ran in order (Runtime ‚Üí Run all)\n",
    "2. Verify random seed is set (ensures reproducibility)\n",
    "3. Try restarting runtime if issues persist\n",
    "\n",
    "Happy analyzing! üß¨üìä"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## End of Notebook ##"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Proteomics ML Exercise",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
