{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Decomposition Methods for RNA-Seq Data\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This notebook demonstrates four popular dimensionality reduction techniques used in bioinformatics:\n",
    "\n",
    "1. **PCA (Principal Component Analysis)** - Linear method for finding directions of maximum variance\n",
    "2. **ICA (Independent Component Analysis)** - Finds statistically independent components\n",
    "3. **t-SNE (t-Distributed Stochastic Neighbor Embedding)** - Nonlinear method for visualization\n",
    "4. **UMAP (Uniform Manifold Approximation and Projection)** - Fast nonlinear method preserving global structure\n",
    "\n",
    "We'll use simulated RNA-Seq data representing different cell types and conditions.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Libraries\n",
    "# ! pip install umap-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix to umap-learn import hanging (did not solve)\n",
    "# pip install --upgrade umap-learn numba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fix to install umap-learn import hanging \n",
    "#  Needed to do this to set up a conda env: (From Terminal before starting notebook)\n",
    "# conda create -n umap_env python=3.11 anaconda\n",
    "# conda activate umap_env\n",
    "# conda install -c conda-forge umap-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Notes ##\n",
    "# The conda-forge version of umap-learn typically doesn't have the threading issues that pip versions sometimes encounter on macOS."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimensionality reduction methods\n",
    "from sklearn.decomposition import PCA, FastICA\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# Try to import UMAP (can be slow on first import)\n",
    "print(\"Importing core libraries... ✓\")\n",
    "print(\"Importing sklearn methods... ✓\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "try:\n",
    "    print(\"Importing UMAP (this may take 10-30 seconds on first run)...\")\n",
    "    import umap\n",
    "    from umap import UMAP\n",
    "    UMAP_AVAILABLE = True\n",
    "    print(\"UMAP imported successfully! ✓\")\n",
    "except ImportError:\n",
    "    print(\"WARNING: UMAP not available. Install with: pip install umap-learn\")\n",
    "    print(\"Continuing without UMAP...\")\n",
    "    UMAP_AVAILABLE = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Plotting settings\n",
    "try:\n",
    "    plt.style.use('seaborn-v0_8-darkgrid')\n",
    "except:\n",
    "    plt.style.use('seaborn-darkgrid')\n",
    "    \n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"✓ All libraries imported successfully!\")\n",
    "print(\"=\"*60)\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "print(f\"Pandas version: {pd.__version__}\")\n",
    "print(f\"UMAP available: {UMAP_AVAILABLE}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 1: Generate Simulated RNA-Seq Data\n",
    "\n",
    "We'll create realistic RNA-Seq count data for different cell types:\n",
    "- **T-cells**: High immune response genes\n",
    "- **B-cells**: High antibody production genes\n",
    "- **Neurons**: High neurotransmitter genes\n",
    "- **Hepatocytes**: High metabolism genes\n",
    "\n",
    "Each cell type will have characteristic gene expression patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_rnaseq_data(n_samples_per_type=50, n_genes=2000, noise_level=0.3):\n",
    "    \"\"\"\n",
    "    Generate simulated RNA-Seq count data for different cell types.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    n_samples_per_type : int\n",
    "        Number of samples per cell type\n",
    "    n_genes : int\n",
    "        Total number of genes to simulate\n",
    "    noise_level : float\n",
    "        Amount of noise to add (0-1)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    counts_df : DataFrame\n",
    "        Gene expression counts (samples x genes)\n",
    "    metadata_df : DataFrame\n",
    "        Sample metadata with cell type labels\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define cell types\n",
    "    cell_types = ['T-cell', 'B-cell', 'Neuron', 'Hepatocyte']\n",
    "    n_types = len(cell_types)\n",
    "    n_samples = n_samples_per_type * n_types\n",
    "    \n",
    "    # Gene categories (genes per category)\n",
    "    genes_per_category = n_genes // 5\n",
    "    \n",
    "    # Initialize count matrix\n",
    "    counts = np.zeros((n_samples, n_genes))\n",
    "    \n",
    "    # Base expression (all cell types have some baseline expression)\n",
    "    baseline = np.random.negative_binomial(n=5, p=0.1, size=(n_samples, n_genes))\n",
    "    counts += baseline\n",
    "    \n",
    "    # Define gene sets with characteristic expression patterns\n",
    "    # Category 1: Immune genes (high in T-cells and B-cells)\n",
    "    immune_genes = slice(0, genes_per_category)\n",
    "    \n",
    "    # Category 2: Antibody genes (very high in B-cells)\n",
    "    antibody_genes = slice(genes_per_category, 2*genes_per_category)\n",
    "    \n",
    "    # Category 3: Neural genes (high in Neurons)\n",
    "    neural_genes = slice(2*genes_per_category, 3*genes_per_category)\n",
    "    \n",
    "    # Category 4: Metabolic genes (high in Hepatocytes)\n",
    "    metabolic_genes = slice(3*genes_per_category, 4*genes_per_category)\n",
    "    \n",
    "    # Category 5: Housekeeping genes (expressed in all)\n",
    "    housekeeping_genes = slice(4*genes_per_category, n_genes)\n",
    "    \n",
    "    # Add cell-type specific expression\n",
    "    for i, cell_type in enumerate(cell_types):\n",
    "        start_idx = i * n_samples_per_type\n",
    "        end_idx = (i + 1) * n_samples_per_type\n",
    "        \n",
    "        if cell_type == 'T-cell':\n",
    "            # High immune gene expression\n",
    "            counts[start_idx:end_idx, immune_genes] += np.random.negative_binomial(\n",
    "                n=20, p=0.2, size=(n_samples_per_type, genes_per_category)\n",
    "            )\n",
    "            # Moderate antibody genes\n",
    "            counts[start_idx:end_idx, antibody_genes] += np.random.negative_binomial(\n",
    "                n=10, p=0.3, size=(n_samples_per_type, genes_per_category)\n",
    "            )\n",
    "            \n",
    "        elif cell_type == 'B-cell':\n",
    "            # High immune gene expression\n",
    "            counts[start_idx:end_idx, immune_genes] += np.random.negative_binomial(\n",
    "                n=15, p=0.2, size=(n_samples_per_type, genes_per_category)\n",
    "            )\n",
    "            # Very high antibody genes\n",
    "            counts[start_idx:end_idx, antibody_genes] += np.random.negative_binomial(\n",
    "                n=30, p=0.15, size=(n_samples_per_type, genes_per_category)\n",
    "            )\n",
    "            \n",
    "        elif cell_type == 'Neuron':\n",
    "            # Very high neural gene expression\n",
    "            counts[start_idx:end_idx, neural_genes] += np.random.negative_binomial(\n",
    "                n=25, p=0.15, size=(n_samples_per_type, genes_per_category)\n",
    "            )\n",
    "            # Some metabolic genes\n",
    "            counts[start_idx:end_idx, metabolic_genes] += np.random.negative_binomial(\n",
    "                n=8, p=0.3, size=(n_samples_per_type, genes_per_category)\n",
    "            )\n",
    "            \n",
    "        elif cell_type == 'Hepatocyte':\n",
    "            # Very high metabolic gene expression\n",
    "            counts[start_idx:end_idx, metabolic_genes] += np.random.negative_binomial(\n",
    "                n=35, p=0.1, size=(n_samples_per_type, genes_per_category)\n",
    "            )\n",
    "    \n",
    "    # Add housekeeping genes (moderate expression in all cells)\n",
    "    counts[:, housekeeping_genes] += np.random.negative_binomial(\n",
    "        n=12, p=0.25, size=(n_samples, n_genes - 4*genes_per_category)\n",
    "    )\n",
    "    \n",
    "    # Add noise\n",
    "    noise = np.random.poisson(\n",
    "        lam=noise_level * counts\n",
    "    )\n",
    "    counts = counts + noise\n",
    "    \n",
    "    # Create gene names\n",
    "    gene_names = []\n",
    "    gene_names += [f\"IMMUNE_{i+1:03d}\" for i in range(genes_per_category)]\n",
    "    gene_names += [f\"ANTIBODY_{i+1:03d}\" for i in range(genes_per_category)]\n",
    "    gene_names += [f\"NEURAL_{i+1:03d}\" for i in range(genes_per_category)]\n",
    "    gene_names += [f\"METABOLIC_{i+1:03d}\" for i in range(genes_per_category)]\n",
    "    gene_names += [f\"HOUSEKEEP_{i+1:03d}\" for i in range(n_genes - 4*genes_per_category)]\n",
    "    \n",
    "    # Create sample names and metadata\n",
    "    sample_names = []\n",
    "    cell_type_labels = []\n",
    "    \n",
    "    for i, cell_type in enumerate(cell_types):\n",
    "        for j in range(n_samples_per_type):\n",
    "            sample_names.append(f\"{cell_type}_{j+1:02d}\")\n",
    "            cell_type_labels.append(cell_type)\n",
    "    \n",
    "    # Create DataFrames\n",
    "    counts_df = pd.DataFrame(\n",
    "        counts,\n",
    "        index=sample_names,\n",
    "        columns=gene_names\n",
    "    )\n",
    "    \n",
    "    metadata_df = pd.DataFrame({\n",
    "        'sample_id': sample_names,\n",
    "        'cell_type': cell_type_labels,\n",
    "        'batch': np.random.choice(['Batch1', 'Batch2'], size=n_samples)\n",
    "    })\n",
    "    \n",
    "    return counts_df, metadata_df\n",
    "\n",
    "# Generate data\n",
    "print(\"Generating simulated RNA-Seq data...\")\n",
    "counts_df, metadata_df = generate_rnaseq_data(\n",
    "    n_samples_per_type=50,\n",
    "    n_genes=2000,\n",
    "    noise_level=0.3\n",
    ")\n",
    "\n",
    "print(f\"\\nData shape: {counts_df.shape}\")\n",
    "print(f\"Samples: {counts_df.shape[0]}\")\n",
    "print(f\"Genes: {counts_df.shape[1]}\")\n",
    "print(f\"\\nCell type distribution:\")\n",
    "print(metadata_df['cell_type'].value_counts())\n",
    "print(f\"\\nFirst few samples:\")\n",
    "display(counts_df.iloc[:5, :10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Raw Data Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot library size distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Total counts per sample\n",
    "library_sizes = counts_df.sum(axis=1)\n",
    "axes[0].hist(library_sizes, bins=30, edgecolor='black', alpha=0.7)\n",
    "axes[0].set_xlabel('Total Read Count per Sample', fontsize=12)\n",
    "axes[0].set_ylabel('Frequency', fontsize=12)\n",
    "axes[0].set_title('Library Size Distribution', fontsize=14, fontweight='bold')\n",
    "axes[0].axvline(library_sizes.mean(), color='red', linestyle='--', \n",
    "                label=f'Mean: {library_sizes.mean():.0f}')\n",
    "axes[0].legend()\n",
    "\n",
    "# Mean expression per gene\n",
    "mean_expression = counts_df.mean(axis=0)\n",
    "axes[1].hist(np.log10(mean_expression + 1), bins=50, edgecolor='black', alpha=0.7)\n",
    "axes[1].set_xlabel('log10(Mean Expression + 1)', fontsize=12)\n",
    "axes[1].set_ylabel('Frequency', fontsize=12)\n",
    "axes[1].set_title('Gene Expression Distribution', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Library size range: {library_sizes.min():.0f} - {library_sizes.max():.0f}\")\n",
    "print(f\"Mean library size: {library_sizes.mean():.0f} ± {library_sizes.std():.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 2: Data Preprocessing\n",
    "\n",
    "Before applying dimensionality reduction, we need to preprocess RNA-Seq data:\n",
    "\n",
    "1. **Log transformation**: RNA-Seq counts are log-normally distributed\n",
    "2. **Feature selection**: Select highly variable genes\n",
    "3. **Standardization**: Scale features for PCA/ICA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_rnaseq(counts_df, n_top_genes=500):\n",
    "    \"\"\"\n",
    "    Preprocess RNA-Seq data for dimensionality reduction.\n",
    "    \n",
    "    Steps:\n",
    "    1. Log transformation: log2(counts + 1)\n",
    "    2. Select highly variable genes\n",
    "    3. Standardize (z-score normalization)\n",
    "    \"\"\"\n",
    "    print(\"Preprocessing RNA-Seq data...\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Step 1: Log transformation\n",
    "    log_counts = np.log2(counts_df + 1)\n",
    "    print(f\"1. Log transformation applied: log2(counts + 1)\")\n",
    "    \n",
    "    # Step 2: Select highly variable genes\n",
    "    # Calculate coefficient of variation for each gene\n",
    "    gene_means = log_counts.mean(axis=0)\n",
    "    gene_vars = log_counts.var(axis=0)\n",
    "    gene_cv = gene_vars / (gene_means + 1e-10)  # Avoid division by zero\n",
    "    \n",
    "    # Select top N most variable genes\n",
    "    top_genes = gene_cv.nlargest(n_top_genes).index\n",
    "    log_counts_hvg = log_counts[top_genes]\n",
    "    \n",
    "    print(f\"2. Selected {n_top_genes} highly variable genes\")\n",
    "    print(f\"   Original genes: {counts_df.shape[1]}\")\n",
    "    print(f\"   Selected genes: {log_counts_hvg.shape[1]}\")\n",
    "    \n",
    "    # Step 3: Standardization (z-score)\n",
    "    scaler = StandardScaler()\n",
    "    data_scaled = scaler.fit_transform(log_counts_hvg)\n",
    "    data_scaled_df = pd.DataFrame(\n",
    "        data_scaled,\n",
    "        index=log_counts_hvg.index,\n",
    "        columns=log_counts_hvg.columns\n",
    "    )\n",
    "    \n",
    "    print(f\"3. Standardization applied (mean=0, std=1)\")\n",
    "    print(f\"   Mean: {data_scaled.mean():.2e}\")\n",
    "    print(f\"   Std: {data_scaled.std():.2f}\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    return data_scaled_df, log_counts_hvg\n",
    "\n",
    "# Preprocess data\n",
    "data_scaled, log_counts_hvg = preprocess_rnaseq(counts_df, n_top_genes=500)\n",
    "\n",
    "print(f\"\\nFinal preprocessed data shape: {data_scaled.shape}\")\n",
    "print(f\"Ready for dimensionality reduction!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 3: Principal Component Analysis (PCA)\n",
    "\n",
    "### What is PCA?\n",
    "\n",
    "**Principal Component Analysis (PCA)** is a linear dimensionality reduction technique that:\n",
    "- Finds orthogonal directions (principal components) of maximum variance\n",
    "- Projects data onto these components\n",
    "- Is deterministic and fast\n",
    "\n",
    "### When to use PCA:\n",
    "- **Fast exploration** of high-dimensional data\n",
    "- **Linear relationships** are important\n",
    "- Need **interpretable components** (loadings)\n",
    "- Want to **preserve global structure**\n",
    "\n",
    "### Advantages:\n",
    "- Fast and scalable\n",
    "- Deterministic (same result every run)\n",
    "- Interpretable (loadings show gene contributions)\n",
    "- Preserves global distances\n",
    "\n",
    "### Disadvantages:\n",
    "- Linear method (may miss nonlinear patterns)\n",
    "- Assumes variance = importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply PCA\n",
    "print(\"Applying PCA...\")\n",
    "pca = PCA(n_components=50, random_state=42)\n",
    "pca_result = pca.fit_transform(data_scaled)\n",
    "\n",
    "# Create DataFrame with PCA results\n",
    "pca_df = pd.DataFrame(\n",
    "    pca_result[:, :10],  # First 10 components\n",
    "    columns=[f'PC{i+1}' for i in range(10)],\n",
    "    index=data_scaled.index\n",
    ")\n",
    "pca_df['cell_type'] = metadata_df['cell_type'].values\n",
    "\n",
    "print(f\"PCA completed!\")\n",
    "print(f\"Shape: {pca_result.shape}\")\n",
    "print(f\"\\nVariance explained by first 10 components:\")\n",
    "for i in range(10):\n",
    "    print(f\"  PC{i+1}: {pca.explained_variance_ratio_[i]*100:.2f}%\")\n",
    "print(f\"\\nTotal variance explained (first 10 PCs): {pca.explained_variance_ratio_[:10].sum()*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize PCA Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive PCA visualization\n",
    "fig = plt.figure(figsize=(16, 10))\n",
    "gs = fig.add_gridspec(2, 3, hspace=0.3, wspace=0.3)\n",
    "\n",
    "# 1. Scree plot (explained variance)\n",
    "ax1 = fig.add_subplot(gs[0, 0])\n",
    "ax1.plot(range(1, 21), pca.explained_variance_ratio_[:20], 'bo-', linewidth=2, markersize=8)\n",
    "ax1.set_xlabel('Principal Component', fontsize=12)\n",
    "ax1.set_ylabel('Explained Variance Ratio', fontsize=12)\n",
    "ax1.set_title('Scree Plot', fontsize=14, fontweight='bold')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Cumulative variance explained\n",
    "ax2 = fig.add_subplot(gs[0, 1])\n",
    "cumsum = np.cumsum(pca.explained_variance_ratio_[:20])\n",
    "ax2.plot(range(1, 21), cumsum, 'ro-', linewidth=2, markersize=8)\n",
    "ax2.axhline(y=0.9, color='green', linestyle='--', label='90% variance')\n",
    "ax2.set_xlabel('Number of Components', fontsize=12)\n",
    "ax2.set_ylabel('Cumulative Variance Explained', fontsize=12)\n",
    "ax2.set_title('Cumulative Variance', fontsize=14, fontweight='bold')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# 3. PC1 vs PC2 scatter plot\n",
    "ax3 = fig.add_subplot(gs[0, 2])\n",
    "cell_types = pca_df['cell_type'].unique()\n",
    "colors = plt.cm.Set2(np.linspace(0, 1, len(cell_types)))\n",
    "\n",
    "for cell_type, color in zip(cell_types, colors):\n",
    "    mask = pca_df['cell_type'] == cell_type\n",
    "    ax3.scatter(pca_df.loc[mask, 'PC1'], pca_df.loc[mask, 'PC2'],\n",
    "               label=cell_type, alpha=0.6, s=80, color=color, edgecolors='black', linewidth=0.5)\n",
    "\n",
    "ax3.set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]*100:.1f}%)', fontsize=12)\n",
    "ax3.set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]*100:.1f}%)', fontsize=12)\n",
    "ax3.set_title('PCA: PC1 vs PC2', fontsize=14, fontweight='bold')\n",
    "ax3.legend(loc='best', frameon=True, shadow=True)\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# 4. PC1 vs PC3 scatter plot\n",
    "ax4 = fig.add_subplot(gs[1, 0])\n",
    "for cell_type, color in zip(cell_types, colors):\n",
    "    mask = pca_df['cell_type'] == cell_type\n",
    "    ax4.scatter(pca_df.loc[mask, 'PC1'], pca_df.loc[mask, 'PC3'],\n",
    "               label=cell_type, alpha=0.6, s=80, color=color, edgecolors='black', linewidth=0.5)\n",
    "\n",
    "ax4.set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]*100:.1f}%)', fontsize=12)\n",
    "ax4.set_ylabel(f'PC3 ({pca.explained_variance_ratio_[2]*100:.1f}%)', fontsize=12)\n",
    "ax4.set_title('PCA: PC1 vs PC3', fontsize=14, fontweight='bold')\n",
    "ax4.legend(loc='best', frameon=True, shadow=True)\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "# 5. PC2 vs PC3 scatter plot\n",
    "ax5 = fig.add_subplot(gs[1, 1])\n",
    "for cell_type, color in zip(cell_types, colors):\n",
    "    mask = pca_df['cell_type'] == cell_type\n",
    "    ax5.scatter(pca_df.loc[mask, 'PC2'], pca_df.loc[mask, 'PC3'],\n",
    "               label=cell_type, alpha=0.6, s=80, color=color, edgecolors='black', linewidth=0.5)\n",
    "\n",
    "ax5.set_xlabel(f'PC2 ({pca.explained_variance_ratio_[1]*100:.1f}%)', fontsize=12)\n",
    "ax5.set_ylabel(f'PC3 ({pca.explained_variance_ratio_[2]*100:.1f}%)', fontsize=12)\n",
    "ax5.set_title('PCA: PC2 vs PC3', fontsize=14, fontweight='bold')\n",
    "ax5.legend(loc='best', frameon=True, shadow=True)\n",
    "ax5.grid(True, alpha=0.3)\n",
    "\n",
    "# 6. Top gene loadings for PC1\n",
    "ax6 = fig.add_subplot(gs[1, 2])\n",
    "loadings_pc1 = pd.Series(pca.components_[0], index=data_scaled.columns)\n",
    "top_genes_pc1 = loadings_pc1.abs().nlargest(15)\n",
    "top_loadings = loadings_pc1[top_genes_pc1.index].sort_values()\n",
    "\n",
    "colors_bar = ['red' if x < 0 else 'blue' for x in top_loadings.values]\n",
    "ax6.barh(range(len(top_loadings)), top_loadings.values, color=colors_bar, alpha=0.7, edgecolor='black')\n",
    "ax6.set_yticks(range(len(top_loadings)))\n",
    "ax6.set_yticklabels(top_loadings.index, fontsize=9)\n",
    "ax6.set_xlabel('Loading Value', fontsize=12)\n",
    "ax6.set_title('Top 15 Genes Contributing to PC1', fontsize=14, fontweight='bold')\n",
    "ax6.axvline(x=0, color='black', linestyle='--', linewidth=1)\n",
    "ax6.grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "plt.suptitle('Principal Component Analysis (PCA) - Comprehensive View', \n",
    "             fontsize=16, fontweight='bold', y=0.995)\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nPCA Interpretation:\")\n",
    "print(f\"- Cell types form distinct clusters in PC space\")\n",
    "print(f\"- First 3 PCs capture {cumsum[2]*100:.1f}% of total variance\")\n",
    "print(f\"- Gene loadings show which genes drive each PC\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 4: Independent Component Analysis (ICA)\n",
    "\n",
    "### What is ICA?\n",
    "\n",
    "**Independent Component Analysis (ICA)** is a computational method that:\n",
    "- Separates a multivariate signal into independent non-Gaussian signals\n",
    "- Assumes observed data is a linear mixture of independent sources\n",
    "- Maximizes statistical independence (not just orthogonality like PCA)\n",
    "\n",
    "### When to use ICA:\n",
    "- **Identifying biological processes**: Gene programs, regulatory modules\n",
    "- **Signal separation**: Separate technical and biological variation\n",
    "- **Finding hidden factors**: Independent biological processes\n",
    "\n",
    "### ICA vs PCA:\n",
    "- **PCA**: Finds orthogonal components with maximum variance\n",
    "- **ICA**: Finds statistically independent components\n",
    "\n",
    "### Advantages:\n",
    "- Captures non-Gaussian structure\n",
    "- Identifies independent biological processes\n",
    "- Can separate overlapping signals\n",
    "\n",
    "### Disadvantages:\n",
    "- Non-deterministic (different runs may differ slightly)\n",
    "- Harder to interpret than PCA\n",
    "- No inherent ordering of components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply ICA\n",
    "print(\"Applying ICA...\")\n",
    "ica = FastICA(n_components=10, random_state=42, max_iter=1000, tol=0.001)\n",
    "ica_result = ica.fit_transform(data_scaled)\n",
    "\n",
    "# Create DataFrame with ICA results\n",
    "ica_df = pd.DataFrame(\n",
    "    ica_result,\n",
    "    columns=[f'IC{i+1}' for i in range(10)],\n",
    "    index=data_scaled.index\n",
    ")\n",
    "ica_df['cell_type'] = metadata_df['cell_type'].values\n",
    "\n",
    "print(f\"ICA completed!\")\n",
    "print(f\"Shape: {ica_result.shape}\")\n",
    "print(f\"Components shape: {ica.components_.shape}\")\n",
    "\n",
    "# Calculate component statistics\n",
    "print(f\"\\nComponent statistics:\")\n",
    "for i in range(5):\n",
    "    print(f\"  IC{i+1}: mean={ica_result[:, i].mean():.3f}, \"\n",
    "          f\"std={ica_result[:, i].std():.3f}, \"\n",
    "          f\"kurtosis={stats.kurtosis(ica_result[:, i]):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize ICA Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive ICA visualization\n",
    "fig = plt.figure(figsize=(16, 10))\n",
    "gs = fig.add_gridspec(2, 3, hspace=0.3, wspace=0.3)\n",
    "\n",
    "# 1. IC1 vs IC2 scatter plot\n",
    "ax1 = fig.add_subplot(gs[0, 0])\n",
    "for cell_type, color in zip(cell_types, colors):\n",
    "    mask = ica_df['cell_type'] == cell_type\n",
    "    ax1.scatter(ica_df.loc[mask, 'IC1'], ica_df.loc[mask, 'IC2'],\n",
    "               label=cell_type, alpha=0.6, s=80, color=color, edgecolors='black', linewidth=0.5)\n",
    "\n",
    "ax1.set_xlabel('IC1', fontsize=12)\n",
    "ax1.set_ylabel('IC2', fontsize=12)\n",
    "ax1.set_title('ICA: IC1 vs IC2', fontsize=14, fontweight='bold')\n",
    "ax1.legend(loc='best', frameon=True, shadow=True)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# 2. IC1 vs IC3 scatter plot\n",
    "ax2 = fig.add_subplot(gs[0, 1])\n",
    "for cell_type, color in zip(cell_types, colors):\n",
    "    mask = ica_df['cell_type'] == cell_type\n",
    "    ax2.scatter(ica_df.loc[mask, 'IC1'], ica_df.loc[mask, 'IC3'],\n",
    "               label=cell_type, alpha=0.6, s=80, color=color, edgecolors='black', linewidth=0.5)\n",
    "\n",
    "ax2.set_xlabel('IC1', fontsize=12)\n",
    "ax2.set_ylabel('IC3', fontsize=12)\n",
    "ax2.set_title('ICA: IC1 vs IC3', fontsize=14, fontweight='bold')\n",
    "ax2.legend(loc='best', frameon=True, shadow=True)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# 3. IC2 vs IC3 scatter plot\n",
    "ax3 = fig.add_subplot(gs[0, 2])\n",
    "for cell_type, color in zip(cell_types, colors):\n",
    "    mask = ica_df['cell_type'] == cell_type\n",
    "    ax3.scatter(ica_df.loc[mask, 'IC2'], ica_df.loc[mask, 'IC3'],\n",
    "               label=cell_type, alpha=0.6, s=80, color=color, edgecolors='black', linewidth=0.5)\n",
    "\n",
    "ax3.set_xlabel('IC2', fontsize=12)\n",
    "ax3.set_ylabel('IC3', fontsize=12)\n",
    "ax3.set_title('ICA: IC2 vs IC3', fontsize=14, fontweight='bold')\n",
    "ax3.legend(loc='best', frameon=True, shadow=True)\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# 4. Component distributions (kurtosis)\n",
    "ax4 = fig.add_subplot(gs[1, 0])\n",
    "kurtosis_values = [stats.kurtosis(ica_result[:, i]) for i in range(10)]\n",
    "ax4.bar(range(1, 11), kurtosis_values, color='steelblue', alpha=0.7, edgecolor='black')\n",
    "ax4.set_xlabel('Independent Component', fontsize=12)\n",
    "ax4.set_ylabel('Kurtosis', fontsize=12)\n",
    "ax4.set_title('Component Kurtosis (Non-Gaussianity)', fontsize=14, fontweight='bold')\n",
    "ax4.axhline(y=0, color='red', linestyle='--', label='Gaussian')\n",
    "ax4.legend()\n",
    "ax4.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# 5. Top gene weights for IC1\n",
    "ax5 = fig.add_subplot(gs[1, 1])\n",
    "weights_ic1 = pd.Series(ica.components_[0], index=data_scaled.columns)\n",
    "top_genes_ic1 = weights_ic1.abs().nlargest(15)\n",
    "top_weights = weights_ic1[top_genes_ic1.index].sort_values()\n",
    "\n",
    "colors_bar = ['red' if x < 0 else 'blue' for x in top_weights.values]\n",
    "ax5.barh(range(len(top_weights)), top_weights.values, color=colors_bar, alpha=0.7, edgecolor='black')\n",
    "ax5.set_yticks(range(len(top_weights)))\n",
    "ax5.set_yticklabels(top_weights.index, fontsize=9)\n",
    "ax5.set_xlabel('Component Weight', fontsize=12)\n",
    "ax5.set_title('Top 15 Genes in IC1', fontsize=14, fontweight='bold')\n",
    "ax5.axvline(x=0, color='black', linestyle='--', linewidth=1)\n",
    "ax5.grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "# 6. Comparison: PCA vs ICA (first 2 components)\n",
    "ax6 = fig.add_subplot(gs[1, 2])\n",
    "ax6.scatter(pca_result[:, 0], ica_result[:, 0], alpha=0.5, s=50, c='purple', edgecolors='black', linewidth=0.5)\n",
    "ax6.set_xlabel('PC1 (PCA)', fontsize=12)\n",
    "ax6.set_ylabel('IC1 (ICA)', fontsize=12)\n",
    "ax6.set_title('PCA vs ICA: First Components', fontsize=14, fontweight='bold')\n",
    "ax6.grid(True, alpha=0.3)\n",
    "\n",
    "# Add correlation\n",
    "correlation = np.corrcoef(pca_result[:, 0], ica_result[:, 0])[0, 1]\n",
    "ax6.text(0.05, 0.95, f'Correlation: {correlation:.3f}',\n",
    "        transform=ax6.transAxes, fontsize=11,\n",
    "        verticalalignment='top', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "\n",
    "plt.suptitle('Independent Component Analysis (ICA) - Comprehensive View', \n",
    "             fontsize=16, fontweight='bold', y=0.995)\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nICA Interpretation:\")\n",
    "print(f\"- ICA identifies statistically independent sources\")\n",
    "print(f\"- Components with high kurtosis are more non-Gaussian (super/sub-Gaussian)\")\n",
    "print(f\"- Gene weights reveal independent biological processes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 5: t-SNE (t-Distributed Stochastic Neighbor Embedding)\n",
    "\n",
    "### What is t-SNE?\n",
    "\n",
    "**t-SNE** is a nonlinear dimensionality reduction technique that:\n",
    "- Preserves local neighborhood structure\n",
    "- Converts similarities between points to joint probabilities\n",
    "- Minimizes divergence between high-D and low-D probability distributions\n",
    "\n",
    "### When to use t-SNE:\n",
    "- **Visualization**: Create 2D/3D plots for exploratory analysis\n",
    "- **Cluster discovery**: Reveal hidden patterns and groupings\n",
    "- **Publication figures**: Beautiful, informative visualizations\n",
    "\n",
    "### Key Parameters:\n",
    "- **perplexity**: Balance between local and global structure (5-50)\n",
    "- **n_iter**: Number of iterations (1000-5000)\n",
    "- **learning_rate**: Step size (10-1000)\n",
    "\n",
    "### Advantages:\n",
    "- Excellent for visualization\n",
    "- Reveals local structure and clusters\n",
    "- Handles nonlinear relationships\n",
    "\n",
    "### Disadvantages:\n",
    "- Computationally expensive (slow for large datasets)\n",
    "- Non-deterministic (different runs give different results)\n",
    "- Distances between clusters are not meaningful\n",
    "- Cannot be applied to new data (no transform method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply t-SNE with different perplexity values\n",
    "print(\"Applying t-SNE with different parameters...\")\n",
    "print(\"This may take a few minutes...\\n\")\n",
    "\n",
    "perplexity_values = [5, 30, 50]\n",
    "tsne_results = {}\n",
    "\n",
    "for perp in perplexity_values:\n",
    "    print(f\"Running t-SNE with perplexity={perp}...\")\n",
    "    tsne = TSNE(\n",
    "        n_components=2,\n",
    "        perplexity=perp,\n",
    "        max_iter=1000,  # Fixed: changed from n_iter to max_iter for sklearn 1.7+\n",
    "        random_state=42,\n",
    "        verbose=0\n",
    "    )\n",
    "    tsne_result = tsne.fit_transform(data_scaled)\n",
    "    tsne_results[perp] = tsne_result\n",
    "    print(f\"  KL divergence: {tsne.kl_divergence_:.4f}\")\n",
    "\n",
    "print(\"\\nt-SNE completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize t-SNE Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive t-SNE visualization\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Plot t-SNE results with different perplexities\n",
    "for idx, (perp, tsne_result) in enumerate(tsne_results.items()):\n",
    "    ax = axes[idx]\n",
    "    \n",
    "    for cell_type, color in zip(cell_types, colors):\n",
    "        mask = metadata_df['cell_type'] == cell_type\n",
    "        ax.scatter(tsne_result[mask, 0], tsne_result[mask, 1],\n",
    "                  label=cell_type, alpha=0.6, s=80, color=color, \n",
    "                  edgecolors='black', linewidth=0.5)\n",
    "    \n",
    "    ax.set_xlabel('t-SNE 1', fontsize=12)\n",
    "    ax.set_ylabel('t-SNE 2', fontsize=12)\n",
    "    ax.set_title(f't-SNE (perplexity={perp})', fontsize=14, fontweight='bold')\n",
    "    ax.legend(loc='best', frameon=True, shadow=True)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Compare with PCA (for reference)\n",
    "ax = axes[3]\n",
    "for cell_type, color in zip(cell_types, colors):\n",
    "    mask = pca_df['cell_type'] == cell_type\n",
    "    ax.scatter(pca_df.loc[mask, 'PC1'], pca_df.loc[mask, 'PC2'],\n",
    "              label=cell_type, alpha=0.6, s=80, color=color, \n",
    "              edgecolors='black', linewidth=0.5)\n",
    "\n",
    "ax.set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]*100:.1f}%)', fontsize=12)\n",
    "ax.set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]*100:.1f}%)', fontsize=12)\n",
    "ax.set_title('PCA (for comparison)', fontsize=14, fontweight='bold')\n",
    "ax.legend(loc='best', frameon=True, shadow=True)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Large t-SNE plot (perplexity=30)\n",
    "ax = axes[4]\n",
    "tsne_result = tsne_results[30]\n",
    "\n",
    "for cell_type, color in zip(cell_types, colors):\n",
    "    mask = metadata_df['cell_type'] == cell_type\n",
    "    ax.scatter(tsne_result[mask, 0], tsne_result[mask, 1],\n",
    "              label=cell_type, alpha=0.7, s=120, color=color, \n",
    "              edgecolors='black', linewidth=0.8)\n",
    "\n",
    "ax.set_xlabel('t-SNE 1', fontsize=14, fontweight='bold')\n",
    "ax.set_ylabel('t-SNE 2', fontsize=14, fontweight='bold')\n",
    "ax.set_title('t-SNE: Best Result (perplexity=30)', fontsize=16, fontweight='bold')\n",
    "ax.legend(loc='best', frameon=True, shadow=True, fontsize=11)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Effect of perplexity\n",
    "ax = axes[5]\n",
    "perplexities = list(tsne_results.keys())\n",
    "ax.bar(range(len(perplexities)), [5, 30, 50], color='steelblue', alpha=0.7, edgecolor='black')\n",
    "ax.set_xticks(range(len(perplexities)))\n",
    "ax.set_xticklabels([f'Perp={p}' for p in perplexities])\n",
    "ax.set_ylabel('Perplexity Value', fontsize=12)\n",
    "ax.set_title('Perplexity Parameter Effect', fontsize=14, fontweight='bold')\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Add text explanation\n",
    "ax.text(0.5, 0.5, 'Perplexity controls\\nlocal vs global structure\\n\\nLow: focuses on local\\nHigh: preserves global',\n",
    "       transform=ax.transAxes, fontsize=11, ha='center', va='center',\n",
    "       bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "\n",
    "plt.suptitle('t-SNE Analysis - Effect of Parameters', \n",
    "             fontsize=18, fontweight='bold', y=0.995)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nt-SNE Interpretation:\")\n",
    "print(f\"- Perplexity affects cluster separation and structure\")\n",
    "print(f\"- Low perplexity: emphasizes local neighborhoods (may fragment clusters)\")\n",
    "print(f\"- High perplexity: preserves more global structure\")\n",
    "print(f\"- t-SNE excels at revealing cluster structure for visualization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 6: UMAP (Uniform Manifold Approximation and Projection)\n",
    "\n",
    "### What is UMAP?\n",
    "\n",
    "**UMAP** is a modern nonlinear dimensionality reduction technique that:\n",
    "- Preserves both local and global structure\n",
    "- Uses manifold learning and topological data analysis\n",
    "- Is much faster than t-SNE\n",
    "- Can be applied to new data (has transform method)\n",
    "\n",
    "### When to use UMAP:\n",
    "- **Fast visualization** of large datasets\n",
    "- **Better preservation** of global structure than t-SNE\n",
    "- **Downstream analysis**: Can use reduced dimensions for clustering\n",
    "- **New data**: Can transform new samples without retraining\n",
    "\n",
    "### Key Parameters:\n",
    "- **n_neighbors**: Size of local neighborhood (2-100)\n",
    "- **min_dist**: Minimum distance between points (0.0-0.99)\n",
    "- **metric**: Distance metric (euclidean, correlation, etc.)\n",
    "\n",
    "### Advantages:\n",
    "- Faster than t-SNE\n",
    "- Preserves global structure better\n",
    "- Can transform new data\n",
    "- Scales to larger datasets\n",
    "\n",
    "### Disadvantages:\n",
    "- Newer method (less established)\n",
    "- Still has stochastic elements\n",
    "- Parameter tuning needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if UMAP is available\n",
    "if not UMAP_AVAILABLE:\n",
    "    print(\"=\"*60)\n",
    "    print(\"UMAP not available - skipping this section\")\n",
    "    print(\"To install UMAP, run: pip install umap-learn\")\n",
    "    print(\"=\"*60)\n",
    "else:\n",
    "    # Apply UMAP with different parameters\n",
    "    print(\"Applying UMAP with different parameters...\")\n",
    "    print(\"This is much faster than t-SNE!\\n\")\n",
    "    \n",
    "    n_neighbors_values = [5, 15, 50]\n",
    "    umap_results = {}\n",
    "    \n",
    "    for n_neighbors in n_neighbors_values:\n",
    "        print(f\"Running UMAP with n_neighbors={n_neighbors}...\")\n",
    "        umap_model = UMAP(\n",
    "            n_components=2,\n",
    "            n_neighbors=n_neighbors,\n",
    "            min_dist=0.1,\n",
    "            metric='euclidean',\n",
    "            random_state=42,\n",
    "            verbose=False\n",
    "        )\n",
    "        umap_result = umap_model.fit_transform(data_scaled)\n",
    "        umap_results[n_neighbors] = umap_result\n",
    "        print(f\"  Completed!\")\n",
    "    \n",
    "    print(\"\\nUMAP completed!\")\n",
    "    \n",
    "    # Also create UMAP with different min_dist\n",
    "    print(\"\\nRunning UMAP with different min_dist values...\")\n",
    "    min_dist_values = [0.0, 0.5, 0.99]\n",
    "    umap_results_dist = {}\n",
    "    \n",
    "    for min_dist in min_dist_values:\n",
    "        print(f\"Running UMAP with min_dist={min_dist}...\")\n",
    "        umap_model = UMAP(\n",
    "            n_components=2,\n",
    "            n_neighbors=15,\n",
    "            min_dist=min_dist,\n",
    "            metric='euclidean',\n",
    "            random_state=42,\n",
    "            verbose=False\n",
    "        )\n",
    "        umap_result = umap_model.fit_transform(data_scaled)\n",
    "        umap_results_dist[min_dist] = umap_result\n",
    "        print(f\"  Completed!\")\n",
    "    \n",
    "    print(\"\\nAll UMAP runs completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize UMAP Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if UMAP is available\n",
    "if not UMAP_AVAILABLE:\n",
    "    print(\"UMAP visualizations skipped (UMAP not installed)\")\n",
    "else:\n",
    "    # Create comprehensive UMAP visualization\n",
    "    fig = plt.figure(figsize=(18, 12))\n",
    "    gs = fig.add_gridspec(2, 3, hspace=0.3, wspace=0.3)\n",
    "    \n",
    "    # Plot UMAP results with different n_neighbors\n",
    "    for idx, (n_neigh, umap_result) in enumerate(umap_results.items()):\n",
    "        ax = fig.add_subplot(gs[0, idx])\n",
    "        \n",
    "        for cell_type, color in zip(cell_types, colors):\n",
    "            mask = metadata_df['cell_type'] == cell_type\n",
    "            ax.scatter(umap_result[mask, 0], umap_result[mask, 1],\n",
    "                      label=cell_type, alpha=0.6, s=80, color=color, \n",
    "                      edgecolors='black', linewidth=0.5)\n",
    "        \n",
    "        ax.set_xlabel('UMAP 1', fontsize=12)\n",
    "        ax.set_ylabel('UMAP 2', fontsize=12)\n",
    "        ax.set_title(f'UMAP (n_neighbors={n_neigh})', fontsize=14, fontweight='bold')\n",
    "        ax.legend(loc='best', frameon=True, shadow=True)\n",
    "        ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot UMAP results with different min_dist\n",
    "    for idx, (min_d, umap_result) in enumerate(umap_results_dist.items()):\n",
    "        ax = fig.add_subplot(gs[1, idx])\n",
    "        \n",
    "        for cell_type, color in zip(cell_types, colors):\n",
    "            mask = metadata_df['cell_type'] == cell_type\n",
    "            ax.scatter(umap_result[mask, 0], umap_result[mask, 1],\n",
    "                      label=cell_type, alpha=0.6, s=80, color=color, \n",
    "                      edgecolors='black', linewidth=0.5)\n",
    "        \n",
    "        ax.set_xlabel('UMAP 1', fontsize=12)\n",
    "        ax.set_ylabel('UMAP 2', fontsize=12)\n",
    "        ax.set_title(f'UMAP (min_dist={min_d})', fontsize=14, fontweight='bold')\n",
    "        ax.legend(loc='best', frameon=True, shadow=True)\n",
    "        ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.suptitle('UMAP Analysis - Effect of Parameters', \n",
    "                 fontsize=18, fontweight='bold', y=0.995)\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\nUMAP Parameter Effects:\")\n",
    "    print(f\"\\nn_neighbors (controls local vs global):\")\n",
    "    print(f\"  - Low values: Focus on very local structure\")\n",
    "    print(f\"  - High values: Preserve more global structure\")\n",
    "    print(f\"\\nmin_dist (controls point spacing):\")\n",
    "    print(f\"  - 0.0: Tightly packed clusters\")\n",
    "    print(f\"  - 0.5: Moderate spacing\")\n",
    "    print(f\"  - 0.99: Loosely distributed points\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 7: Side-by-Side Comparison\n",
    "\n",
    "Let's compare all four methods directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive comparison plot\n",
    "if UMAP_AVAILABLE:\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 14))\n",
    "else:\n",
    "    # Only show 3 methods if UMAP not available\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "    axes = np.array([axes[0], axes[1], axes[2], None])  # Add None for consistency\n",
    "\n",
    "# 1. PCA\n",
    "ax = axes[0, 0] if UMAP_AVAILABLE else axes[0]\n",
    "for cell_type, color in zip(cell_types, colors):\n",
    "    mask = pca_df['cell_type'] == cell_type\n",
    "    ax.scatter(pca_df.loc[mask, 'PC1'], pca_df.loc[mask, 'PC2'],\n",
    "              label=cell_type, alpha=0.7, s=100, color=color, \n",
    "              edgecolors='black', linewidth=0.8)\n",
    "\n",
    "ax.set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]*100:.1f}%)', fontsize=13, fontweight='bold')\n",
    "ax.set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]*100:.1f}%)', fontsize=13, fontweight='bold')\n",
    "ax.set_title('PCA\\n(Linear, Fast, Deterministic)', fontsize=15, fontweight='bold')\n",
    "ax.legend(loc='best', frameon=True, shadow=True, fontsize=10)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# 2. ICA\n",
    "ax = axes[0, 1] if UMAP_AVAILABLE else axes[1]\n",
    "for cell_type, color in zip(cell_types, colors):\n",
    "    mask = ica_df['cell_type'] == cell_type\n",
    "    ax.scatter(ica_df.loc[mask, 'IC1'], ica_df.loc[mask, 'IC2'],\n",
    "              label=cell_type, alpha=0.7, s=100, color=color, \n",
    "              edgecolors='black', linewidth=0.8)\n",
    "\n",
    "ax.set_xlabel('IC1', fontsize=13, fontweight='bold')\n",
    "ax.set_ylabel('IC2', fontsize=13, fontweight='bold')\n",
    "ax.set_title('ICA\\n(Independent Sources, Statistical)', fontsize=15, fontweight='bold')\n",
    "ax.legend(loc='best', frameon=True, shadow=True, fontsize=10)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# 3. t-SNE\n",
    "ax = axes[1, 0] if UMAP_AVAILABLE else axes[2]\n",
    "tsne_result = tsne_results[30]\n",
    "for cell_type, color in zip(cell_types, colors):\n",
    "    mask = metadata_df['cell_type'] == cell_type\n",
    "    ax.scatter(tsne_result[mask, 0], tsne_result[mask, 1],\n",
    "              label=cell_type, alpha=0.7, s=100, color=color, \n",
    "              edgecolors='black', linewidth=0.8)\n",
    "\n",
    "ax.set_xlabel('t-SNE 1', fontsize=13, fontweight='bold')\n",
    "ax.set_ylabel('t-SNE 2', fontsize=13, fontweight='bold')\n",
    "ax.set_title('t-SNE\\n(Nonlinear, Local Structure, Slow)', fontsize=15, fontweight='bold')\n",
    "ax.legend(loc='best', frameon=True, shadow=True, fontsize=10)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# 4. UMAP (only if available)\n",
    "if UMAP_AVAILABLE:\n",
    "    ax = axes[1, 1]\n",
    "    umap_result = umap_results[15]\n",
    "    for cell_type, color in zip(cell_types, colors):\n",
    "        mask = metadata_df['cell_type'] == cell_type\n",
    "        ax.scatter(umap_result[mask, 0], umap_result[mask, 1],\n",
    "                  label=cell_type, alpha=0.7, s=100, color=color, \n",
    "                  edgecolors='black', linewidth=0.8)\n",
    "    \n",
    "    ax.set_xlabel('UMAP 1', fontsize=13, fontweight='bold')\n",
    "    ax.set_ylabel('UMAP 2', fontsize=13, fontweight='bold')\n",
    "    ax.set_title('UMAP\\n(Nonlinear, Global+Local, Fast)', fontsize=15, fontweight='bold')\n",
    "    ax.legend(loc='best', frameon=True, shadow=True, fontsize=10)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "title = 'Dimensionality Reduction Methods Comparison\\nRNA-Seq Data (4 Cell Types)'\n",
    "if not UMAP_AVAILABLE:\n",
    "    title += '\\n(UMAP not available - install with: pip install umap-learn)'\n",
    "\n",
    "plt.suptitle(title, fontsize=18, fontweight='bold', y=0.995 if UMAP_AVAILABLE else 1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary: When to Use Each Method\n",
    "\n",
    "| Method | Best For | Speed | Preserves | Deterministic | New Data |\n",
    "|--------|----------|-------|-----------|---------------|----------|\n",
    "| **PCA** | Quick exploration, preprocessing | ⚡⚡⚡ Fast | Global distances | ✅ Yes | ✅ Yes |\n",
    "| **ICA** | Finding independent processes | ⚡⚡ Medium | Independence | ⚠️ Mostly | ✅ Yes |\n",
    "| **t-SNE** | Visualization, cluster discovery | ⚡ Slow | Local structure | ❌ No | ❌ No |\n",
    "| **UMAP** | Large datasets, general use | ⚡⚡⚡ Fast | Local + Global | ⚠️ Mostly | ✅ Yes |\n",
    "\n",
    "### Recommendations:\n",
    "\n",
    "1. **Start with PCA**\n",
    "   - Quick overview of data structure\n",
    "   - Identify major sources of variation\n",
    "   - Check for batch effects or outliers\n",
    "\n",
    "2. **Use ICA for**\n",
    "   - Identifying independent biological processes\n",
    "   - Gene module discovery\n",
    "   - Separating technical from biological variation\n",
    "\n",
    "3. **Use t-SNE for**\n",
    "   - Publication-quality 2D visualizations\n",
    "   - Discovering subtle subpopulations\n",
    "   - Small to medium datasets (< 10,000 samples)\n",
    "\n",
    "4. **Use UMAP for**\n",
    "   - Large datasets (> 10,000 samples)\n",
    "   - When you need to transform new data\n",
    "   - Balance between speed and quality\n",
    "   - Downstream analysis (clustering, etc.)\n",
    "\n",
    "### Pro Tips:\n",
    "\n",
    "- **Preprocessing matters**: Always log-transform RNA-Seq data and select highly variable genes\n",
    "- **Multiple methods**: Use PCA first, then t-SNE/UMAP for visualization\n",
    "- **Parameter tuning**: Try different parameters (perplexity, n_neighbors) to find optimal results\n",
    "- **Biological validation**: Dimensionality reduction is exploratory - validate findings with differential expression analysis\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practical Exercise\n",
    "\n",
    "Try modifying the code above to:\n",
    "\n",
    "1. **Change the number of cell types** or samples per type\n",
    "2. **Experiment with different preprocessing** (no log transform, different gene selections)\n",
    "3. **Try 3D visualizations** by setting `n_components=3`\n",
    "4. **Compare different distance metrics** in UMAP (correlation, cosine, manhattan)\n",
    "5. **Add batch effects** to the simulated data and see how methods handle them\n",
    "\n",
    "### Challenge:\n",
    "Can you identify which genes drive the separation in each method? Use the component loadings/weights!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here for experimentation!\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
