{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Fundamentals: Data Cleaning, Labeling, and Normalization\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Welcome to this hands-on exercise on data preprocessing for machine learning! In this notebook, you'll work with a gene expression dataset to classify cancer vs. normal tissue samples.\n",
    "\n",
    "**The catch**: The data is messy (just like real-world data!). You'll need to clean, label, and normalize it before building effective models.\n",
    "\n",
    "### Learning Goals\n",
    "1. Handle missing values, duplicates, and outliers\n",
    "2. Standardize inconsistent labels\n",
    "3. Apply and compare normalization techniques\n",
    "4. Understand the impact of preprocessing on model performance\n",
    "5. Avoid common pitfalls like data leakage\n",
    "\n",
    "**Estimated time**: 60 minutes\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Core libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Machine learning\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler, StandardScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\n\n# Display settings\npd.set_option('display.max_columns', 20)\nsns.set_style('whitegrid')\nplt.rcParams['figure.figsize'] = (10, 6)\n\nprint(\"Libraries imported successfully!\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Data\n",
    "\n",
    "We have two CSV files:\n",
    "- `gene_expression_data.csv`: Expression values for 50 genes across samples\n",
    "- `sample_metadata.csv`: Diagnosis labels and patient information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expression data shape: (104, 51)\n",
      "Metadata shape: (100, 4)\n",
      "\n",
      "First few rows of expression data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_id</th>\n",
       "      <th>GENE_001</th>\n",
       "      <th>GENE_002</th>\n",
       "      <th>GENE_003</th>\n",
       "      <th>GENE_004</th>\n",
       "      <th>GENE_005</th>\n",
       "      <th>GENE_006</th>\n",
       "      <th>GENE_007</th>\n",
       "      <th>GENE_008</th>\n",
       "      <th>GENE_009</th>\n",
       "      <th>...</th>\n",
       "      <th>GENE_041</th>\n",
       "      <th>GENE_042</th>\n",
       "      <th>GENE_043</th>\n",
       "      <th>GENE_044</th>\n",
       "      <th>GENE_045</th>\n",
       "      <th>GENE_046</th>\n",
       "      <th>GENE_047</th>\n",
       "      <th>GENE_048</th>\n",
       "      <th>GENE_049</th>\n",
       "      <th>GENE_050</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SAMPLE_001</td>\n",
       "      <td>262.001863</td>\n",
       "      <td>114.105724</td>\n",
       "      <td>899.499280</td>\n",
       "      <td>2078.036716</td>\n",
       "      <td>NaN</td>\n",
       "      <td>335.587639</td>\n",
       "      <td>5139.720525</td>\n",
       "      <td>1926.357376</td>\n",
       "      <td>152.646792</td>\n",
       "      <td>...</td>\n",
       "      <td>1658.330781</td>\n",
       "      <td>790.788464</td>\n",
       "      <td>601.266323</td>\n",
       "      <td>418.555444</td>\n",
       "      <td>48.304222</td>\n",
       "      <td>133.048405</td>\n",
       "      <td>10.344491</td>\n",
       "      <td>890.158990</td>\n",
       "      <td>568.697439</td>\n",
       "      <td>32.991700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SAMPLE_002</td>\n",
       "      <td>202.230136</td>\n",
       "      <td>78.798854</td>\n",
       "      <td>123.337247</td>\n",
       "      <td>529.614026</td>\n",
       "      <td>858.751204</td>\n",
       "      <td>1927.557152</td>\n",
       "      <td>136.607039</td>\n",
       "      <td>383.145752</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>633.641461</td>\n",
       "      <td>2614.806996</td>\n",
       "      <td>249.492974</td>\n",
       "      <td>402.208933</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43.606529</td>\n",
       "      <td>32.187966</td>\n",
       "      <td>269.697148</td>\n",
       "      <td>342.267057</td>\n",
       "      <td>326.665119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SAMPLE_003</td>\n",
       "      <td>14.883069</td>\n",
       "      <td>74.705513</td>\n",
       "      <td>203.615553</td>\n",
       "      <td>63.511320</td>\n",
       "      <td>143.602834</td>\n",
       "      <td>874.073845</td>\n",
       "      <td>8145.440591</td>\n",
       "      <td>791.635259</td>\n",
       "      <td>454.257340</td>\n",
       "      <td>...</td>\n",
       "      <td>770.513252</td>\n",
       "      <td>4344.614073</td>\n",
       "      <td>64.153942</td>\n",
       "      <td>867.326675</td>\n",
       "      <td>655.321630</td>\n",
       "      <td>1265.488669</td>\n",
       "      <td>3.228398</td>\n",
       "      <td>25.154375</td>\n",
       "      <td>743.102110</td>\n",
       "      <td>725.088167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SAMPLE_004</td>\n",
       "      <td>181.094620</td>\n",
       "      <td>236.085537</td>\n",
       "      <td>122.764559</td>\n",
       "      <td>299.769726</td>\n",
       "      <td>283.890520</td>\n",
       "      <td>163.295501</td>\n",
       "      <td>7899.830069</td>\n",
       "      <td>1240.144788</td>\n",
       "      <td>51.696136</td>\n",
       "      <td>...</td>\n",
       "      <td>280.365616</td>\n",
       "      <td>2209.620970</td>\n",
       "      <td>985.994730</td>\n",
       "      <td>101.479493</td>\n",
       "      <td>575.404545</td>\n",
       "      <td>698.164947</td>\n",
       "      <td>5.482856</td>\n",
       "      <td>229.592135</td>\n",
       "      <td>370.641094</td>\n",
       "      <td>83.626529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sample_005</td>\n",
       "      <td>212.716741</td>\n",
       "      <td>325.609451</td>\n",
       "      <td>1728.280584</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.161141</td>\n",
       "      <td>116.786913</td>\n",
       "      <td>1041.573326</td>\n",
       "      <td>1316.738285</td>\n",
       "      <td>668.415382</td>\n",
       "      <td>...</td>\n",
       "      <td>166.848438</td>\n",
       "      <td>514.848879</td>\n",
       "      <td>1525.368520</td>\n",
       "      <td>2409.314864</td>\n",
       "      <td>73.321754</td>\n",
       "      <td>237.158208</td>\n",
       "      <td>10.124865</td>\n",
       "      <td>68.423949</td>\n",
       "      <td>4798.710315</td>\n",
       "      <td>852.598558</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    sample_id    GENE_001    GENE_002     GENE_003     GENE_004    GENE_005  \\\n",
       "0  SAMPLE_001  262.001863  114.105724   899.499280  2078.036716         NaN   \n",
       "1  SAMPLE_002  202.230136   78.798854   123.337247   529.614026  858.751204   \n",
       "2  SAMPLE_003   14.883069   74.705513   203.615553    63.511320  143.602834   \n",
       "3  SAMPLE_004  181.094620  236.085537   122.764559   299.769726  283.890520   \n",
       "4  sample_005  212.716741  325.609451  1728.280584          NaN   23.161141   \n",
       "\n",
       "      GENE_006     GENE_007     GENE_008    GENE_009  ...     GENE_041  \\\n",
       "0   335.587639  5139.720525  1926.357376  152.646792  ...  1658.330781   \n",
       "1  1927.557152   136.607039   383.145752         NaN  ...   633.641461   \n",
       "2   874.073845  8145.440591   791.635259  454.257340  ...   770.513252   \n",
       "3   163.295501  7899.830069  1240.144788   51.696136  ...   280.365616   \n",
       "4   116.786913  1041.573326  1316.738285  668.415382  ...   166.848438   \n",
       "\n",
       "      GENE_042     GENE_043     GENE_044    GENE_045     GENE_046   GENE_047  \\\n",
       "0   790.788464   601.266323   418.555444   48.304222   133.048405  10.344491   \n",
       "1  2614.806996   249.492974   402.208933         NaN    43.606529  32.187966   \n",
       "2  4344.614073    64.153942   867.326675  655.321630  1265.488669   3.228398   \n",
       "3  2209.620970   985.994730   101.479493  575.404545   698.164947   5.482856   \n",
       "4   514.848879  1525.368520  2409.314864   73.321754   237.158208  10.124865   \n",
       "\n",
       "     GENE_048     GENE_049    GENE_050  \n",
       "0  890.158990   568.697439   32.991700  \n",
       "1  269.697148   342.267057  326.665119  \n",
       "2   25.154375   743.102110  725.088167  \n",
       "3  229.592135   370.641094   83.626529  \n",
       "4   68.423949  4798.710315  852.598558  \n",
       "\n",
       "[5 rows x 51 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First few rows of metadata:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SAMPLE_001</td>\n",
       "      <td>healthy</td>\n",
       "      <td>27</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SAMPLE_002</td>\n",
       "      <td>control</td>\n",
       "      <td>69</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SAMPLE_003</td>\n",
       "      <td>normal</td>\n",
       "      <td>63</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SAMPLE_004</td>\n",
       "      <td>normal</td>\n",
       "      <td>61</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SAMPLE_005</td>\n",
       "      <td>Normal</td>\n",
       "      <td>79</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sample_id diagnosis  age gender\n",
       "0  SAMPLE_001   healthy   27      F\n",
       "1  SAMPLE_002   control   69      F\n",
       "2  SAMPLE_003    normal   63      F\n",
       "3  SAMPLE_004    normal   61      F\n",
       "4  SAMPLE_005    Normal   79      M"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load datasets\n",
    "expression_df = pd.read_csv('gene_expression_data.csv')\n",
    "metadata_df = pd.read_csv('sample_metadata.csv')\n",
    "\n",
    "print(\"Expression data shape:\", expression_df.shape)\n",
    "print(\"Metadata shape:\", metadata_df.shape)\n",
    "print(\"\\nFirst few rows of expression data:\")\n",
    "display(expression_df.head())\n",
    "print(\"\\nFirst few rows of metadata:\")\n",
    "display(metadata_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 1: Data Cleaning\n",
    "\n",
    "Real-world datasets are rarely clean. Let's identify and fix common issues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1.1: Visualize Missing Data\n",
    "\n",
    "Create a heatmap showing where missing values occur in the expression dataset.\n",
    "\n",
    "**Key Insight**: Visualizing missing data patterns helps identify if missingness is random or systematic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total missing values: 371\n",
      "Percentage missing: 6.99%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check for missing values\n",
    "missing_summary = expression_df.isnull().sum()\n",
    "print(f\"Total missing values: {expression_df.isnull().sum().sum()}\")\n",
    "print(f\"Percentage missing: {100 * expression_df.isnull().sum().sum() / expression_df.size:.2f}%\")\n",
    "\n",
    "# TODO: Create a heatmap of missing values using seaborn\n",
    "# Hint: Use sns.heatmap with expression_df.isnull()\n",
    "# Set cbar=False and use an appropriate colormap\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "# YOUR CODE HERE\n",
    "\n",
    "plt.title('Missing Data Heatmap (Yellow = Missing)', fontsize=14)\n",
    "plt.xlabel('Genes')\n",
    "plt.ylabel('Samples')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Think About It**: \n",
    "- Are missing values random or concentrated in certain genes/samples?\n",
    "- What might cause missing gene expression measurements in real experiments?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1.2: Handle Missing Values\n",
    "\n",
    "Choose a strategy to handle missing values:\n",
    "1. **Drop rows**: Remove samples with any missing values\n",
    "2. **Mean imputation**: Fill with column mean\n",
    "3. **Median imputation**: Fill with column median (more robust to outliers)\n",
    "\n",
    "**Common Mistake**: Dropping too many samples reduces statistical power!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Make a copy to preserve original data\nexpr_cleaned = expression_df.copy()\n\n# TODO: Implement median imputation for missing values\n# Hint: Use sklearn's SimpleImputer for robust imputation\n# Remember to exclude the 'sample_id' column\n\ngene_columns = [col for col in expr_cleaned.columns if col != 'sample_id']\n\n# YOUR CODE HERE\n# Example approach:\n# imputer = SimpleImputer(strategy='median')\n# expr_cleaned[gene_columns] = imputer.fit_transform(expr_cleaned[gene_columns])\n\n# Verify no missing values remain\nprint(f\"Missing values after imputation: {expr_cleaned.isnull().sum().sum()}\")\nassert expr_cleaned.isnull().sum().sum() == 0, \"Still have missing values!\""
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check Your Work**: The assertion should pass (no error means success!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1.3: Detect and Remove Duplicate Samples\n",
    "\n",
    "Duplicate samples violate the independence assumption in ML and can bias results.\n",
    "\n",
    "**Key Insight**: Keep the first occurrence and drop subsequent duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicates (excluding sample_id which should be unique)\n",
    "print(f\"Shape before removing duplicates: {expr_cleaned.shape}\")\n",
    "print(f\"Number of duplicate rows: {expr_cleaned.duplicated(subset=gene_columns).sum()}\")\n",
    "\n",
    "# TODO: Remove duplicate rows based on gene expression values\n",
    "# Hint: Use drop_duplicates() with subset=gene_columns\n",
    "# Keep the first occurrence\n",
    "\n",
    "# YOUR CODE HERE\n",
    "\n",
    "print(f\"Shape after removing duplicates: {expr_cleaned.shape}\")\n",
    "assert expr_cleaned.duplicated(subset=gene_columns).sum() == 0, \"Still have duplicates!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1.4: Identify and Handle Outliers\n",
    "\n",
    "Outliers can be:\n",
    "1. **Errors**: Measurement mistakes (should remove)\n",
    "2. **Real biology**: True extreme values (should keep)\n",
    "\n",
    "We'll visualize outliers using boxplots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize distribution of first 10 genes\n",
    "fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, gene in enumerate(gene_columns[:10]):\n",
    "    axes[i].boxplot(expr_cleaned[gene].dropna())\n",
    "    axes[i].set_title(gene, fontsize=10)\n",
    "    axes[i].set_ylabel('Expression')\n",
    "\n",
    "plt.suptitle('Gene Expression Distributions (First 10 Genes)', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n Notice: Some genes have very different scales and outliers!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Think About It**: \n",
    "- Which genes have outliers?\n",
    "- Should we remove outliers or handle them with normalization?\n",
    "- For this exercise, we'll handle outliers through normalization later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1.5: Standardize Sample IDs\n",
    "\n",
    "The sample IDs don't match between files! We need to standardize them.\n",
    "\n",
    "**Common Mistake**: Ignoring ID mismatches leads to losing samples during merge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check current ID formats\n",
    "print(\"Expression data sample IDs (first 10):\")\n",
    "print(expr_cleaned['sample_id'].head(10).tolist())\n",
    "print(\"\\nMetadata sample IDs (first 10):\")\n",
    "print(metadata_df['sample_id'].head(10).tolist())\n",
    "\n",
    "# Check how many IDs match\n",
    "matching_ids = set(expr_cleaned['sample_id']) & set(metadata_df['sample_id'])\n",
    "print(f\"\\nCurrently matching IDs: {len(matching_ids)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create a function to standardize sample IDs to 'SAMPLE_XXX' format\n",
    "# Handle various formats: 'patient-1', 'Patient_01', 'sample-001', etc.\n",
    "\n",
    "def standardize_sample_id(sample_id):\n",
    "    \"\"\"\n",
    "    Standardize sample ID to 'SAMPLE_XXX' format.\n",
    "    \n",
    "    Examples:\n",
    "    'patient-1' -> 'SAMPLE_001'\n",
    "    'Patient_01' -> 'SAMPLE_001'\n",
    "    'SAMPLE-002' -> 'SAMPLE_002'\n",
    "    \"\"\"\n",
    "    # TODO: Implement standardization logic\n",
    "    # Hints:\n",
    "    # 1. Convert to uppercase\n",
    "    # 2. Extract the numeric part\n",
    "    # 3. Return formatted as 'SAMPLE_XXX' with zero-padding\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    pass\n",
    "\n",
    "# Apply standardization\n",
    "expr_cleaned['sample_id'] = expr_cleaned['sample_id'].apply(standardize_sample_id)\n",
    "metadata_df['sample_id'] = metadata_df['sample_id'].apply(standardize_sample_id)\n",
    "\n",
    "# Check matches now\n",
    "matching_ids = set(expr_cleaned['sample_id']) & set(metadata_df['sample_id'])\n",
    "print(f\"Matching IDs after standardization: {len(matching_ids)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check Your Work**: You should have 100 matching IDs after standardization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 2: Data Labeling\n",
    "\n",
    "Now let's prepare the labels for classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2.1: Inspect Label Inconsistencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine unique diagnosis values\n",
    "print(\"Unique diagnosis labels:\")\n",
    "print(metadata_df['diagnosis'].unique())\n",
    "print(\"\\nDiagnosis value counts:\")\n",
    "print(metadata_df['diagnosis'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Key Insight**: We have inconsistent terminology!\n",
    "- Cancer class: 'cancer', 'tumor', 'malignant', 'Cancer'\n",
    "- Normal class: 'normal', 'healthy', 'control', 'Normal'\n",
    "- Ambiguous: 'borderline', 'unclear', 'suspicious'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2.2: Map Labels to Binary Classification\n",
    "\n",
    "Create binary labels: 0 = Normal, 1 = Cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create a function to map diagnosis labels to binary (0 or 1)\n",
    "# Return None for ambiguous cases\n",
    "\n",
    "def map_diagnosis_to_binary(diagnosis):\n",
    "    \"\"\"\n",
    "    Map diagnosis string to binary classification.\n",
    "    \n",
    "    Returns:\n",
    "    - 0 for normal/healthy/control\n",
    "    - 1 for cancer/tumor/malignant\n",
    "    - None for ambiguous cases\n",
    "    \"\"\"\n",
    "    diagnosis_lower = diagnosis.lower()\n",
    "    \n",
    "    # TODO: Implement mapping logic\n",
    "    # YOUR CODE HERE\n",
    "    pass\n",
    "\n",
    "# Apply mapping\n",
    "metadata_df['label'] = metadata_df['diagnosis'].apply(map_diagnosis_to_binary)\n",
    "\n",
    "print(\"Label distribution:\")\n",
    "print(metadata_df['label'].value_counts())\n",
    "print(f\"\\nAmbiguous cases: {metadata_df['label'].isnull().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2.3: Handle Ambiguous Labels\n",
    "\n",
    "**Think About It**: What should we do with ambiguous cases?\n",
    "\n",
    "Options:\n",
    "1. **Drop them**: Most conservative approach\n",
    "2. **Assign to majority class**: Could introduce bias\n",
    "3. **Use semi-supervised learning**: Advanced technique\n",
    "\n",
    "For this exercise, we'll drop ambiguous cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Remove rows with ambiguous labels (where label is None/NaN)\n",
    "# YOUR CODE HERE\n",
    "\n",
    "print(f\"Samples after removing ambiguous cases: {len(metadata_df)}\")\n",
    "assert metadata_df['label'].isnull().sum() == 0, \"Still have ambiguous labels!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2.4: Merge Expression Data with Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Merge expression data with metadata on 'sample_id'\n",
    "# Use inner join to keep only samples present in both datasets\n",
    "# YOUR CODE HERE\n",
    "# full_data = ...\n",
    "\n",
    "print(f\"Final dataset shape: {full_data.shape}\")\n",
    "print(f\"\\nColumns: {full_data.columns.tolist()[:10]}...\")  # Show first 10 columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2.5: Visualize Class Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create a bar plot showing class distribution\n",
    "# YOUR CODE HERE\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "# Use full_data['label'].value_counts() and plot\n",
    "\n",
    "plt.xlabel('Class (0=Normal, 1=Cancer)')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Class Distribution')\n",
    "plt.xticks([0, 1])\n",
    "plt.show()\n",
    "\n",
    "# Calculate class balance\n",
    "class_counts = full_data['label'].value_counts()\n",
    "print(f\"\\nClass balance:\")\n",
    "print(f\"Normal (0): {class_counts[0]} ({100*class_counts[0]/len(full_data):.1f}%)\")\n",
    "print(f\"Cancer (1): {class_counts[1]} ({100*class_counts[1]/len(full_data):.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Warning**: If classes are very imbalanced (e.g., 90/10), we'd need to address it with techniques like SMOTE or class weights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2.6: Create Train/Validation/Test Splits\n",
    "\n",
    "We'll use stratified splitting to maintain class balance:\n",
    "- 60% training\n",
    "- 20% validation  \n",
    "- 20% test\n",
    "\n",
    "**Key Insight**: Stratification ensures each split has similar class proportions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Prepare features (X) and target (y)\nX = full_data[gene_columns].values\ny = full_data['label'].values.astype(int)  # Convert to int for proper bincount\n\n# Safety check: Verify no NaN values\nprint(f\"Checking for NaN values in features: {np.isnan(X).sum()}\")\nif np.isnan(X).sum() > 0:\n    raise ValueError(f\"Found {np.isnan(X).sum()} NaN values! Please complete Task 1.2 (missing value imputation) first.\")\n\n# TODO: Create train/temp split (60/40)\n# Then split temp into validation/test (50/50 of temp = 20/20 of total)\n# Use stratify parameter to maintain class balance\n# Set random_state=42 for reproducibility\n\n# YOUR CODE HERE\n# X_train, X_temp, y_train, y_temp = train_test_split(...)\n# X_val, X_test, y_val, y_test = train_test_split(...)\n\nprint(\"Split sizes:\")\nprint(f\"Training: {len(X_train)} samples\")\nprint(f\"Validation: {len(X_val)} samples\")\nprint(f\"Test: {len(X_test)} samples\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check Your Work**: Verify class balance in each split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify stratification worked\n",
    "print(\"Class distribution in each split:\")\n",
    "print(f\"\\nTraining: {np.bincount(y_train)} -> {100*np.bincount(y_train)/len(y_train)}\")\n",
    "print(f\"Validation: {np.bincount(y_val)} -> {100*np.bincount(y_val)/len(y_val)}\")\n",
    "print(f\"Test: {np.bincount(y_test)} -> {100*np.bincount(y_test)/len(y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 3: Normalization and Its Impact\n",
    "\n",
    "Now we'll see how normalization affects model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3.1: Baseline Model (No Normalization)\n",
    "\n",
    "First, let's train a model WITHOUT normalization to establish a baseline.\n",
    "\n",
    "**Key Insight**: Features with larger scales will dominate the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train logistic regression without normalization\n",
    "baseline_model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "baseline_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on validation set\n",
    "y_val_pred_baseline = baseline_model.predict(X_val)\n",
    "\n",
    "# Evaluate\n",
    "baseline_acc = accuracy_score(y_val, y_val_pred_baseline)\n",
    "print(f\"Baseline Validation Accuracy: {baseline_acc:.4f}\")\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_val, y_val_pred_baseline))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_val, y_val_pred_baseline, target_names=['Normal', 'Cancer']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize feature importance (model coefficients)\n",
    "coef_baseline = baseline_model.coef_[0]\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.bar(range(len(coef_baseline)), coef_baseline)\n",
    "plt.xlabel('Gene Index')\n",
    "plt.ylabel('Coefficient')\n",
    "plt.title('Baseline Model Coefficients (No Normalization)')\n",
    "plt.axhline(y=0, color='r', linestyle='--', alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(f\"Coefficient range: [{coef_baseline.min():.6f}, {coef_baseline.max():.6f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Think About It**: \n",
    "- Why are some coefficients much larger than others?\n",
    "- Can we fairly compare feature importance when features have different scales?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3.2: Min-Max Scaling\n",
    "\n",
    "Min-Max scaling transforms features to [0, 1] range:\n",
    "$$X_{scaled} = \\frac{X - X_{min}}{X_{max} - X_{min}}$$\n",
    "\n",
    "**Critical**: Fit scaler on training data ONLY!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Apply Min-Max scaling\n",
    "# 1. Create MinMaxScaler instance\n",
    "# 2. Fit on training data\n",
    "# 3. Transform train, validation, and test sets\n",
    "\n",
    "# YOUR CODE HERE\n",
    "# minmax_scaler = MinMaxScaler()\n",
    "# X_train_minmax = ...\n",
    "# X_val_minmax = ...\n",
    "# X_test_minmax = ...\n",
    "\n",
    "# Train model on scaled data\n",
    "model_minmax = LogisticRegression(random_state=42, max_iter=1000)\n",
    "model_minmax.fit(X_train_minmax, y_train)\n",
    "\n",
    "# Evaluate\n",
    "y_val_pred_minmax = model_minmax.predict(X_val_minmax)\n",
    "minmax_acc = accuracy_score(y_val, y_val_pred_minmax)\n",
    "\n",
    "print(f\"Min-Max Scaling Validation Accuracy: {minmax_acc:.4f}\")\n",
    "print(f\"Improvement over baseline: {minmax_acc - baseline_acc:+.4f}\")\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_val, y_val_pred_minmax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize coefficients after Min-Max scaling\n",
    "coef_minmax = model_minmax.coef_[0]\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.bar(range(len(coef_minmax)), coef_minmax, alpha=0.7)\n",
    "plt.xlabel('Gene Index')\n",
    "plt.ylabel('Coefficient')\n",
    "plt.title('Model Coefficients After Min-Max Scaling')\n",
    "plt.axhline(y=0, color='r', linestyle='--', alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(f\"Coefficient range: [{coef_minmax.min():.4f}, {coef_minmax.max():.4f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3.3: Standardization (Z-Score)\n",
    "\n",
    "Standardization transforms features to have mean=0 and std=1:\n",
    "$$X_{scaled} = \\frac{X - \\mu}{\\sigma}$$\n",
    "\n",
    "**Key Insight**: Unlike Min-Max, standardization isn't bounded to a specific range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Apply Standardization\n",
    "# Use StandardScaler from sklearn\n",
    "\n",
    "# YOUR CODE HERE\n",
    "# standard_scaler = StandardScaler()\n",
    "# X_train_standard = ...\n",
    "# X_val_standard = ...\n",
    "# X_test_standard = ...\n",
    "\n",
    "# Train model\n",
    "model_standard = LogisticRegression(random_state=42, max_iter=1000)\n",
    "model_standard.fit(X_train_standard, y_train)\n",
    "\n",
    "# Evaluate\n",
    "y_val_pred_standard = model_standard.predict(X_val_standard)\n",
    "standard_acc = accuracy_score(y_val, y_val_pred_standard)\n",
    "\n",
    "print(f\"Standardization Validation Accuracy: {standard_acc:.4f}\")\n",
    "print(f\"Improvement over baseline: {standard_acc - baseline_acc:+.4f}\")\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_val, y_val_pred_standard))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize coefficients\n",
    "coef_standard = model_standard.coef_[0]\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.bar(range(len(coef_standard)), coef_standard, alpha=0.7, color='green')\n",
    "plt.xlabel('Gene Index')\n",
    "plt.ylabel('Coefficient')\n",
    "plt.title('Model Coefficients After Standardization')\n",
    "plt.axhline(y=0, color='r', linestyle='--', alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(f\"Coefficient range: [{coef_standard.min():.4f}, {coef_standard.max():.4f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Task 3.4: Log Transformation + Standardization\n\nGene expression data is often log-normally distributed. Let's try log transformation.\n\n**Warning**: Can't take log of zero! Use log1p instead: log(1 + x)\n\n**Important**: Make sure you completed Task 1.2 (missing value imputation) before running this cell!"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Apply log transformation\n# Note: log1p means log(1 + x) which handles zeros\n# Gene expression should be non-negative\nX_train_log = np.log1p(X_train)\nX_val_log = np.log1p(X_val)\nX_test_log = np.log1p(X_test)\n\n# Then standardize\nlog_scaler = StandardScaler()\nX_train_log_std = log_scaler.fit_transform(X_train_log)\nX_val_log_std = log_scaler.transform(X_val_log)\nX_test_log_std = log_scaler.transform(X_test_log)\n\n# Train model\nmodel_log = LogisticRegression(random_state=42, max_iter=1000)\nmodel_log.fit(X_train_log_std, y_train)\n\n# Evaluate\ny_val_pred_log = model_log.predict(X_val_log_std)\nlog_acc = accuracy_score(y_val, y_val_pred_log)\n\nprint(f\"Log + Standardization Validation Accuracy: {log_acc:.4f}\")\nprint(f\"Improvement over baseline: {log_acc - baseline_acc:+.4f}\")\nprint(\"\\nConfusion Matrix:\")\nprint(confusion_matrix(y_val, y_val_pred_log))"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3.5: Compare All Normalization Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison table\n",
    "results_df = pd.DataFrame({\n",
    "    'Method': ['Baseline (No Norm)', 'Min-Max Scaling', 'Standardization', 'Log + Standardization'],\n",
    "    'Validation Accuracy': [baseline_acc, minmax_acc, standard_acc, log_acc],\n",
    "    'Improvement': [0, minmax_acc - baseline_acc, standard_acc - baseline_acc, log_acc - baseline_acc]\n",
    "})\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"NORMALIZATION COMPARISON\")\n",
    "print(\"=\"*70)\n",
    "print(results_df.to_string(index=False))\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize comparison\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(results_df['Method'], results_df['Validation Accuracy'], color=['red', 'blue', 'green', 'purple'], alpha=0.7)\n",
    "plt.ylabel('Validation Accuracy')\n",
    "plt.title('Model Performance: Impact of Normalization Methods')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.ylim([0.5, 1.0])\n",
    "plt.axhline(y=baseline_acc, color='red', linestyle='--', alpha=0.5, label='Baseline')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Think About It**:\n",
    "- Which normalization method worked best?\n",
    "- Why might log transformation be particularly appropriate for gene expression data?\n",
    "- How much did normalization improve over the baseline?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 4: Pipeline Integration\n",
    "\n",
    "Sklearn pipelines help avoid data leakage and make code cleaner."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4.1: Build a Proper Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create a pipeline with StandardScaler and LogisticRegression\n",
    "# YOUR CODE HERE\n",
    "# pipeline = Pipeline([\n",
    "#     ('scaler', ...),\n",
    "#     ('classifier', ...)\n",
    "# ])\n",
    "\n",
    "# Fit pipeline on training data\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate\n",
    "y_val_pred_pipeline = pipeline.predict(X_val)\n",
    "pipeline_acc = accuracy_score(y_val, y_val_pred_pipeline)\n",
    "\n",
    "print(f\"Pipeline Validation Accuracy: {pipeline_acc:.4f}\")\n",
    "print(\"\\nPipeline steps:\", pipeline.named_steps.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4.2: Demonstrate Data Leakage Bug\n",
    "\n",
    "**Common Mistake**: Normalizing before splitting data!\n",
    "\n",
    "This leaks information from test set into training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WRONG: Normalize entire dataset before split\n",
    "print(\"WARNING: This demonstrates INCORRECT data handling!\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Normalize ALL data (data leakage!)\n",
    "leaky_scaler = StandardScaler()\n",
    "X_all_normalized = leaky_scaler.fit_transform(X)  # Fit on ALL data - BAD!\n",
    "\n",
    "# Then split\n",
    "X_train_leaky, X_temp_leaky, y_train_leaky, y_temp_leaky = train_test_split(\n",
    "    X_all_normalized, y, test_size=0.4, stratify=y, random_state=42\n",
    ")\n",
    "X_val_leaky, X_test_leaky, y_val_leaky, y_test_leaky = train_test_split(\n",
    "    X_temp_leaky, y_temp_leaky, test_size=0.5, stratify=y_temp_leaky, random_state=42\n",
    ")\n",
    "\n",
    "# Train model\n",
    "leaky_model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "leaky_model.fit(X_train_leaky, y_train_leaky)\n",
    "leaky_acc = accuracy_score(y_val_leaky, leaky_model.predict(X_val_leaky))\n",
    "\n",
    "print(f\"Leaky approach accuracy: {leaky_acc:.4f}\")\n",
    "print(f\"Proper approach accuracy: {standard_acc:.4f}\")\n",
    "print(f\"\\nDifference: {leaky_acc - standard_acc:+.4f}\")\n",
    "print(\"\\nLeaky accuracy may be artificially inflated!\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Key Insight**: Data leakage makes performance estimates unrealistically optimistic!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4.3: Final Evaluation on Test Set\n",
    "\n",
    "Now let's evaluate our best model on the held-out test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the best normalization method (based on validation results)\n",
    "# TODO: Choose your best model and evaluate on test set\n",
    "\n",
    "# Example with standardization:\n",
    "y_test_pred = model_standard.predict(X_test_standard)\n",
    "test_acc = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"FINAL TEST SET EVALUATION\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Test Accuracy: {test_acc:.4f}\")\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_test_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_test_pred, target_names=['Normal', 'Cancer']))\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Summary and Reflection\n",
    "\n",
    "## What We Learned\n",
    "\n",
    "1. **Data Cleaning is Critical**\n",
    "   - Missing values, duplicates, and outliers are common\n",
    "   - Each issue requires thoughtful handling\n",
    "   - Document your decisions!\n",
    "\n",
    "2. **Label Quality Matters**\n",
    "   - Inconsistent labels prevent learning\n",
    "   - Ambiguous cases need careful consideration\n",
    "   - Stratification maintains class balance\n",
    "\n",
    "3. **Normalization Improves Performance**\n",
    "   - Features with different scales bias models\n",
    "   - Different normalization methods suit different data\n",
    "   - Always fit on training data only!\n",
    "\n",
    "4. **Pipelines Prevent Mistakes**\n",
    "   - Encapsulate preprocessing steps\n",
    "   - Avoid data leakage\n",
    "   - Make code reproducible\n",
    "\n",
    "## Key Takeaways\n",
    "\n",
    "- **Data quality** often matters more than model choice\n",
    "- **Preprocessing** is not optional for real-world data\n",
    "- **Data leakage** is easy to introduce and hard to detect\n",
    "- **Documentation** helps reproduce and explain results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus Challenge\n",
    "\n",
    "Try these extensions:\n",
    "\n",
    "1. **Different Models**: Try RandomForestClassifier or SVM\n",
    "2. **Cross-Validation**: Use 5-fold CV instead of single validation set\n",
    "3. **Feature Selection**: Identify the 10 most important genes\n",
    "4. **Dimensionality Reduction**: Apply PCA before classification\n",
    "5. **Class Imbalance**: If you had 90/10 split, how would you handle it?\n",
    "6. **Error Analysis**: Which samples are misclassified and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your Reflection\n",
    "\n",
    "Answer these questions:\n",
    "\n",
    "1. Which preprocessing step had the biggest impact on your model?\n",
    "2. What surprised you most in this exercise?\n",
    "3. How would you handle these issues in a real research project?\n",
    "4. What additional data quality checks would you add?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**YOUR REFLECTION HERE:**\n",
    "\n",
    "_[Write your thoughts]_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Congratulations!\n",
    "\n",
    "You've completed the ML fundamentals exercise. You now understand:\n",
    "- How to clean messy real-world data\n",
    "- Why normalization matters\n",
    "- How to avoid data leakage\n",
    "- The importance of proper preprocessing pipelines\n",
    "\n",
    "These skills are essential for any machine learning project!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}