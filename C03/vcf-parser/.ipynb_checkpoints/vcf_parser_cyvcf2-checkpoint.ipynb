{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# VCF File Parser (cyvcf2 Implementation)\n",
    "\n",
    "This notebook implements a VCF parser using the **cyvcf2** library, a fast Cython wrapper around htslib.\n",
    "\n",
    "## Advantages over Manual Parsing\n",
    "\n",
    "| Feature | Manual Parser | cyvcf2 Parser |\n",
    "|---------|---------------|---------------|\n",
    "| Speed | Slower (pure Python) | Fast (C/Cython) |\n",
    "| Dependencies | Standard library + pandas | cyvcf2 + numpy |\n",
    "| Compressed files | gzip module | Native support (including bgzip) |\n",
    "| Index support | None | Supports .tbi/.csi indexes |\n",
    "| Memory | Loads all to DataFrame | Can iterate lazily |\n",
    "| Random access | Not possible | Query specific regions instantly |\n",
    "\n",
    "## Features\n",
    "- Parse standard VCF files using cyvcf2\n",
    "- Handle gzip/bgzip-compressed VCF files (.vcf.gz)\n",
    "- **Tabix indexing for fast random access queries**\n",
    "- Exception handling for robust error management\n",
    "- Unit tests for validation\n",
    "- Visualizations of variant data\n",
    "- Performance comparison with manual parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import unittest\n",
    "import tempfile\n",
    "import time\n",
    "from typing import Dict, List, Optional\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# cyvcf2 for fast VCF parsing\n",
    "from cyvcf2 import VCF\n",
    "\n",
    "# Set style for visualizations\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (10, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-2",
   "metadata": {},
   "source": [
    "## Custom Exceptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VCFError(Exception):\n",
    "    \"\"\"Base exception for VCF parsing errors.\"\"\"\n",
    "    pass\n",
    "\n",
    "\n",
    "class VCFFileNotFoundError(VCFError):\n",
    "    \"\"\"Raised when the VCF file cannot be found.\"\"\"\n",
    "    pass\n",
    "\n",
    "\n",
    "class VCFFormatError(VCFError):\n",
    "    \"\"\"Raised when the VCF file format is invalid.\"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-4",
   "metadata": {},
   "source": [
    "## CyVCF2 Parser Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CyVCF2Parser:\n",
    "    \"\"\"\n",
    "    A fast VCF parser using the cyvcf2 library.\n",
    "    \n",
    "    cyvcf2 is a Cython wrapper around htslib, providing significantly\n",
    "    better performance than pure Python parsing for large VCF files.\n",
    "    \n",
    "    Attributes:\n",
    "        file_path: Path to the VCF file\n",
    "        samples: List of sample names\n",
    "        variants: DataFrame containing variant records\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, file_path: Optional[str] = None):\n",
    "        \"\"\"Initialize the cyvcf2 parser.\"\"\"\n",
    "        self.file_path = file_path\n",
    "        self.samples: List[str] = []\n",
    "        self.variants: pd.DataFrame = pd.DataFrame()\n",
    "        self._vcf_reader: Optional[VCF] = None\n",
    "        \n",
    "        if file_path:\n",
    "            self.parse(file_path)\n",
    "    \n",
    "    def _format_info_value(self, value):\n",
    "        \"\"\"Format an INFO field value for string representation.\"\"\"\n",
    "        if value is True:\n",
    "            return None  # Flag field, no value needed\n",
    "        elif isinstance(value, (tuple, list)):\n",
    "            # Handle array values (e.g., AF with multiple alleles)\n",
    "            return ','.join(str(v) for v in value)\n",
    "        else:\n",
    "            return str(value)\n",
    "    \n",
    "    def parse(self, file_path: str) -> 'CyVCF2Parser':\n",
    "        \"\"\"Parse a VCF file and store the data.\"\"\"\n",
    "        self.file_path = file_path\n",
    "        \n",
    "        # Check if file exists\n",
    "        if not os.path.exists(file_path):\n",
    "            raise VCFFileNotFoundError(f\"VCF file not found: {file_path}\")\n",
    "        \n",
    "        try:\n",
    "            # Open VCF file with cyvcf2\n",
    "            self._vcf_reader = VCF(file_path)\n",
    "            self.samples = list(self._vcf_reader.samples)\n",
    "            \n",
    "            # Extract variants into a list of dictionaries\n",
    "            variants_data = []\n",
    "            \n",
    "            for variant in self._vcf_reader:\n",
    "                # Build variant record\n",
    "                record = {\n",
    "                    'CHROM': variant.CHROM,\n",
    "                    'POS': variant.POS,\n",
    "                    'ID': variant.ID if variant.ID else '.',\n",
    "                    'REF': variant.REF,\n",
    "                    'ALT': ','.join(str(a) for a in variant.ALT) if variant.ALT else '.',\n",
    "                    'QUAL': variant.QUAL if variant.QUAL is not None else np.nan,\n",
    "                    'FILTER': variant.FILTER if variant.FILTER else 'PASS',\n",
    "                }\n",
    "                \n",
    "                # Extract INFO fields, properly formatting array values\n",
    "                info_parts = []\n",
    "                for k, v in variant.INFO:\n",
    "                    formatted = self._format_info_value(v)\n",
    "                    if formatted is None:\n",
    "                        info_parts.append(k)  # Flag field\n",
    "                    else:\n",
    "                        info_parts.append(f\"{k}={formatted}\")\n",
    "                record['INFO'] = ';'.join(info_parts)\n",
    "                \n",
    "                variants_data.append(record)\n",
    "            \n",
    "            # Create DataFrame\n",
    "            if variants_data:\n",
    "                self.variants = pd.DataFrame(variants_data)\n",
    "            else:\n",
    "                self.variants = pd.DataFrame(\n",
    "                    columns=['CHROM', 'POS', 'ID', 'REF', 'ALT', 'QUAL', 'FILTER', 'INFO']\n",
    "                )\n",
    "            \n",
    "            # Reopen for potential future operations\n",
    "            self._vcf_reader = VCF(file_path)\n",
    "            \n",
    "        except Exception as e:\n",
    "            if \"VCFFileNotFoundError\" in str(type(e)):\n",
    "                raise\n",
    "            raise VCFFormatError(f\"Error parsing VCF file: {e}\")\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def parse_string(self, vcf_string: str) -> 'CyVCF2Parser':\n",
    "        \"\"\"Parse VCF data from a string (useful for testing).\"\"\"\n",
    "        with tempfile.NamedTemporaryFile(mode='w', suffix='.vcf', delete=False) as f:\n",
    "            f.write(vcf_string)\n",
    "            temp_path = f.name\n",
    "        \n",
    "        try:\n",
    "            self.parse(temp_path)\n",
    "        finally:\n",
    "            os.unlink(temp_path)\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def get_variant_count(self) -> int:\n",
    "        \"\"\"Return the total number of variants.\"\"\"\n",
    "        return len(self.variants)\n",
    "    \n",
    "    def get_chromosomes(self) -> List[str]:\n",
    "        \"\"\"Return a list of unique chromosomes.\"\"\"\n",
    "        if self.variants.empty:\n",
    "            return []\n",
    "        return self.variants['CHROM'].unique().tolist()\n",
    "    \n",
    "    def get_variants_by_chromosome(self, chrom: str) -> pd.DataFrame:\n",
    "        \"\"\"Return variants for a specific chromosome.\"\"\"\n",
    "        return self.variants[self.variants['CHROM'] == chrom].copy()\n",
    "    \n",
    "    def get_variant_types(self) -> pd.Series:\n",
    "        \"\"\"Classify variants by type (SNP, insertion, deletion, etc.).\"\"\"\n",
    "        def classify(row):\n",
    "            ref = row['REF']\n",
    "            alt = row['ALT']\n",
    "            \n",
    "            # Handle multiple alternates\n",
    "            alts = alt.split(',')\n",
    "            \n",
    "            types = []\n",
    "            for a in alts:\n",
    "                if a == '.':\n",
    "                    types.append('NO_VARIATION')\n",
    "                elif len(ref) == 1 and len(a) == 1:\n",
    "                    types.append('SNP')\n",
    "                elif len(ref) > len(a):\n",
    "                    types.append('DELETION')\n",
    "                elif len(ref) < len(a):\n",
    "                    types.append('INSERTION')\n",
    "                else:\n",
    "                    types.append('MNP')  # Multi-nucleotide polymorphism\n",
    "            \n",
    "            return ','.join(types)\n",
    "        \n",
    "        if self.variants.empty:\n",
    "            return pd.Series(dtype=str)\n",
    "        \n",
    "        return self.variants.apply(classify, axis=1)\n",
    "    \n",
    "    def get_info_field(self, field: str) -> pd.Series:\n",
    "        \"\"\"Extract a specific field from the INFO column.\"\"\"\n",
    "        def extract(info_str):\n",
    "            if pd.isna(info_str) or info_str == '.':\n",
    "                return None\n",
    "            \n",
    "            for item in info_str.split(';'):\n",
    "                if '=' in item:\n",
    "                    key, value = item.split('=', 1)\n",
    "                    if key == field:\n",
    "                        return value\n",
    "                elif item == field:\n",
    "                    return True  # Flag field\n",
    "            return None\n",
    "        \n",
    "        if self.variants.empty:\n",
    "            return pd.Series(dtype=object)\n",
    "        \n",
    "        return self.variants['INFO'].apply(extract)\n",
    "    \n",
    "    def summary(self) -> Dict:\n",
    "        \"\"\"Return a summary of the VCF file.\"\"\"\n",
    "        return {\n",
    "            'file_path': self.file_path,\n",
    "            'total_variants': self.get_variant_count(),\n",
    "            'chromosomes': self.get_chromosomes(),\n",
    "            'num_chromosomes': len(self.get_chromosomes()),\n",
    "            'samples': self.samples,\n",
    "            'num_samples': len(self.samples),\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-6",
   "metadata": {},
   "source": [
    "## Unit Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestCyVCF2Parser(unittest.TestCase):\n",
    "    \"\"\"Unit tests for the cyvcf2-based VCF parser.\"\"\"\n",
    "    \n",
    "    def setUp(self):\n",
    "        \"\"\"Set up test fixtures.\"\"\"\n",
    "        # Include ##contig lines to avoid htslib warnings\n",
    "        self.valid_vcf = \"\"\"##fileformat=VCFv4.2\n",
    "##contig=<ID=chr1,length=1000000>\n",
    "##contig=<ID=chr2,length=1000000>\n",
    "##INFO=<ID=DP,Number=1,Type=Integer,Description=\"Total Depth\">\n",
    "##FILTER=<ID=PASS,Description=\"All filters passed\">\n",
    "#CHROM\\tPOS\\tID\\tREF\\tALT\\tQUAL\\tFILTER\\tINFO\n",
    "chr1\\t100\\trs123\\tA\\tG\\t30\\tPASS\\tDP=100\n",
    "chr1\\t200\\trs456\\tC\\tT\\t25\\tPASS\\tDP=50\n",
    "chr2\\t300\\t.\\tGG\\tG\\t20\\tPASS\\tDP=75\n",
    "\"\"\"\n",
    "        \n",
    "        self.vcf_with_samples = \"\"\"##fileformat=VCFv4.2\n",
    "##contig=<ID=chr1,length=1000000>\n",
    "##FORMAT=<ID=GT,Number=1,Type=String,Description=\"Genotype\">\n",
    "##FORMAT=<ID=DP,Number=1,Type=Integer,Description=\"Read Depth\">\n",
    "#CHROM\\tPOS\\tID\\tREF\\tALT\\tQUAL\\tFILTER\\tINFO\\tFORMAT\\tSAMPLE1\\tSAMPLE2\n",
    "chr1\\t100\\trs123\\tA\\tG\\t30\\tPASS\\tDP=100\\tGT:DP\\t0/1:30\\t1/1:40\n",
    "\"\"\"\n",
    "    \n",
    "    def test_parse_valid_vcf(self):\n",
    "        \"\"\"Test parsing a valid VCF string.\"\"\"\n",
    "        parser = CyVCF2Parser()\n",
    "        parser.parse_string(self.valid_vcf)\n",
    "        \n",
    "        self.assertEqual(parser.get_variant_count(), 3)\n",
    "        self.assertEqual(set(parser.get_chromosomes()), {'chr1', 'chr2'})\n",
    "    \n",
    "    def test_parse_samples(self):\n",
    "        \"\"\"Test sample extraction.\"\"\"\n",
    "        parser = CyVCF2Parser()\n",
    "        parser.parse_string(self.vcf_with_samples)\n",
    "        \n",
    "        self.assertEqual(parser.samples, ['SAMPLE1', 'SAMPLE2'])\n",
    "    \n",
    "    def test_get_variants_by_chromosome(self):\n",
    "        \"\"\"Test filtering variants by chromosome.\"\"\"\n",
    "        parser = CyVCF2Parser()\n",
    "        parser.parse_string(self.valid_vcf)\n",
    "        \n",
    "        chr1_variants = parser.get_variants_by_chromosome('chr1')\n",
    "        self.assertEqual(len(chr1_variants), 2)\n",
    "    \n",
    "    def test_variant_types(self):\n",
    "        \"\"\"Test variant type classification.\"\"\"\n",
    "        parser = CyVCF2Parser()\n",
    "        parser.parse_string(self.valid_vcf)\n",
    "        \n",
    "        types = parser.get_variant_types()\n",
    "        self.assertEqual(types.iloc[0], 'SNP')  # A->G\n",
    "        self.assertEqual(types.iloc[2], 'DELETION')  # GG->G\n",
    "    \n",
    "    def test_get_info_field(self):\n",
    "        \"\"\"Test INFO field extraction.\"\"\"\n",
    "        parser = CyVCF2Parser()\n",
    "        parser.parse_string(self.valid_vcf)\n",
    "        \n",
    "        dp_values = parser.get_info_field('DP')\n",
    "        self.assertEqual(dp_values.iloc[0], '100')\n",
    "    \n",
    "    def test_file_not_found_error(self):\n",
    "        \"\"\"Test that missing file raises error.\"\"\"\n",
    "        parser = CyVCF2Parser()\n",
    "        with self.assertRaises(VCFFileNotFoundError):\n",
    "            parser.parse('/nonexistent/path/file.vcf')\n",
    "    \n",
    "    def test_summary(self):\n",
    "        \"\"\"Test summary generation.\"\"\"\n",
    "        parser = CyVCF2Parser()\n",
    "        parser.parse_string(self.valid_vcf)\n",
    "        \n",
    "        summary = parser.summary()\n",
    "        self.assertEqual(summary['total_variants'], 3)\n",
    "        self.assertEqual(summary['num_chromosomes'], 2)\n",
    "\n",
    "\n",
    "# Run tests\n",
    "print(\"Running unit tests...\\n\")\n",
    "suite = unittest.TestLoader().loadTestsFromTestCase(TestCyVCF2Parser)\n",
    "runner = unittest.TextTestRunner(verbosity=2)\n",
    "result = runner.run(suite)\n",
    "\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(f\"Tests run: {result.testsRun}\")\n",
    "print(f\"Failures: {len(result.failures)}\")\n",
    "print(f\"Errors: {len(result.errors)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-8",
   "metadata": {},
   "source": [
    "## Create Sample VCF Files for Demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "\n",
    "# Create a sample VCF file for demonstration\n",
    "# Note: Including ##contig lines to avoid htslib warnings\n",
    "sample_vcf_content = \"\"\"##fileformat=VCFv4.2\n",
    "##fileDate=20240101\n",
    "##source=VCFParserDemo\n",
    "##reference=GRCh38\n",
    "##contig=<ID=chr1,length=248956422>\n",
    "##contig=<ID=chr2,length=242193529>\n",
    "##contig=<ID=chr3,length=198295559>\n",
    "##contig=<ID=chr4,length=190214555>\n",
    "##contig=<ID=chr5,length=181538259>\n",
    "##INFO=<ID=DP,Number=1,Type=Integer,Description=\"Total Depth\">\n",
    "##INFO=<ID=AF,Number=A,Type=Float,Description=\"Allele Frequency\">\n",
    "##INFO=<ID=DB,Number=0,Type=Flag,Description=\"dbSNP membership\">\n",
    "##FILTER=<ID=PASS,Description=\"All filters passed\">\n",
    "##FILTER=<ID=LowQual,Description=\"Low quality\">\n",
    "##FORMAT=<ID=GT,Number=1,Type=String,Description=\"Genotype\">\n",
    "##FORMAT=<ID=DP,Number=1,Type=Integer,Description=\"Read Depth\">\n",
    "#CHROM\\tPOS\\tID\\tREF\\tALT\\tQUAL\\tFILTER\\tINFO\\tFORMAT\\tSAMPLE1\\tSAMPLE2\\tSAMPLE3\n",
    "chr1\\t10000\\trs001\\tA\\tG\\t50\\tPASS\\tDP=120;AF=0.25;DB\\tGT:DP\\t0/1:40\\t0/0:35\\t0/1:45\n",
    "chr1\\t20000\\trs002\\tC\\tT\\t45\\tPASS\\tDP=95;AF=0.15\\tGT:DP\\t0/0:30\\t0/1:32\\t0/0:33\n",
    "chr1\\t35000\\trs003\\tG\\tA\\t35\\tLowQual\\tDP=40;AF=0.05\\tGT:DP\\t0/0:12\\t0/0:15\\t0/1:13\n",
    "chr1\\t50000\\trs004\\tT\\tC\\t55\\tPASS\\tDP=150;AF=0.30\\tGT:DP\\t0/1:50\\t0/1:48\\t1/1:52\n",
    "chr2\\t15000\\trs005\\tAA\\tA\\t40\\tPASS\\tDP=85;AF=0.10\\tGT:DP\\t0/1:28\\t0/0:27\\t0/0:30\n",
    "chr2\\t30000\\trs006\\tG\\tGT\\t42\\tPASS\\tDP=90;AF=0.20\\tGT:DP\\t0/0:30\\t0/1:28\\t0/1:32\n",
    "chr2\\t45000\\t.\\tC\\tA\\t48\\tPASS\\tDP=110;AF=0.18\\tGT:DP\\t0/1:38\\t0/1:35\\t0/0:37\n",
    "chr3\\t10000\\trs008\\tT\\tG\\t52\\tPASS\\tDP=130;AF=0.22\\tGT:DP\\t0/0:42\\t0/1:44\\t0/1:44\n",
    "chr3\\t25000\\trs009\\tA\\tC\\t38\\tLowQual\\tDP=55;AF=0.08\\tGT:DP\\t0/0:18\\t0/0:17\\t0/1:20\n",
    "chr3\\t40000\\trs010\\tGG\\tTT\\t60\\tPASS\\tDP=145;AF=0.35;DB\\tGT:DP\\t0/1:48\\t0/1:47\\t1/1:50\n",
    "chr4\\t5000\\trs011\\tC\\tG\\t44\\tPASS\\tDP=100;AF=0.12\\tGT:DP\\t0/1:33\\t0/0:32\\t0/0:35\n",
    "chr4\\t20000\\trs012\\tT\\tA\\t46\\tPASS\\tDP=105;AF=0.16\\tGT:DP\\t0/0:35\\t0/1:34\\t0/0:36\n",
    "chr4\\t35000\\trs013\\tA\\tT,G\\t58\\tPASS\\tDP=140;AF=0.28,0.12\\tGT:DP\\t0/1:46\\t0/2:45\\t1/2:49\n",
    "chr5\\t12000\\trs014\\tG\\tC\\t36\\tLowQual\\tDP=48;AF=0.06\\tGT:DP\\t0/0:16\\t0/0:15\\t0/1:17\n",
    "chr5\\t28000\\trs015\\tC\\tT\\t50\\tPASS\\tDP=115;AF=0.24\\tGT:DP\\t0/1:38\\t0/1:36\\t0/0:41\n",
    "\"\"\"\n",
    "\n",
    "# Write sample VCF file\n",
    "sample_vcf_path = 'sample.vcf'\n",
    "with open(sample_vcf_path, 'w') as f:\n",
    "    f.write(sample_vcf_content)\n",
    "\n",
    "# Create compressed version\n",
    "sample_vcf_gz_path = 'sample.vcf.gz'\n",
    "with gzip.open(sample_vcf_gz_path, 'wt', encoding='utf-8') as f:\n",
    "    f.write(sample_vcf_content)\n",
    "\n",
    "print(f\"Created sample VCF file: {sample_vcf_path}\")\n",
    "print(f\"Created compressed VCF file: {sample_vcf_gz_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-10",
   "metadata": {},
   "source": [
    "## Parse the Sample VCF File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the uncompressed VCF file\n",
    "parser = CyVCF2Parser(sample_vcf_path)\n",
    "\n",
    "# Display summary\n",
    "print(\"VCF File Summary (cyvcf2)\")\n",
    "print(\"=\"*50)\n",
    "summary = parser.summary()\n",
    "for key, value in summary.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test parsing compressed file\n",
    "parser_gz = CyVCF2Parser(sample_vcf_gz_path)\n",
    "print(f\"\\nCompressed file parsed successfully!\")\n",
    "print(f\"Variants in compressed file: {parser_gz.get_variant_count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the variants DataFrame\n",
    "print(\"\\nVariant Data:\")\n",
    "parser.variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add variant types to the dataframe for visualization\n",
    "parser.variants['VARIANT_TYPE'] = parser.get_variant_types()\n",
    "parser.variants['AF'] = parser.get_info_field('AF').apply(\n",
    "    lambda x: float(x.split(',')[0]) if x and x != 'None' else np.nan\n",
    ")\n",
    "parser.variants['DP_INFO'] = pd.to_numeric(parser.get_info_field('DP'), errors='coerce')\n",
    "\n",
    "parser.variants[['CHROM', 'POS', 'REF', 'ALT', 'QUAL', 'VARIANT_TYPE', 'AF', 'DP_INFO']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "k0xye55p6gn",
   "metadata": {},
   "source": [
    "## Tabix Indexing and Random Access\n",
    "\n",
    "One of the key advantages of cyvcf2 over manual parsing is support for **tabix indexes**. \n",
    "Tabix enables fast random access to specific genomic regions without scanning the entire file.\n",
    "\n",
    "### Requirements\n",
    "- **bgzip**: Block-gzip compression (NOT regular gzip)\n",
    "- **tabix**: Creates the `.tbi` index file\n",
    "\n",
    "### How it works\n",
    "1. Compress VCF with `bgzip` (creates `.vcf.gz` with block compression)\n",
    "2. Index with `tabix` (creates `.vcf.gz.tbi`)\n",
    "3. Query specific regions with cyvcf2: `vcf(\"chr1:10000-50000\")`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "o5f7dteyhx",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import shutil\n",
    "\n",
    "# Check if bgzip and tabix are available\n",
    "bgzip_path = shutil.which('bgzip')\n",
    "tabix_path = shutil.which('tabix')\n",
    "\n",
    "print(\"Checking for required tools...\")\n",
    "print(f\"  bgzip: {'Found at ' + bgzip_path if bgzip_path else 'NOT FOUND'}\")\n",
    "print(f\"  tabix: {'Found at ' + tabix_path if tabix_path else 'NOT FOUND'}\")\n",
    "\n",
    "if not bgzip_path or not tabix_path:\n",
    "    print(\"\\nInstall htslib to get bgzip and tabix:\")\n",
    "    print(\"  macOS:  brew install htslib\")\n",
    "    print(\"  Ubuntu: apt-get install tabix\")\n",
    "    print(\"  conda:  conda install -c bioconda htslib\")\n",
    "    TABIX_AVAILABLE = False\n",
    "else:\n",
    "    TABIX_AVAILABLE = True\n",
    "    print(\"\\nAll tools available!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wab55z2y68i",
   "metadata": {},
   "outputs": [],
   "source": [
    "if TABIX_AVAILABLE:\n",
    "    # Create a bgzip-compressed VCF file with tabix index\n",
    "    indexed_vcf_path = 'sample_indexed.vcf.gz'\n",
    "    \n",
    "    # Remove existing files if present\n",
    "    for f in [indexed_vcf_path, indexed_vcf_path + '.tbi']:\n",
    "        if os.path.exists(f):\n",
    "            os.remove(f)\n",
    "    \n",
    "    # Step 1: Compress with bgzip (reads from stdin, writes to file)\n",
    "    print(\"Step 1: Compressing VCF with bgzip...\")\n",
    "    with open(sample_vcf_path, 'rb') as vcf_in:\n",
    "        with open(indexed_vcf_path, 'wb') as vcf_out:\n",
    "            result = subprocess.run(['bgzip', '-c'], stdin=vcf_in, stdout=vcf_out)\n",
    "    \n",
    "    if result.returncode == 0:\n",
    "        print(f\"  Created: {indexed_vcf_path}\")\n",
    "    else:\n",
    "        print(f\"  Error compressing file\")\n",
    "    \n",
    "    # Step 2: Create tabix index\n",
    "    print(\"\\nStep 2: Creating tabix index...\")\n",
    "    result = subprocess.run(['tabix', '-p', 'vcf', indexed_vcf_path], capture_output=True, text=True)\n",
    "    \n",
    "    if result.returncode == 0:\n",
    "        print(f\"  Created: {indexed_vcf_path}.tbi\")\n",
    "    else:\n",
    "        print(f\"  Error: {result.stderr}\")\n",
    "    \n",
    "    # Verify files exist\n",
    "    print(\"\\nGenerated files:\")\n",
    "    for f in [indexed_vcf_path, indexed_vcf_path + '.tbi']:\n",
    "        if os.path.exists(f):\n",
    "            size = os.path.getsize(f)\n",
    "            print(f\"  {f}: {size} bytes\")\n",
    "else:\n",
    "    print(\"Skipping bgzip/tabix - tools not available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "uf9xvlnp43",
   "metadata": {},
   "source": [
    "### Random Access Queries\n",
    "\n",
    "With an indexed VCF file, cyvcf2 can jump directly to specific regions without reading the entire file. This is critical for large VCF files (e.g., whole genome sequencing data).\n",
    "\n",
    "**Query syntax:**\n",
    "- Single region: `vcf(\"chr1:10000-50000\")`\n",
    "- Whole chromosome: `vcf(\"chr1\")`\n",
    "- Multiple regions: `vcf(\"chr1:10000-20000,chr2:15000-30000\")`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "n546oxpfda",
   "metadata": {},
   "outputs": [],
   "source": [
    "if TABIX_AVAILABLE:\n",
    "    # Open the indexed VCF file\n",
    "    indexed_vcf = VCF(indexed_vcf_path)\n",
    "    \n",
    "    print(\"Random Access Query Examples\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Example 1: Query a specific region on chr1\n",
    "    print(\"\\n1. Query chr1:10000-40000\")\n",
    "    print(\"-\" * 40)\n",
    "    for variant in indexed_vcf(\"chr1:10000-40000\"):\n",
    "        print(f\"   {variant.CHROM}:{variant.POS} {variant.REF}>{','.join(variant.ALT)} (ID: {variant.ID})\")\n",
    "    \n",
    "    # Reopen to reset iterator\n",
    "    indexed_vcf = VCF(indexed_vcf_path)\n",
    "    \n",
    "    # Example 2: Query entire chromosome\n",
    "    print(\"\\n2. Query all of chr2\")\n",
    "    print(\"-\" * 40)\n",
    "    for variant in indexed_vcf(\"chr2\"):\n",
    "        print(f\"   {variant.CHROM}:{variant.POS} {variant.REF}>{','.join(variant.ALT)} (ID: {variant.ID})\")\n",
    "    \n",
    "    # Reopen to reset iterator\n",
    "    indexed_vcf = VCF(indexed_vcf_path)\n",
    "    \n",
    "    # Example 3: Query multiple regions\n",
    "    print(\"\\n3. Query multiple regions (chr1:10000-25000 and chr3:20000-50000)\")\n",
    "    print(\"-\" * 40)\n",
    "    regions = [\"chr1:10000-25000\", \"chr3:20000-50000\"]\n",
    "    for region in regions:\n",
    "        indexed_vcf = VCF(indexed_vcf_path)  # Reopen for each region\n",
    "        print(f\"   Region: {region}\")\n",
    "        for variant in indexed_vcf(region):\n",
    "            print(f\"      {variant.CHROM}:{variant.POS} {variant.REF}>{','.join(variant.ALT)}\")\n",
    "else:\n",
    "    print(\"Skipping random access demo - tabix not available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eukwdo5kb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if TABIX_AVAILABLE:\n",
    "    def query_region_to_dataframe(vcf_path: str, region: str) -> pd.DataFrame:\n",
    "        \"\"\"Query a region and return results as a DataFrame.\"\"\"\n",
    "        vcf = VCF(vcf_path)\n",
    "        variants_data = []\n",
    "        \n",
    "        for variant in vcf(region):\n",
    "            record = {\n",
    "                'CHROM': variant.CHROM,\n",
    "                'POS': variant.POS,\n",
    "                'ID': variant.ID if variant.ID else '.',\n",
    "                'REF': variant.REF,\n",
    "                'ALT': ','.join(str(a) for a in variant.ALT) if variant.ALT else '.',\n",
    "                'QUAL': variant.QUAL,\n",
    "                'FILTER': variant.FILTER if variant.FILTER else 'PASS',\n",
    "            }\n",
    "            variants_data.append(record)\n",
    "        \n",
    "        return pd.DataFrame(variants_data)\n",
    "    \n",
    "    # Query chr1 and get as DataFrame\n",
    "    print(\"Query chr1:10000-50000 as DataFrame:\")\n",
    "    chr1_df = query_region_to_dataframe(indexed_vcf_path, \"chr1:10000-50000\")\n",
    "    display(chr1_df)\n",
    "else:\n",
    "    print(\"Skipping DataFrame query demo - tabix not available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "kgruou1eto",
   "metadata": {},
   "source": [
    "### Random Access vs Full Scan Performance\n",
    "\n",
    "For large VCF files, random access is dramatically faster than scanning the entire file.\n",
    "The benefit scales with file size - for a 10GB VCF, a region query can be 1000x+ faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6l6rwhaj9rj",
   "metadata": {},
   "outputs": [],
   "source": [
    "if TABIX_AVAILABLE:\n",
    "    import time\n",
    "    \n",
    "    n_iterations = 50\n",
    "    \n",
    "    # Benchmark: Full file scan to find chr1 variants\n",
    "    full_scan_times = []\n",
    "    for _ in range(n_iterations):\n",
    "        start = time.perf_counter()\n",
    "        vcf = VCF(indexed_vcf_path)\n",
    "        chr1_variants = [v for v in vcf if v.CHROM == \"chr1\"]\n",
    "        full_scan_times.append(time.perf_counter() - start)\n",
    "    \n",
    "    # Benchmark: Random access query for chr1\n",
    "    random_access_times = []\n",
    "    for _ in range(n_iterations):\n",
    "        start = time.perf_counter()\n",
    "        vcf = VCF(indexed_vcf_path)\n",
    "        chr1_variants = list(vcf(\"chr1\"))\n",
    "        random_access_times.append(time.perf_counter() - start)\n",
    "    \n",
    "    print(\"Performance: Full Scan vs Random Access\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"Task: Retrieve all chr1 variants ({len(chr1_variants)} variants)\")\n",
    "    print(f\"Iterations: {n_iterations}\\n\")\n",
    "    \n",
    "    full_scan_mean = np.mean(full_scan_times) * 1000\n",
    "    full_scan_std = np.std(full_scan_times) * 1000\n",
    "    random_mean = np.mean(random_access_times) * 1000\n",
    "    random_std = np.std(random_access_times) * 1000\n",
    "    \n",
    "    print(f\"Full Scan:     {full_scan_mean:.3f} ms ± {full_scan_std:.3f} ms\")\n",
    "    print(f\"Random Access: {random_mean:.3f} ms ± {random_std:.3f} ms\")\n",
    "    \n",
    "    if random_mean < full_scan_mean:\n",
    "        speedup = full_scan_mean / random_mean\n",
    "        print(f\"\\nRandom access is {speedup:.1f}x faster\")\n",
    "    else:\n",
    "        print(f\"\\n(For small files, the difference is minimal)\")\n",
    "    \n",
    "    print(\"\\nNote: The speedup is dramatic for large files (GB-scale VCFs)\")\n",
    "else:\n",
    "    print(\"Skipping performance comparison - tabix not available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-15",
   "metadata": {},
   "source": [
    "## Visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-16",
   "metadata": {},
   "source": [
    "### Visualization 1: Variant Distribution by Chromosome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count variants per chromosome\n",
    "chrom_counts = parser.variants['CHROM'].value_counts().sort_index()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "colors = sns.color_palette(\"viridis\", len(chrom_counts))\n",
    "bars = ax.bar(chrom_counts.index, chrom_counts.values, color=colors, edgecolor='black')\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar, count in zip(bars, chrom_counts.values):\n",
    "    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.1, \n",
    "            str(count), ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "ax.set_xlabel('Chromosome', fontsize=12)\n",
    "ax.set_ylabel('Number of Variants', fontsize=12)\n",
    "ax.set_title('Variant Distribution by Chromosome (cyvcf2)', fontsize=14, fontweight='bold')\n",
    "ax.set_ylim(0, max(chrom_counts.values) + 1)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('viz1_variants_by_chromosome_cyvcf2.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-18",
   "metadata": {},
   "source": [
    "### Visualization 2: Variant Types Distribution (Pie Chart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count variant types\n",
    "type_counts = parser.variants['VARIANT_TYPE'].value_counts()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "colors = sns.color_palette(\"Set2\", len(type_counts))\n",
    "explode = [0.05] * len(type_counts)\n",
    "\n",
    "wedges, texts, autotexts = ax.pie(\n",
    "    type_counts.values, \n",
    "    labels=type_counts.index,\n",
    "    autopct='%1.1f%%',\n",
    "    colors=colors,\n",
    "    explode=explode,\n",
    "    shadow=True,\n",
    "    startangle=90\n",
    ")\n",
    "\n",
    "# Style the text\n",
    "for autotext in autotexts:\n",
    "    autotext.set_fontweight('bold')\n",
    "\n",
    "ax.set_title('Distribution of Variant Types (cyvcf2)', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Add legend with counts\n",
    "legend_labels = [f\"{label} (n={count})\" for label, count in zip(type_counts.index, type_counts.values)]\n",
    "ax.legend(wedges, legend_labels, title=\"Variant Types\", loc=\"center left\", bbox_to_anchor=(1, 0, 0.5, 1))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('viz2_variant_types_cyvcf2.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-20",
   "metadata": {},
   "source": [
    "### Visualization 3: Quality Score Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-21",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Histogram\n",
    "ax1 = axes[0]\n",
    "qual_data = parser.variants['QUAL'].dropna()\n",
    "ax1.hist(qual_data, bins=15, color='steelblue', edgecolor='black', alpha=0.7)\n",
    "ax1.axvline(qual_data.mean(), color='red', linestyle='--', linewidth=2, label=f'Mean: {qual_data.mean():.1f}')\n",
    "ax1.axvline(qual_data.median(), color='orange', linestyle='--', linewidth=2, label=f'Median: {qual_data.median():.1f}')\n",
    "ax1.set_xlabel('Quality Score (QUAL)', fontsize=12)\n",
    "ax1.set_ylabel('Frequency', fontsize=12)\n",
    "ax1.set_title('Quality Score Distribution (cyvcf2)', fontsize=14, fontweight='bold')\n",
    "ax1.legend()\n",
    "\n",
    "# Box plot by filter status\n",
    "ax2 = axes[1]\n",
    "filter_groups = parser.variants.groupby('FILTER')['QUAL'].apply(list).to_dict()\n",
    "box_data = [filter_groups.get(f, []) for f in ['PASS', 'LowQual']]\n",
    "bp = ax2.boxplot(box_data, tick_labels=['PASS', 'LowQual'], patch_artist=True)\n",
    "\n",
    "colors_box = ['lightgreen', 'lightcoral']\n",
    "for patch, color in zip(bp['boxes'], colors_box):\n",
    "    patch.set_facecolor(color)\n",
    "\n",
    "ax2.set_xlabel('Filter Status', fontsize=12)\n",
    "ax2.set_ylabel('Quality Score (QUAL)', fontsize=12)\n",
    "ax2.set_title('Quality Score by Filter Status (cyvcf2)', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('viz3_quality_distribution_cyvcf2.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-22",
   "metadata": {},
   "source": [
    "### Visualization 4: Allele Frequency vs Read Depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-23",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 7))\n",
    "\n",
    "# Filter out NaN values\n",
    "plot_data = parser.variants.dropna(subset=['AF', 'DP_INFO'])\n",
    "\n",
    "# Create scatter plot colored by variant type\n",
    "variant_types = plot_data['VARIANT_TYPE'].unique()\n",
    "colors = sns.color_palette(\"husl\", len(variant_types))\n",
    "color_map = dict(zip(variant_types, colors))\n",
    "\n",
    "for vtype in variant_types:\n",
    "    mask = plot_data['VARIANT_TYPE'] == vtype\n",
    "    subset = plot_data[mask]\n",
    "    ax.scatter(\n",
    "        subset['AF'], \n",
    "        subset['DP_INFO'],\n",
    "        c=[color_map[vtype]],\n",
    "        s=subset['QUAL'] * 3,  # Size by quality\n",
    "        alpha=0.7,\n",
    "        label=vtype,\n",
    "        edgecolors='black',\n",
    "        linewidth=0.5\n",
    "    )\n",
    "\n",
    "ax.set_xlabel('Allele Frequency (AF)', fontsize=12)\n",
    "ax.set_ylabel('Read Depth (DP)', fontsize=12)\n",
    "ax.set_title('Allele Frequency vs Read Depth (cyvcf2)\\n(point size = quality score)', fontsize=14, fontweight='bold')\n",
    "ax.legend(title='Variant Type')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('viz4_af_vs_depth_cyvcf2.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-24",
   "metadata": {},
   "source": [
    "### Visualization 5: Genomic Position Density Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-25",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "# Get unique chromosomes in order\n",
    "chromosomes = sorted(parser.variants['CHROM'].unique())\n",
    "colors = sns.color_palette(\"tab10\", len(chromosomes))\n",
    "\n",
    "# Create chromosome offset for visualization\n",
    "chrom_offsets = {}\n",
    "offset = 0\n",
    "tick_positions = []\n",
    "tick_labels = []\n",
    "\n",
    "for i, chrom in enumerate(chromosomes):\n",
    "    chrom_data = parser.variants[parser.variants['CHROM'] == chrom].copy()\n",
    "    positions = chrom_data['POS'].values + offset\n",
    "    \n",
    "    # Plot variants as vertical lines\n",
    "    for pos in positions:\n",
    "        ax.axvline(pos, color=colors[i], alpha=0.7, linewidth=2)\n",
    "    \n",
    "    # Store tick position (middle of chromosome region)\n",
    "    max_pos = chrom_data['POS'].max()\n",
    "    tick_positions.append(offset + max_pos / 2)\n",
    "    tick_labels.append(chrom)\n",
    "    \n",
    "    # Add separator and update offset\n",
    "    offset += max_pos + 10000\n",
    "    if i < len(chromosomes) - 1:\n",
    "        ax.axvline(offset - 5000, color='gray', linestyle=':', alpha=0.5)\n",
    "\n",
    "ax.set_xticks(tick_positions)\n",
    "ax.set_xticklabels(tick_labels)\n",
    "ax.set_xlabel('Chromosome', fontsize=12)\n",
    "ax.set_ylabel('Variant Presence', fontsize=12)\n",
    "ax.set_title('Variant Positions Across Chromosomes (cyvcf2)', fontsize=14, fontweight='bold')\n",
    "ax.set_yticks([])\n",
    "\n",
    "# Add legend\n",
    "from matplotlib.patches import Patch\n",
    "legend_elements = [Patch(facecolor=colors[i], label=chrom) for i, chrom in enumerate(chromosomes)]\n",
    "ax.legend(handles=legend_elements, title='Chromosome', loc='upper right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('viz5_genomic_positions_cyvcf2.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-26",
   "metadata": {},
   "source": [
    "## Performance Comparison: Manual Parser vs cyvcf2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the manual parser for comparison\n",
    "# We'll define a simplified version here to avoid file dependencies\n",
    "\n",
    "class ManualVCFParser:\n",
    "    \"\"\"Simplified manual VCF parser for performance comparison.\"\"\"\n",
    "    \n",
    "    def __init__(self, file_path: Optional[str] = None):\n",
    "        self.file_path = file_path\n",
    "        self.variants: pd.DataFrame = pd.DataFrame()\n",
    "        self.samples: List[str] = []\n",
    "        \n",
    "        if file_path:\n",
    "            self.parse(file_path)\n",
    "    \n",
    "    def parse(self, file_path: str) -> 'ManualVCFParser':\n",
    "        self.file_path = file_path\n",
    "        variants_data = []\n",
    "        header = []\n",
    "        \n",
    "        # Handle gzip\n",
    "        if file_path.endswith('.gz'):\n",
    "            open_func = lambda p: gzip.open(p, 'rt', encoding='utf-8')\n",
    "        else:\n",
    "            open_func = lambda p: open(p, 'r', encoding='utf-8')\n",
    "        \n",
    "        with open_func(file_path) as f:\n",
    "            for line in f:\n",
    "                line = line.strip()\n",
    "                if not line or line.startswith('##'):\n",
    "                    continue\n",
    "                elif line.startswith('#'):\n",
    "                    header = line.lstrip('#').split('\\t')\n",
    "                    if 'FORMAT' in header:\n",
    "                        format_idx = header.index('FORMAT')\n",
    "                        self.samples = header[format_idx + 1:]\n",
    "                else:\n",
    "                    variants_data.append(line.split('\\t'))\n",
    "        \n",
    "        if variants_data:\n",
    "            self.variants = pd.DataFrame(variants_data, columns=header)\n",
    "            self.variants['POS'] = pd.to_numeric(self.variants['POS'], errors='coerce')\n",
    "            self.variants['QUAL'] = pd.to_numeric(self.variants['QUAL'], errors='coerce')\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def get_variant_count(self) -> int:\n",
    "        return len(self.variants)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_parsers(file_path: str, n_iterations: int = 10):\n",
    "    \"\"\"Compare parsing speed between manual and cyvcf2 parsers.\"\"\"\n",
    "    \n",
    "    # Benchmark manual parser\n",
    "    manual_times = []\n",
    "    for _ in range(n_iterations):\n",
    "        start = time.perf_counter()\n",
    "        parser = ManualVCFParser(file_path)\n",
    "        manual_times.append(time.perf_counter() - start)\n",
    "    \n",
    "    # Benchmark cyvcf2 parser\n",
    "    cyvcf2_times = []\n",
    "    for _ in range(n_iterations):\n",
    "        start = time.perf_counter()\n",
    "        parser = CyVCF2Parser(file_path)\n",
    "        cyvcf2_times.append(time.perf_counter() - start)\n",
    "    \n",
    "    return {\n",
    "        'manual': {\n",
    "            'mean': np.mean(manual_times) * 1000,  # Convert to ms\n",
    "            'std': np.std(manual_times) * 1000,\n",
    "            'times': manual_times\n",
    "        },\n",
    "        'cyvcf2': {\n",
    "            'mean': np.mean(cyvcf2_times) * 1000,\n",
    "            'std': np.std(cyvcf2_times) * 1000,\n",
    "            'times': cyvcf2_times\n",
    "        }\n",
    "    }\n",
    "\n",
    "# Run benchmark\n",
    "print(\"Performance Comparison\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"\\nBenchmarking with file: {sample_vcf_path}\")\n",
    "print(f\"Number of variants: {parser.get_variant_count()}\")\n",
    "print(f\"Number of iterations: 10\\n\")\n",
    "\n",
    "results = benchmark_parsers(sample_vcf_path, n_iterations=10)\n",
    "\n",
    "print(f\"Manual Parser:\")\n",
    "print(f\"  Mean time: {results['manual']['mean']:.2f} ms ± {results['manual']['std']:.2f} ms\")\n",
    "\n",
    "print(f\"\\ncyvcf2 Parser:\")\n",
    "print(f\"  Mean time: {results['cyvcf2']['mean']:.2f} ms ± {results['cyvcf2']['std']:.2f} ms\")\n",
    "\n",
    "speedup = results['manual']['mean'] / results['cyvcf2']['mean']\n",
    "if speedup > 1:\n",
    "    print(f\"\\ncyvcf2 is {speedup:.2f}x faster than manual parsing\")\n",
    "else:\n",
    "    print(f\"\\nManual parsing is {1/speedup:.2f}x faster than cyvcf2\")\n",
    "    print(\"(Note: For small files, overhead may dominate. cyvcf2 shines with large files)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the benchmark results\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "\n",
    "parsers = ['Manual Parser', 'cyvcf2 Parser']\n",
    "means = [results['manual']['mean'], results['cyvcf2']['mean']]\n",
    "stds = [results['manual']['std'], results['cyvcf2']['std']]\n",
    "colors = ['#ff7f0e', '#2ca02c']\n",
    "\n",
    "bars = ax.bar(parsers, means, yerr=stds, color=colors, edgecolor='black', capsize=5)\n",
    "\n",
    "# Add value labels\n",
    "for bar, mean, std in zip(bars, means, stds):\n",
    "    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + std + 0.2,\n",
    "            f'{mean:.2f} ms', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "ax.set_ylabel('Time (milliseconds)', fontsize=12)\n",
    "ax.set_title('VCF Parsing Performance Comparison', fontsize=14, fontweight='bold')\n",
    "ax.set_ylim(0, max(means) + max(stds) + 2)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('viz6_performance_comparison.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-30",
   "metadata": {},
   "source": [
    "## Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-31",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"VCF Analysis Summary (cyvcf2)\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nFile: {parser.file_path}\")\n",
    "print(f\"Total Variants: {parser.get_variant_count()}\")\n",
    "print(f\"Chromosomes: {', '.join(parser.get_chromosomes())}\")\n",
    "print(f\"Samples: {', '.join(parser.samples) if parser.samples else 'None'}\")\n",
    "\n",
    "print(f\"\\nVariant Types:\")\n",
    "for vtype, count in parser.variants['VARIANT_TYPE'].value_counts().items():\n",
    "    print(f\"  - {vtype}: {count}\")\n",
    "\n",
    "print(f\"\\nFilter Status:\")\n",
    "for filt, count in parser.variants['FILTER'].value_counts().items():\n",
    "    print(f\"  - {filt}: {count}\")\n",
    "\n",
    "print(f\"\\nQuality Score Statistics:\")\n",
    "qual_stats = parser.variants['QUAL'].describe()\n",
    "print(f\"  - Mean: {qual_stats['mean']:.2f}\")\n",
    "print(f\"  - Std: {qual_stats['std']:.2f}\")\n",
    "print(f\"  - Min: {qual_stats['min']:.2f}\")\n",
    "print(f\"  - Max: {qual_stats['max']:.2f}\")\n",
    "\n",
    "print(f\"\\nRead Depth Statistics:\")\n",
    "dp_stats = parser.variants['DP_INFO'].describe()\n",
    "print(f\"  - Mean: {dp_stats['mean']:.2f}\")\n",
    "print(f\"  - Std: {dp_stats['std']:.2f}\")\n",
    "print(f\"  - Min: {dp_stats['min']:.2f}\")\n",
    "print(f\"  - Max: {dp_stats['max']:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-32",
   "metadata": {},
   "source": [
    "## Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optionally clean up generated files\n",
    "# Uncomment the following lines to remove generated files\n",
    "\n",
    "# import os\n",
    "# for f in ['sample.vcf', 'sample.vcf.gz', 'sample_indexed.vcf.gz', 'sample_indexed.vcf.gz.tbi']:\n",
    "#     if os.path.exists(f):\n",
    "#         os.remove(f)\n",
    "#         print(f\"Removed {f}\")\n",
    "\n",
    "print(\"\\nGenerated files:\")\n",
    "print(\"- sample.vcf (sample VCF file)\")\n",
    "print(\"- sample.vcf.gz (gzip-compressed sample VCF file)\")\n",
    "print(\"- sample_indexed.vcf.gz (bgzip-compressed VCF for random access)\")\n",
    "print(\"- sample_indexed.vcf.gz.tbi (tabix index)\")\n",
    "print(\"- viz1_variants_by_chromosome_cyvcf2.png\")\n",
    "print(\"- viz2_variant_types_cyvcf2.png\")\n",
    "print(\"- viz3_quality_distribution_cyvcf2.png\")\n",
    "print(\"- viz4_af_vs_depth_cyvcf2.png\")\n",
    "print(\"- viz5_genomic_positions_cyvcf2.png\")\n",
    "print(\"- viz6_performance_comparison.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dee6a60-76a2-453f-8d36-d08e77b7672c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
