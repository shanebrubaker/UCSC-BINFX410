{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FASTA Parser - Comprehensive Tutorial\n",
    "\n",
    "This notebook demonstrates all features of the comprehensive FASTA parser toolkit.\n",
    "\n",
    "## Features Covered:\n",
    "- Parsing compressed and uncompressed FASTA files\n",
    "- Calculating statistics (N50, GC content, etc.)\n",
    "- Filtering and sorting sequences\n",
    "- Creating visualizations\n",
    "- Real-world bioinformatics workflows\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Installation\n",
    "\n",
    "First, ensure you have the required dependencies installed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages (uncomment if needed)\n",
    "# !pip install matplotlib numpy seaborn --break-system-packages\n",
    "\n",
    "# Import the FASTA parser\n",
    "from fasta_parser import FastaParser, FastaSequence\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Set up matplotlib for notebook\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"✓ All imports successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Generate Sample Data\n",
    "\n",
    "Let's create a sample FASTA file to work with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import gzip\n",
    "\n",
    "def generate_random_sequence(length):\n",
    "    \"\"\"Generate a random DNA sequence.\"\"\"\n",
    "    return ''.join(random.choices('ATGC', k=length))\n",
    "\n",
    "# Create a sample FASTA file\n",
    "with open('notebook_sample.fasta', 'w') as f:\n",
    "    for i in range(50):\n",
    "        # Vary sequence lengths\n",
    "        if i < 5:\n",
    "            length = random.randint(5000, 15000)  # Long sequences\n",
    "        elif i < 15:\n",
    "            length = random.randint(1000, 5000)   # Medium sequences\n",
    "        else:\n",
    "            length = random.randint(100, 1000)    # Short sequences\n",
    "        \n",
    "        seq = generate_random_sequence(length)\n",
    "        header = f\"sequence_{i+1} length={length} sample_data\"\n",
    "        \n",
    "        f.write(f\">{header}\\n\")\n",
    "        for j in range(0, len(seq), 80):\n",
    "            f.write(seq[j:j+80] + '\\n')\n",
    "\n",
    "# Also create a compressed version\n",
    "with gzip.open('notebook_sample.fasta.gz', 'wt') as f:\n",
    "    for i in range(20):\n",
    "        length = random.randint(500, 5000)\n",
    "        seq = generate_random_sequence(length)\n",
    "        header = f\"compressed_seq_{i+1} length={length}\"\n",
    "        f.write(f\">{header}\\n\")\n",
    "        for j in range(0, len(seq), 80):\n",
    "            f.write(seq[j:j+80] + '\\n')\n",
    "\n",
    "print(\"✓ Sample FASTA files created:\")\n",
    "print(\"  - notebook_sample.fasta (50 sequences)\")\n",
    "print(\"  - notebook_sample.fasta.gz (20 sequences, compressed)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Basic Parsing\n",
    "\n",
    "Let's parse a FASTA file and explore the basic functionality:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the FASTA file\n",
    "fasta = FastaParser()\n",
    "fasta.parse('notebook_sample.fasta')\n",
    "\n",
    "print(f\"Loaded {len(fasta)} sequences\\n\")\n",
    "\n",
    "# Access individual sequences\n",
    "first_seq = fasta[0]\n",
    "print(\"First sequence details:\")\n",
    "print(f\"  Header: {first_seq.header}\")\n",
    "print(f\"  ID: {first_seq.id}\")\n",
    "print(f\"  Length: {first_seq.length:,} bp\")\n",
    "print(f\"  GC Content: {first_seq.gc_content:.2f}%\")\n",
    "print(f\"  First 60 bp: {first_seq.sequence[:60]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Comprehensive Statistics\n",
    "\n",
    "Generate detailed statistics about the FASTA file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print comprehensive statistics\n",
    "fasta.print_statistics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Sequence Iteration\n",
    "\n",
    "The parser is iterable, making it easy to loop through sequences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through sequences\n",
    "print(\"Top 10 sequences by length:\\n\")\n",
    "for i, seq in enumerate(sorted(fasta, key=lambda x: x.length, reverse=True)[:10]):\n",
    "    print(f\"{i+1:2d}. {seq.id:20s} {seq.length:7,} bp  GC: {seq.gc_content:5.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Filtering Sequences\n",
    "\n",
    "Filter sequences by length or other criteria:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter sequences by length\n",
    "print(f\"Original: {len(fasta)} sequences\\n\")\n",
    "\n",
    "# Create a copy and filter\n",
    "fasta_filtered = FastaParser().parse('notebook_sample.fasta')\n",
    "fasta_filtered.filter_by_length(min_length=1000, max_length=10000)\n",
    "\n",
    "print(f\"After filtering (1000-10000 bp): {len(fasta_filtered)} sequences\")\n",
    "print(f\"Total bases: {sum(s.length for s in fasta_filtered):,}\")\n",
    "\n",
    "# Show some filtered sequences\n",
    "print(\"\\nFiltered sequences:\")\n",
    "for seq in fasta_filtered[:5]:\n",
    "    print(f\"  {seq.id}: {seq.length:,} bp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Sorting Sequences\n",
    "\n",
    "Sort sequences by different criteria:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by length (descending)\n",
    "fasta_by_length = FastaParser().parse('notebook_sample.fasta')\n",
    "fasta_by_length.sort_sequences(key='length', reverse=True)\n",
    "\n",
    "print(\"Sorted by LENGTH (longest first):\")\n",
    "for seq in fasta_by_length[:5]:\n",
    "    print(f\"  {seq.id:20s} {seq.length:7,} bp\")\n",
    "\n",
    "# Sort by GC content (descending)\n",
    "fasta_by_gc = FastaParser().parse('notebook_sample.fasta')\n",
    "fasta_by_gc.sort_sequences(key='gc_content', reverse=True)\n",
    "\n",
    "print(\"\\nSorted by GC CONTENT (highest first):\")\n",
    "for seq in fasta_by_gc[:5]:\n",
    "    print(f\"  {seq.id:20s} {seq.gc_content:5.2f}%\")\n",
    "\n",
    "# Sort by ID (alphabetical)\n",
    "fasta_by_id = FastaParser().parse('notebook_sample.fasta')\n",
    "fasta_by_id.sort_sequences(key='id', reverse=False)\n",
    "\n",
    "print(\"\\nSorted by ID (alphabetical):\")\n",
    "for seq in fasta_by_id[:5]:\n",
    "    print(f\"  {seq.id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Method Chaining\n",
    "\n",
    "The parser supports fluent method chaining:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method chaining example\n",
    "result = (FastaParser()\n",
    "    .parse('notebook_sample.fasta')\n",
    "    .filter_by_length(min_length=2000, max_length=8000)\n",
    "    .sort_sequences(key='gc_content', reverse=True))\n",
    "\n",
    "print(f\"Chained operations resulted in {len(result)} sequences\")\n",
    "print(\"\\nTop 3 by GC content (2-8kb range):\")\n",
    "for i, seq in enumerate(result[:3]):\n",
    "    print(f\"  {i+1}. {seq.id}: {seq.length:,} bp, GC={seq.gc_content:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Compressed File Handling\n",
    "\n",
    "The parser automatically handles compressed files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse compressed file\n",
    "fasta_compressed = FastaParser().parse('notebook_sample.fasta.gz')\n",
    "\n",
    "print(f\"Loaded {len(fasta_compressed)} sequences from compressed file\")\n",
    "print(f\"Total bases: {sum(s.length for s in fasta_compressed):,}\")\n",
    "\n",
    "# Statistics work the same way\n",
    "lengths = [s.length for s in fasta_compressed]\n",
    "print(f\"\\nLength range: {min(lengths):,} - {max(lengths):,} bp\")\n",
    "print(f\"Mean length: {np.mean(lengths):,.0f} bp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Comprehensive Visualization\n",
    "\n",
    "Generate a 6-panel visualization showing various analyses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive visualization\n",
    "fasta.visualize(output_file='notebook_analysis.png')\n",
    "\n",
    "# The visualization is also displayed inline in notebooks\n",
    "print(\"✓ Visualization created and saved to notebook_analysis.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Custom Analysis - GC Content Distribution\n",
    "\n",
    "Let's perform some custom analysis using the parsed data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Analyze GC content distribution\n",
    "gc_contents = [seq.gc_content for seq in fasta]\n",
    "lengths = [seq.length for seq in fasta]\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# GC content histogram\n",
    "ax1.hist(gc_contents, bins=20, color='seagreen', edgecolor='black', alpha=0.7)\n",
    "ax1.axvline(np.mean(gc_contents), color='red', linestyle='--', linewidth=2, label=f'Mean: {np.mean(gc_contents):.1f}%')\n",
    "ax1.axvline(np.median(gc_contents), color='blue', linestyle='--', linewidth=2, label=f'Median: {np.median(gc_contents):.1f}%')\n",
    "ax1.set_xlabel('GC Content (%)', fontsize=12)\n",
    "ax1.set_ylabel('Frequency', fontsize=12)\n",
    "ax1.set_title('GC Content Distribution', fontsize=14, fontweight='bold')\n",
    "ax1.legend()\n",
    "ax1.grid(alpha=0.3)\n",
    "\n",
    "# Length vs GC scatter with regression line\n",
    "ax2.scatter(lengths, gc_contents, alpha=0.6, s=80, c=gc_contents, cmap='viridis', edgecolors='black', linewidth=0.5)\n",
    "z = np.polyfit(lengths, gc_contents, 1)\n",
    "p = np.poly1d(z)\n",
    "ax2.plot(lengths, p(lengths), \"r--\", alpha=0.8, linewidth=2, label=f'Trend: y={z[0]:.2e}x+{z[1]:.2f}')\n",
    "ax2.set_xlabel('Sequence Length (bp)', fontsize=12)\n",
    "ax2.set_ylabel('GC Content (%)', fontsize=12)\n",
    "ax2.set_title('Length vs GC Content Correlation', fontsize=14, fontweight='bold')\n",
    "ax2.legend()\n",
    "ax2.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('custom_gc_analysis.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Calculate correlation\n",
    "correlation = np.corrcoef(lengths, gc_contents)[0, 1]\n",
    "print(f\"Correlation between length and GC content: {correlation:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Writing Sorted Output\n",
    "\n",
    "Write sorted sequences to new FASTA files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by length and write to file\n",
    "fasta_to_write = FastaParser().parse('notebook_sample.fasta')\n",
    "fasta_to_write.sort_sequences(key='length', reverse=True)\n",
    "fasta_to_write.write('sorted_by_length.fasta')\n",
    "\n",
    "print(\"✓ Written sorted_by_length.fasta\")\n",
    "\n",
    "# Also write compressed version\n",
    "fasta_to_write.write('sorted_by_length.fasta.gz')\n",
    "print(\"✓ Written sorted_by_length.fasta.gz (compressed)\")\n",
    "\n",
    "# Verify by reading back\n",
    "verify = FastaParser().parse('sorted_by_length.fasta')\n",
    "print(f\"\\nVerification: Read back {len(verify)} sequences\")\n",
    "print(f\"First sequence length: {verify[0].length:,} bp (should be longest)\")\n",
    "print(f\"Last sequence length: {verify[-1].length:,} bp (should be shortest)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Sequence Retrieval by ID\n",
    "\n",
    "Find specific sequences by their ID:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get sequence by ID\n",
    "seq_id = 'sequence_1'\n",
    "seq = fasta.get_sequence_by_id(seq_id)\n",
    "\n",
    "if seq:\n",
    "    print(f\"Found sequence: {seq_id}\")\n",
    "    print(f\"  Length: {seq.length:,} bp\")\n",
    "    print(f\"  GC Content: {seq.gc_content:.2f}%\")\n",
    "    print(f\"  First 80 bp: {seq.sequence[:80]}\")\n",
    "else:\n",
    "    print(f\"Sequence {seq_id} not found\")\n",
    "\n",
    "# Search for sequences matching a pattern\n",
    "print(\"\\nAll sequences with 'sequence_1' in ID:\")\n",
    "matches = [s for s in fasta if 'sequence_1' in s.id]\n",
    "for s in matches:\n",
    "    print(f\"  {s.id}: {s.length:,} bp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Real-World Workflow: Assembly QC\n",
    "\n",
    "A practical example of assembly quality control:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assembly_qc(fasta_parser):\n",
    "    \"\"\"Perform quality control checks on an assembly.\"\"\"\n",
    "    print(\"=\" * 70)\n",
    "    print(\"ASSEMBLY QUALITY CONTROL\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    lengths = [s.length for s in fasta_parser]\n",
    "    gc_contents = [s.gc_content for s in fasta_parser]\n",
    "    \n",
    "    # Basic metrics\n",
    "    print(f\"\\nBasic Metrics:\")\n",
    "    print(f\"  Total sequences: {len(fasta_parser):,}\")\n",
    "    print(f\"  Total bases: {sum(lengths):,}\")\n",
    "    print(f\"  N50: {fasta_parser._calculate_n50(lengths):,} bp\")\n",
    "    \n",
    "    # Quality checks\n",
    "    print(f\"\\nQuality Checks:\")\n",
    "    \n",
    "    # Check for short contigs\n",
    "    short = sum(1 for l in lengths if l < 500)\n",
    "    if short > 0:\n",
    "        print(f\"  ⚠ {short} sequences < 500 bp ({short/len(fasta_parser)*100:.1f}%)\")\n",
    "    else:\n",
    "        print(f\"  ✓ No sequences < 500 bp\")\n",
    "    \n",
    "    # Check for extreme GC content\n",
    "    extreme_gc = sum(1 for gc in gc_contents if gc < 20 or gc > 80)\n",
    "    if extreme_gc > 0:\n",
    "        print(f\"  ⚠ {extreme_gc} sequences with extreme GC content\")\n",
    "    else:\n",
    "        print(f\"  ✓ All sequences have reasonable GC content\")\n",
    "    \n",
    "    # Assembly fragmentation\n",
    "    if len(fasta_parser) > 1000:\n",
    "        print(f\"  ⚠ Highly fragmented assembly ({len(fasta_parser):,} sequences)\")\n",
    "    else:\n",
    "        print(f\"  ✓ Assembly fragmentation is reasonable\")\n",
    "    \n",
    "    # Length distribution\n",
    "    print(f\"\\nLength Distribution:\")\n",
    "    print(f\"  Longest: {max(lengths):,} bp\")\n",
    "    print(f\"  Shortest: {min(lengths):,} bp\")\n",
    "    print(f\"  Mean: {np.mean(lengths):,.0f} bp\")\n",
    "    print(f\"  Median: {np.median(lengths):,.0f} bp\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "\n",
    "# Run QC on our sample data\n",
    "assembly_qc(fasta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15. Real-World Workflow: Size Selection\n",
    "\n",
    "Create size-selected sequence libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_size_libraries(input_file):\n",
    "    \"\"\"Create size-selected libraries.\"\"\"\n",
    "    print(\"Creating size-selected libraries...\\n\")\n",
    "    \n",
    "    bins = [\n",
    "        (0, 500, \"very_short\"),\n",
    "        (500, 2000, \"short\"),\n",
    "        (2000, 5000, \"medium\"),\n",
    "        (5000, float('inf'), \"long\")\n",
    "    ]\n",
    "    \n",
    "    for min_len, max_len, name in bins:\n",
    "        lib = FastaParser().parse(input_file)\n",
    "        lib.filter_by_length(min_length=min_len, max_length=max_len)\n",
    "        \n",
    "        if len(lib) > 0:\n",
    "            filename = f\"{name}_library.fasta\"\n",
    "            lib.write(filename)\n",
    "            \n",
    "            print(f\"{name.upper()} ({min_len:,}-{max_len:,} bp):\")\n",
    "            print(f\"  Sequences: {len(lib):,}\")\n",
    "            print(f\"  Total bases: {sum(s.length for s in lib):,}\")\n",
    "            print(f\"  File: {filename}\")\n",
    "            print()\n",
    "\n",
    "create_size_libraries('notebook_sample.fasta')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16. Advanced: Outlier Detection\n",
    "\n",
    "Identify sequences that are statistical outliers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_outliers(fasta_parser, threshold=3):\n",
    "    \"\"\"Detect outliers using Z-score.\"\"\"\n",
    "    lengths = [s.length for s in fasta_parser]\n",
    "    gc_contents = [s.gc_content for s in fasta_parser]\n",
    "    \n",
    "    mean_len = np.mean(lengths)\n",
    "    std_len = np.std(lengths)\n",
    "    \n",
    "    mean_gc = np.mean(gc_contents)\n",
    "    std_gc = np.std(gc_contents)\n",
    "    \n",
    "    print(f\"Outlier Detection (|Z-score| > {threshold})\\n\")\n",
    "    \n",
    "    # Length outliers\n",
    "    print(\"LENGTH OUTLIERS:\")\n",
    "    length_outliers = []\n",
    "    for seq in fasta_parser:\n",
    "        z_score = (seq.length - mean_len) / std_len\n",
    "        if abs(z_score) > threshold:\n",
    "            length_outliers.append((seq, z_score))\n",
    "    \n",
    "    if length_outliers:\n",
    "        for seq, z in sorted(length_outliers, key=lambda x: abs(x[1]), reverse=True):\n",
    "            print(f\"  {seq.id:20s} {seq.length:7,} bp  Z={z:+.2f}\")\n",
    "    else:\n",
    "        print(\"  None detected\")\n",
    "    \n",
    "    # GC outliers\n",
    "    print(\"\\nGC CONTENT OUTLIERS:\")\n",
    "    gc_outliers = []\n",
    "    for seq in fasta_parser:\n",
    "        z_score = (seq.gc_content - mean_gc) / std_gc\n",
    "        if abs(z_score) > threshold:\n",
    "            gc_outliers.append((seq, z_score))\n",
    "    \n",
    "    if gc_outliers:\n",
    "        for seq, z in sorted(gc_outliers, key=lambda x: abs(x[1]), reverse=True):\n",
    "            print(f\"  {seq.id:20s} {seq.gc_content:5.2f}%  Z={z:+.2f}\")\n",
    "    else:\n",
    "        print(\"  None detected\")\n",
    "\n",
    "detect_outliers(fasta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 17. Comparison of Different Assemblies\n",
    "\n",
    "Compare statistics between different FASTA files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_assemblies(file1, file2):\n",
    "    \"\"\"Compare two assemblies.\"\"\"\n",
    "    f1 = FastaParser().parse(file1)\n",
    "    f2 = FastaParser().parse(file2)\n",
    "    \n",
    "    lengths1 = [s.length for s in f1]\n",
    "    lengths2 = [s.length for s in f2]\n",
    "    \n",
    "    print(\"=\" * 70)\n",
    "    print(\"ASSEMBLY COMPARISON\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    print(f\"\\nFile 1: {file1}\")\n",
    "    print(f\"  Sequences: {len(f1):,}\")\n",
    "    print(f\"  Total bases: {sum(lengths1):,}\")\n",
    "    print(f\"  N50: {f1._calculate_n50(lengths1):,} bp\")\n",
    "    print(f\"  Longest: {max(lengths1):,} bp\")\n",
    "    \n",
    "    print(f\"\\nFile 2: {file2}\")\n",
    "    print(f\"  Sequences: {len(f2):,}\")\n",
    "    print(f\"  Total bases: {sum(lengths2):,}\")\n",
    "    print(f\"  N50: {f2._calculate_n50(lengths2):,} bp\")\n",
    "    print(f\"  Longest: {max(lengths2):,} bp\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "\n",
    "# Compare original and compressed files\n",
    "compare_assemblies('notebook_sample.fasta', 'notebook_sample.fasta.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 18. Summary and Next Steps\n",
    "\n",
    "### What We've Covered:\n",
    "\n",
    "1. ✅ Basic parsing of FASTA files\n",
    "2. ✅ Accessing sequence properties (length, GC%, etc.)\n",
    "3. ✅ Comprehensive statistics and N50 calculation\n",
    "4. ✅ Filtering sequences by length\n",
    "5. ✅ Sorting by multiple criteria\n",
    "6. ✅ Handling compressed files (.gz)\n",
    "7. ✅ Creating visualizations\n",
    "8. ✅ Writing sorted output\n",
    "9. ✅ Custom analyses and quality control\n",
    "10. ✅ Real-world bioinformatics workflows\n",
    "\n",
    "### Key Takeaways:\n",
    "\n",
    "- The parser handles both compressed and uncompressed files automatically\n",
    "- Method chaining enables clean, readable code\n",
    "- FastaSequence objects provide easy access to sequence properties\n",
    "- Comprehensive statistics help assess assembly quality\n",
    "- Visualizations provide quick insights into sequence characteristics\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "1. Try with your own FASTA files\n",
    "2. Customize the visualizations for your needs\n",
    "3. Integrate into your existing workflows\n",
    "4. Extend with additional analyses\n",
    "5. Combine with other bioinformatics tools\n",
    "\n",
    "### Additional Resources:\n",
    "\n",
    "- See `README.md` for complete API documentation\n",
    "- Check `QUICK_REFERENCE.txt` for common patterns\n",
    "- Review `bioinformatics_examples.py` for more workflows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 19. Cleanup (Optional)\n",
    "\n",
    "Remove generated files if desired:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Uncomment to clean up generated files\n",
    "# files_to_remove = [\n",
    "#     'notebook_sample.fasta',\n",
    "#     'notebook_sample.fasta.gz',\n",
    "#     'sorted_by_length.fasta',\n",
    "#     'sorted_by_length.fasta.gz',\n",
    "#     'notebook_analysis.png',\n",
    "#     'custom_gc_analysis.png',\n",
    "#     'very_short_library.fasta',\n",
    "#     'short_library.fasta',\n",
    "#     'medium_library.fasta',\n",
    "#     'long_library.fasta'\n",
    "# ]\n",
    "\n",
    "# for f in files_to_remove:\n",
    "#     if os.path.exists(f):\n",
    "#         os.remove(f)\n",
    "#         print(f\"Removed {f}\")\n",
    "\n",
    "print(\"Notebook complete! Check the generated files for results.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
