{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PostgreSQL SQL Warmups: Clinical Sequencing QC Data\n",
    "\n",
    "## Installation Instructions for PostgreSQL on Mac\n",
    "\n",
    "### Step 1: Install PostgreSQL using Homebrew\n",
    "\n",
    "```bash\n",
    "# Install Homebrew if not already installed\n",
    "/bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\"\n",
    "\n",
    "# Install PostgreSQL\n",
    "brew install postgresql@15\n",
    "\n",
    "# Add PostgreSQL to your PATH\n",
    "echo 'export PATH=\"/opt/homebrew/opt/postgresql@15/bin:$PATH\"' >> ~/.zshrc\n",
    "source ~/.zshrc\n",
    "```\n",
    "\n",
    "### Step 2: Start PostgreSQL Service\n",
    "\n",
    "```bash\n",
    "# Start PostgreSQL service\n",
    "brew services start postgresql@15\n",
    "\n",
    "# Verify it's running\n",
    "brew services list | grep postgresql\n",
    "```\n",
    "\n",
    "### Step 3: Create a Practice Database\n",
    "\n",
    "```bash\n",
    "# Create a database called 'sequencing_qc'\n",
    "createdb sequencing_qc\n",
    "\n",
    "# Test connection\n",
    "psql sequencing_qc -c \"SELECT version();\"\n",
    "```\n",
    "\n",
    "### Step 4: Install Python Dependencies\n",
    "\n",
    "```bash\n",
    "pip install psycopg2-binary pandas matplotlib seaborn jupyter\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup: Import Libraries and Connect to Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "from psycopg2 import sql\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set plotting style\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (10, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Database connection parameters\n",
    "DB_NAME = \"sequencing_qc\"\n",
    "DB_USER = \"your_username\"  # Usually your Mac username, or 'postgres'\n",
    "DB_HOST = \"localhost\"\n",
    "DB_PORT = \"5432\"\n",
    "\n",
    "# Create connection\n",
    "def get_connection():\n",
    "    return psycopg2.connect(\n",
    "        dbname=DB_NAME,\n",
    "        user=DB_USER,\n",
    "        host=DB_HOST,\n",
    "        port=DB_PORT\n",
    "    )\n",
    "\n",
    "# Test connection\n",
    "try:\n",
    "    conn = get_connection()\n",
    "    print(\"✓ Successfully connected to PostgreSQL!\")\n",
    "    conn.close()\n",
    "except Exception as e:\n",
    "    print(f\"✗ Connection failed: {e}\")\n",
    "    print(\"\\nTip: You may need to update DB_USER to your Mac username.\")\n",
    "    print(\"Run this in terminal to find it: whoami\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Database Schema Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tables for clinical sequencing QC data\n",
    "schema_sql = \"\"\"\n",
    "DROP TABLE IF EXISTS variant_calls CASCADE;\n",
    "DROP TABLE IF EXISTS coverage_metrics CASCADE;\n",
    "DROP TABLE IF EXISTS sequencing_runs CASCADE;\n",
    "DROP TABLE IF EXISTS samples CASCADE;\n",
    "DROP TABLE IF EXISTS patients CASCADE;\n",
    "\n",
    "-- Patients table\n",
    "CREATE TABLE patients (\n",
    "    patient_id VARCHAR(20) PRIMARY KEY,\n",
    "    age INTEGER,\n",
    "    gender VARCHAR(10),\n",
    "    clinical_indication TEXT\n",
    ");\n",
    "\n",
    "-- Samples table\n",
    "CREATE TABLE samples (\n",
    "    sample_id VARCHAR(20) PRIMARY KEY,\n",
    "    patient_id VARCHAR(20) REFERENCES patients(patient_id),\n",
    "    sample_type VARCHAR(50),\n",
    "    collection_date DATE,\n",
    "    tumor_purity DECIMAL(5,2)\n",
    ");\n",
    "\n",
    "-- Sequencing runs table\n",
    "CREATE TABLE sequencing_runs (\n",
    "    run_id VARCHAR(30) PRIMARY KEY,\n",
    "    sample_id VARCHAR(20) REFERENCES samples(sample_id),\n",
    "    sequencer VARCHAR(50),\n",
    "    run_date DATE,\n",
    "    flowcell_id VARCHAR(30),\n",
    "    total_reads BIGINT,\n",
    "    mapped_reads BIGINT,\n",
    "    duplicate_reads BIGINT,\n",
    "    properly_paired_reads BIGINT,\n",
    "    mean_insert_size DECIMAL(8,2),\n",
    "    q30_bases_pct DECIMAL(5,2),\n",
    "    contamination_pct DECIMAL(5,3),\n",
    "    pass_qc BOOLEAN\n",
    ");\n",
    "\n",
    "-- Coverage metrics table\n",
    "CREATE TABLE coverage_metrics (\n",
    "    metric_id SERIAL PRIMARY KEY,\n",
    "    run_id VARCHAR(30) REFERENCES sequencing_runs(run_id),\n",
    "    chromosome VARCHAR(10),\n",
    "    mean_coverage DECIMAL(8,2),\n",
    "    median_coverage DECIMAL(8,2),\n",
    "    pct_bases_10x DECIMAL(5,2),\n",
    "    pct_bases_20x DECIMAL(5,2),\n",
    "    pct_bases_30x DECIMAL(5,2),\n",
    "    uniformity DECIMAL(5,2)\n",
    ");\n",
    "\n",
    "-- Variant calls table\n",
    "CREATE TABLE variant_calls (\n",
    "    variant_id SERIAL PRIMARY KEY,\n",
    "    run_id VARCHAR(30) REFERENCES sequencing_runs(run_id),\n",
    "    chromosome VARCHAR(10),\n",
    "    position INTEGER,\n",
    "    ref_allele VARCHAR(255),\n",
    "    alt_allele VARCHAR(255),\n",
    "    variant_type VARCHAR(20),\n",
    "    quality_score DECIMAL(8,2),\n",
    "    depth INTEGER,\n",
    "    allele_frequency DECIMAL(5,4),\n",
    "    gene_name VARCHAR(50),\n",
    "    clinical_significance VARCHAR(50)\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "conn = get_connection()\n",
    "cur = conn.cursor()\n",
    "\n",
    "try:\n",
    "    cur.execute(schema_sql)\n",
    "    conn.commit()\n",
    "    print(\"✓ Database schema created successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ Error creating schema: {e}\")\n",
    "    conn.rollback()\n",
    "finally:\n",
    "    cur.close()\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Populate Database with Faux Clinical Sequencing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate realistic sequencing QC data for 10 clinical samples\n",
    "np.random.seed(42)\n",
    "\n",
    "conn = get_connection()\n",
    "cur = conn.cursor()\n",
    "\n",
    "# Clinical indications pool\n",
    "indications = [\n",
    "    'Breast cancer screening',\n",
    "    'Colorectal cancer',\n",
    "    'Hereditary cancer syndrome',\n",
    "    'Lung adenocarcinoma',\n",
    "    'Prostate cancer',\n",
    "    'Ovarian cancer',\n",
    "    'Melanoma',\n",
    "    'Lynch syndrome screening'\n",
    "]\n",
    "\n",
    "# Insert patients\n",
    "patients_data = []\n",
    "for i in range(10):\n",
    "    patient_id = f\"PT{1000+i}\"\n",
    "    age = np.random.randint(35, 75)\n",
    "    gender = np.random.choice(['Male', 'Female'])\n",
    "    indication = np.random.choice(indications)\n",
    "    patients_data.append((patient_id, age, gender, indication))\n",
    "\n",
    "cur.executemany(\n",
    "    \"INSERT INTO patients VALUES (%s, %s, %s, %s)\",\n",
    "    patients_data\n",
    ")\n",
    "\n",
    "# Insert samples\n",
    "samples_data = []\n",
    "sample_types = ['Blood', 'Tumor tissue', 'Saliva', 'Buccal swab']\n",
    "base_date = datetime(2024, 1, 1)\n",
    "\n",
    "for i, (patient_id, _, _, _) in enumerate(patients_data):\n",
    "    sample_id = f\"SAM{2000+i}\"\n",
    "    sample_type = np.random.choice(sample_types)\n",
    "    collection_date = base_date + timedelta(days=np.random.randint(0, 365))\n",
    "    tumor_purity = np.random.uniform(30, 95) if 'tumor' in sample_type.lower() else None\n",
    "    samples_data.append((sample_id, patient_id, sample_type, collection_date, tumor_purity))\n",
    "\n",
    "cur.executemany(\n",
    "    \"INSERT INTO samples VALUES (%s, %s, %s, %s, %s)\",\n",
    "    samples_data\n",
    ")\n",
    "\n",
    "# Insert sequencing runs\n",
    "sequencers = ['NovaSeq 6000', 'NextSeq 550', 'MiSeq']\n",
    "runs_data = []\n",
    "\n",
    "for i, (sample_id, _, _, _, _) in enumerate(samples_data):\n",
    "    run_id = f\"RUN_{datetime.now().strftime('%Y%m%d')}_{i+1:03d}\"\n",
    "    sequencer = np.random.choice(sequencers)\n",
    "    run_date = base_date + timedelta(days=np.random.randint(0, 365))\n",
    "    flowcell_id = f\"FC{np.random.randint(100000, 999999)}\"\n",
    "    \n",
    "    # Generate realistic read counts based on sequencer\n",
    "    if 'NovaSeq' in sequencer:\n",
    "        total_reads = np.random.randint(250_000_000, 350_000_000)\n",
    "    elif 'NextSeq' in sequencer:\n",
    "        total_reads = np.random.randint(80_000_000, 120_000_000)\n",
    "    else:  # MiSeq\n",
    "        total_reads = np.random.randint(15_000_000, 25_000_000)\n",
    "    \n",
    "    mapping_rate = np.random.uniform(0.92, 0.99)\n",
    "    mapped_reads = int(total_reads * mapping_rate)\n",
    "    duplicate_rate = np.random.uniform(0.05, 0.25)\n",
    "    duplicate_reads = int(mapped_reads * duplicate_rate)\n",
    "    properly_paired = int(mapped_reads * np.random.uniform(0.95, 0.99))\n",
    "    \n",
    "    mean_insert_size = np.random.uniform(300, 450)\n",
    "    q30_bases_pct = np.random.uniform(85, 95)\n",
    "    contamination_pct = np.random.uniform(0.1, 2.5)\n",
    "    pass_qc = contamination_pct < 2.0 and q30_bases_pct > 80 and mapping_rate > 0.90\n",
    "    \n",
    "    runs_data.append((\n",
    "        run_id, sample_id, sequencer, run_date, flowcell_id,\n",
    "        total_reads, mapped_reads, duplicate_reads, properly_paired,\n",
    "        mean_insert_size, q30_bases_pct, contamination_pct, pass_qc\n",
    "    ))\n",
    "\n",
    "cur.executemany(\n",
    "    \"\"\"INSERT INTO sequencing_runs VALUES \n",
    "       (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\"\"\",\n",
    "    runs_data\n",
    ")\n",
    "\n",
    "# Insert coverage metrics\n",
    "chromosomes = [str(i) for i in range(1, 23)] + ['X', 'Y']\n",
    "coverage_data = []\n",
    "\n",
    "for run_id, _, _, _, _, _, _, _, _, _, _, _, _ in runs_data:\n",
    "    base_coverage = np.random.uniform(80, 150)\n",
    "    for chrom in chromosomes:\n",
    "        # Add variation per chromosome\n",
    "        mean_cov = base_coverage * np.random.uniform(0.8, 1.2)\n",
    "        median_cov = mean_cov * np.random.uniform(0.95, 1.05)\n",
    "        pct_10x = np.random.uniform(95, 99.9)\n",
    "        pct_20x = np.random.uniform(92, 99.5)\n",
    "        pct_30x = np.random.uniform(88, 98)\n",
    "        uniformity = np.random.uniform(75, 95)\n",
    "        \n",
    "        coverage_data.append((\n",
    "            run_id, chrom, mean_cov, median_cov,\n",
    "            pct_10x, pct_20x, pct_30x, uniformity\n",
    "        ))\n",
    "\n",
    "cur.executemany(\n",
    "    \"\"\"INSERT INTO coverage_metrics \n",
    "       (run_id, chromosome, mean_coverage, median_coverage, \n",
    "        pct_bases_10x, pct_bases_20x, pct_bases_30x, uniformity)\n",
    "       VALUES (%s, %s, %s, %s, %s, %s, %s, %s)\"\"\",\n",
    "    coverage_data\n",
    ")\n",
    "\n",
    "# Insert variant calls\n",
    "variant_types = ['SNV', 'INDEL', 'MNV']\n",
    "genes = ['BRCA1', 'BRCA2', 'TP53', 'KRAS', 'EGFR', 'PIK3CA', 'PTEN', 'APC', 'MLH1', 'MSH2']\n",
    "clinical_sig = ['Pathogenic', 'Likely pathogenic', 'VUS', 'Likely benign', 'Benign']\n",
    "variants_data = []\n",
    "\n",
    "for run_id, _, _, _, _, _, _, _, _, _, _, _, _ in runs_data:\n",
    "    # Generate 50-200 variants per sample\n",
    "    num_variants = np.random.randint(50, 200)\n",
    "    \n",
    "    for _ in range(num_variants):\n",
    "        chrom = np.random.choice(chromosomes[:22])  # Autosomes only for simplicity\n",
    "        position = np.random.randint(1000000, 200000000)\n",
    "        \n",
    "        var_type = np.random.choice(variant_types, p=[0.85, 0.13, 0.02])\n",
    "        \n",
    "        if var_type == 'SNV':\n",
    "            bases = ['A', 'C', 'G', 'T']\n",
    "            ref = np.random.choice(bases)\n",
    "            alt = np.random.choice([b for b in bases if b != ref])\n",
    "        elif var_type == 'INDEL':\n",
    "            if np.random.random() < 0.5:  # Deletion\n",
    "                ref = ''.join(np.random.choice(['A','C','G','T'], size=np.random.randint(1,10)))\n",
    "                alt = ref[0]\n",
    "            else:  # Insertion\n",
    "                ref = np.random.choice(['A','C','G','T'])\n",
    "                alt = ref + ''.join(np.random.choice(['A','C','G','T'], size=np.random.randint(1,10)))\n",
    "        else:  # MNV\n",
    "            ref = ''.join(np.random.choice(['A','C','G','T'], size=2))\n",
    "            alt = ''.join(np.random.choice(['A','C','G','T'], size=2))\n",
    "        \n",
    "        quality = np.random.uniform(30, 500)\n",
    "        depth = int(np.random.uniform(50, 300))\n",
    "        allele_freq = np.random.uniform(0.05, 0.95)\n",
    "        gene = np.random.choice(genes)\n",
    "        significance = np.random.choice(clinical_sig, p=[0.05, 0.10, 0.50, 0.20, 0.15])\n",
    "        \n",
    "        variants_data.append((\n",
    "            run_id, chrom, position, ref, alt, var_type,\n",
    "            quality, depth, allele_freq, gene, significance\n",
    "        ))\n",
    "\n",
    "# Insert in batches for efficiency\n",
    "batch_size = 1000\n",
    "for i in range(0, len(variants_data), batch_size):\n",
    "    batch = variants_data[i:i+batch_size]\n",
    "    cur.executemany(\n",
    "        \"\"\"INSERT INTO variant_calls \n",
    "           (run_id, chromosome, position, ref_allele, alt_allele, variant_type,\n",
    "            quality_score, depth, allele_frequency, gene_name, clinical_significance)\n",
    "           VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\"\"\",\n",
    "        batch\n",
    "    )\n",
    "\n",
    "conn.commit()\n",
    "print(\"✓ Database populated successfully!\")\n",
    "print(f\"  - {len(patients_data)} patients\")\n",
    "print(f\"  - {len(samples_data)} samples\")\n",
    "print(f\"  - {len(runs_data)} sequencing runs\")\n",
    "print(f\"  - {len(coverage_data)} coverage metrics\")\n",
    "print(f\"  - {len(variants_data)} variant calls\")\n",
    "\n",
    "cur.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# SQL Warmup Exercises\n",
    "\n",
    "## Basic SELECT Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Warmup 1: Select all patients\n",
    "query = \"SELECT * FROM patients;\"\n",
    "\n",
    "df = pd.read_sql(query, get_connection())\n",
    "print(f\"Query 1: Retrieved {len(df)} patients\\n\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Warmup 2: Select specific columns from samples\n",
    "query = \"SELECT sample_id, patient_id, sample_type, collection_date FROM samples;\"\n",
    "\n",
    "df = pd.read_sql(query, get_connection())\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Warmup 3: Count total number of sequencing runs\n",
    "query = \"SELECT COUNT(*) as total_runs FROM sequencing_runs;\"\n",
    "\n",
    "df = pd.read_sql(query, get_connection())\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WHERE Clause Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Warmup 4: Find all female patients\n",
    "query = \"SELECT * FROM patients WHERE gender = 'Female';\"\n",
    "\n",
    "df = pd.read_sql(query, get_connection())\n",
    "print(f\"Found {len(df)} female patients\\n\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Warmup 5: Find runs that passed QC\n",
    "query = \"SELECT run_id, sample_id, sequencer, pass_qc FROM sequencing_runs WHERE pass_qc = TRUE;\"\n",
    "\n",
    "df = pd.read_sql(query, get_connection())\n",
    "print(f\"Runs passing QC: {len(df)}\\n\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Warmup 6: Find patients older than 60\n",
    "query = \"SELECT patient_id, age, gender, clinical_indication FROM patients WHERE age > 60;\"\n",
    "\n",
    "df = pd.read_sql(query, get_connection())\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Warmup 7: Find runs with high Q30 percentage (>90%)\n",
    "query = \"\"\"\n",
    "SELECT run_id, sample_id, q30_bases_pct, sequencer \n",
    "FROM sequencing_runs \n",
    "WHERE q30_bases_pct > 90\n",
    "ORDER BY q30_bases_pct DESC;\n",
    "\"\"\"\n",
    "\n",
    "df = pd.read_sql(query, get_connection())\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Warmup 8: Calculate average age of patients\n",
    "query = \"SELECT AVG(age) as average_age, MIN(age) as min_age, MAX(age) as max_age FROM patients;\"\n",
    "\n",
    "df = pd.read_sql(query, get_connection())\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Warmup 9: Get total and average reads per sequencer\n",
    "query = \"\"\"\n",
    "SELECT \n",
    "    sequencer,\n",
    "    COUNT(*) as num_runs,\n",
    "    AVG(total_reads) as avg_reads,\n",
    "    AVG(q30_bases_pct) as avg_q30\n",
    "FROM sequencing_runs\n",
    "GROUP BY sequencer\n",
    "ORDER BY avg_reads DESC;\n",
    "\"\"\"\n",
    "\n",
    "df = pd.read_sql(query, get_connection())\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Warmup 10: Count samples by type\n",
    "query = \"\"\"\n",
    "SELECT sample_type, COUNT(*) as count \n",
    "FROM samples \n",
    "GROUP BY sample_type\n",
    "ORDER BY count DESC;\n",
    "\"\"\"\n",
    "\n",
    "df = pd.read_sql(query, get_connection())\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JOIN Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Warmup 11: Join patients and samples\n",
    "query = \"\"\"\n",
    "SELECT \n",
    "    p.patient_id,\n",
    "    p.age,\n",
    "    p.gender,\n",
    "    s.sample_id,\n",
    "    s.sample_type\n",
    "FROM patients p\n",
    "JOIN samples s ON p.patient_id = s.patient_id;\n",
    "\"\"\"\n",
    "\n",
    "df = pd.read_sql(query, get_connection())\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Warmup 12: Join samples and sequencing runs with QC info\n",
    "query = \"\"\"\n",
    "SELECT \n",
    "    s.sample_id,\n",
    "    s.sample_type,\n",
    "    sr.run_id,\n",
    "    sr.sequencer,\n",
    "    sr.pass_qc,\n",
    "    sr.contamination_pct\n",
    "FROM samples s\n",
    "JOIN sequencing_runs sr ON s.sample_id = sr.sample_id;\n",
    "\"\"\"\n",
    "\n",
    "df = pd.read_sql(query, get_connection())\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Warmup 13: Three-table join - patients, samples, runs\n",
    "query = \"\"\"\n",
    "SELECT \n",
    "    p.patient_id,\n",
    "    p.clinical_indication,\n",
    "    s.sample_id,\n",
    "    sr.run_id,\n",
    "    sr.total_reads,\n",
    "    sr.pass_qc\n",
    "FROM patients p\n",
    "JOIN samples s ON p.patient_id = s.patient_id\n",
    "JOIN sequencing_runs sr ON s.sample_id = sr.sample_id\n",
    "ORDER BY p.patient_id;\n",
    "\"\"\"\n",
    "\n",
    "df = pd.read_sql(query, get_connection())\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Filtering and Calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Warmup 14: Calculate mapping percentage\n",
    "query = \"\"\"\n",
    "SELECT \n",
    "    run_id,\n",
    "    total_reads,\n",
    "    mapped_reads,\n",
    "    ROUND((mapped_reads::NUMERIC / total_reads * 100), 2) as mapping_pct\n",
    "FROM sequencing_runs\n",
    "ORDER BY mapping_pct DESC;\n",
    "\"\"\"\n",
    "\n",
    "df = pd.read_sql(query, get_connection())\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Warmup 15: Calculate duplicate percentage\n",
    "query = \"\"\"\n",
    "SELECT \n",
    "    run_id,\n",
    "    sequencer,\n",
    "    duplicate_reads,\n",
    "    mapped_reads,\n",
    "    ROUND((duplicate_reads::NUMERIC / mapped_reads * 100), 2) as duplicate_pct\n",
    "FROM sequencing_runs\n",
    "ORDER BY duplicate_pct DESC;\n",
    "\"\"\"\n",
    "\n",
    "df = pd.read_sql(query, get_connection())\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Warmup 16: Find pathogenic variants\n",
    "query = \"\"\"\n",
    "SELECT \n",
    "    gene_name,\n",
    "    COUNT(*) as variant_count,\n",
    "    AVG(quality_score) as avg_quality\n",
    "FROM variant_calls\n",
    "WHERE clinical_significance IN ('Pathogenic', 'Likely pathogenic')\n",
    "GROUP BY gene_name\n",
    "ORDER BY variant_count DESC;\n",
    "\"\"\"\n",
    "\n",
    "df = pd.read_sql(query, get_connection())\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Warmup 17: Coverage statistics by chromosome\n",
    "query = \"\"\"\n",
    "SELECT \n",
    "    chromosome,\n",
    "    AVG(mean_coverage) as avg_coverage,\n",
    "    AVG(uniformity) as avg_uniformity,\n",
    "    AVG(pct_bases_30x) as avg_30x_coverage\n",
    "FROM coverage_metrics\n",
    "GROUP BY chromosome\n",
    "ORDER BY \n",
    "    CASE \n",
    "        WHEN chromosome ~ '^[0-9]+$' THEN chromosome::INTEGER\n",
    "        ELSE 999 \n",
    "    END,\n",
    "    chromosome;\n",
    "\"\"\"\n",
    "\n",
    "df = pd.read_sql(query, get_connection())\n",
    "df.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subqueries and Complex Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Warmup 18: Find runs with above-average read counts\n",
    "query = \"\"\"\n",
    "SELECT run_id, total_reads, sequencer\n",
    "FROM sequencing_runs\n",
    "WHERE total_reads > (SELECT AVG(total_reads) FROM sequencing_runs)\n",
    "ORDER BY total_reads DESC;\n",
    "\"\"\"\n",
    "\n",
    "df = pd.read_sql(query, get_connection())\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Warmup 19: Samples with multiple variants in cancer genes\n",
    "query = \"\"\"\n",
    "SELECT \n",
    "    run_id,\n",
    "    gene_name,\n",
    "    COUNT(*) as variant_count\n",
    "FROM variant_calls\n",
    "WHERE gene_name IN ('BRCA1', 'BRCA2', 'TP53', 'KRAS')\n",
    "GROUP BY run_id, gene_name\n",
    "HAVING COUNT(*) > 5\n",
    "ORDER BY variant_count DESC;\n",
    "\"\"\"\n",
    "\n",
    "df = pd.read_sql(query, get_connection())\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Warmup 20: Patients with failed QC runs\n",
    "query = \"\"\"\n",
    "SELECT \n",
    "    p.patient_id,\n",
    "    p.clinical_indication,\n",
    "    s.sample_id,\n",
    "    sr.run_id,\n",
    "    sr.contamination_pct,\n",
    "    sr.q30_bases_pct\n",
    "FROM patients p\n",
    "JOIN samples s ON p.patient_id = s.patient_id\n",
    "JOIN sequencing_runs sr ON s.sample_id = sr.sample_id\n",
    "WHERE sr.pass_qc = FALSE;\n",
    "\"\"\"\n",
    "\n",
    "df = pd.read_sql(query, get_connection())\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Date and Time Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Warmup 21: Runs by month\n",
    "query = \"\"\"\n",
    "SELECT \n",
    "    DATE_TRUNC('month', run_date) as month,\n",
    "    COUNT(*) as runs_count,\n",
    "    AVG(total_reads) as avg_reads\n",
    "FROM sequencing_runs\n",
    "GROUP BY month\n",
    "ORDER BY month;\n",
    "\"\"\"\n",
    "\n",
    "df = pd.read_sql(query, get_connection())\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Warmup 22: Time between sample collection and sequencing\n",
    "query = \"\"\"\n",
    "SELECT \n",
    "    s.sample_id,\n",
    "    s.collection_date,\n",
    "    sr.run_date,\n",
    "    sr.run_date - s.collection_date as days_to_sequencing\n",
    "FROM samples s\n",
    "JOIN sequencing_runs sr ON s.sample_id = sr.sample_id\n",
    "ORDER BY days_to_sequencing DESC;\n",
    "\"\"\"\n",
    "\n",
    "df = pd.read_sql(query, get_connection())\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Analytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Warmup 23: Variant distribution by type and significance\n",
    "query = \"\"\"\n",
    "SELECT \n",
    "    variant_type,\n",
    "    clinical_significance,\n",
    "    COUNT(*) as count,\n",
    "    AVG(quality_score) as avg_quality,\n",
    "    AVG(depth) as avg_depth\n",
    "FROM variant_calls\n",
    "GROUP BY variant_type, clinical_significance\n",
    "ORDER BY variant_type, count DESC;\n",
    "\"\"\"\n",
    "\n",
    "df = pd.read_sql(query, get_connection())\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Warmup 24: QC summary report per sample\n",
    "query = \"\"\"\n",
    "SELECT \n",
    "    sr.sample_id,\n",
    "    sr.sequencer,\n",
    "    sr.total_reads,\n",
    "    ROUND((sr.mapped_reads::NUMERIC / sr.total_reads * 100), 2) as mapping_pct,\n",
    "    ROUND((sr.duplicate_reads::NUMERIC / sr.mapped_reads * 100), 2) as duplicate_pct,\n",
    "    sr.mean_insert_size,\n",
    "    sr.q30_bases_pct,\n",
    "    sr.contamination_pct,\n",
    "    sr.pass_qc,\n",
    "    COUNT(vc.variant_id) as total_variants\n",
    "FROM sequencing_runs sr\n",
    "LEFT JOIN variant_calls vc ON sr.run_id = vc.run_id\n",
    "GROUP BY sr.run_id, sr.sample_id, sr.sequencer, sr.total_reads, \n",
    "         sr.mapped_reads, sr.duplicate_reads, sr.mean_insert_size,\n",
    "         sr.q30_bases_pct, sr.contamination_pct, sr.pass_qc\n",
    "ORDER BY sr.sample_id;\n",
    "\"\"\"\n",
    "\n",
    "df = pd.read_sql(query, get_connection())\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Warmup 25: Complete clinical report\n",
    "query = \"\"\"\n",
    "SELECT \n",
    "    p.patient_id,\n",
    "    p.age,\n",
    "    p.gender,\n",
    "    p.clinical_indication,\n",
    "    s.sample_type,\n",
    "    sr.sequencer,\n",
    "    sr.pass_qc,\n",
    "    COUNT(DISTINCT CASE WHEN vc.clinical_significance IN ('Pathogenic', 'Likely pathogenic') \n",
    "                        THEN vc.gene_name END) as pathogenic_genes,\n",
    "    COUNT(DISTINCT CASE WHEN vc.clinical_significance = 'VUS' \n",
    "                        THEN vc.gene_name END) as vus_genes\n",
    "FROM patients p\n",
    "JOIN samples s ON p.patient_id = s.patient_id\n",
    "JOIN sequencing_runs sr ON s.sample_id = sr.sample_id\n",
    "LEFT JOIN variant_calls vc ON sr.run_id = vc.run_id\n",
    "GROUP BY p.patient_id, p.age, p.gender, p.clinical_indication, \n",
    "         s.sample_type, sr.sequencer, sr.pass_qc\n",
    "ORDER BY p.patient_id;\n",
    "\"\"\"\n",
    "\n",
    "df = pd.read_sql(query, get_connection())\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Data Visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization 1: QC Pass Rate by Sequencer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT \n",
    "    sequencer,\n",
    "    SUM(CASE WHEN pass_qc THEN 1 ELSE 0 END)::FLOAT / COUNT(*) * 100 as pass_rate,\n",
    "    COUNT(*) as total_runs\n",
    "FROM sequencing_runs\n",
    "GROUP BY sequencer;\n",
    "\"\"\"\n",
    "\n",
    "df = pd.read_sql(query, get_connection())\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Bar plot of pass rates\n",
    "colors = sns.color_palette('Set2', n_colors=len(df))\n",
    "ax1.bar(df['sequencer'], df['pass_rate'], color=colors)\n",
    "ax1.set_ylabel('QC Pass Rate (%)', fontsize=12)\n",
    "ax1.set_xlabel('Sequencer', fontsize=12)\n",
    "ax1.set_title('QC Pass Rate by Sequencer Platform', fontsize=14, fontweight='bold')\n",
    "ax1.set_ylim([0, 105])\n",
    "for i, v in enumerate(df['pass_rate']):\n",
    "    ax1.text(i, v + 2, f'{v:.1f}%', ha='center', fontweight='bold')\n",
    "\n",
    "# Pie chart of total runs\n",
    "ax2.pie(df['total_runs'], labels=df['sequencer'], autopct='%1.0f%%', \n",
    "        colors=colors, startangle=90)\n",
    "ax2.set_title('Distribution of Sequencing Runs', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization 2: Read Depth Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT total_reads, sequencer, pass_qc\n",
    "FROM sequencing_runs;\n",
    "\"\"\"\n",
    "\n",
    "df = pd.read_sql(query, get_connection())\n",
    "df['total_reads_millions'] = df['total_reads'] / 1_000_000\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "# Box plot by sequencer\n",
    "sns.boxplot(data=df, x='sequencer', y='total_reads_millions', \n",
    "            hue='pass_qc', palette='Set1', ax=ax)\n",
    "ax.set_ylabel('Total Reads (Millions)', fontsize=12)\n",
    "ax.set_xlabel('Sequencer Platform', fontsize=12)\n",
    "ax.set_title('Read Depth Distribution by Sequencer and QC Status', \n",
    "             fontsize=14, fontweight='bold')\n",
    "ax.legend(title='Passed QC', loc='upper right')\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization 3: Coverage Uniformity Across Chromosomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT \n",
    "    chromosome,\n",
    "    AVG(mean_coverage) as avg_coverage,\n",
    "    AVG(uniformity) as avg_uniformity\n",
    "FROM coverage_metrics\n",
    "WHERE chromosome ~ '^[0-9]+$'\n",
    "GROUP BY chromosome\n",
    "ORDER BY chromosome::INTEGER;\n",
    "\"\"\"\n",
    "\n",
    "df = pd.read_sql(query, get_connection())\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 10))\n",
    "\n",
    "# Coverage by chromosome\n",
    "ax1.plot(df['chromosome'], df['avg_coverage'], marker='o', linewidth=2, \n",
    "         markersize=8, color='#2E86AB')\n",
    "ax1.fill_between(range(len(df)), df['avg_coverage'], alpha=0.3, color='#2E86AB')\n",
    "ax1.set_ylabel('Average Coverage', fontsize=12)\n",
    "ax1.set_xlabel('Chromosome', fontsize=12)\n",
    "ax1.set_title('Mean Coverage Distribution Across Chromosomes', \n",
    "              fontsize=14, fontweight='bold')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Uniformity by chromosome\n",
    "ax2.bar(df['chromosome'], df['avg_uniformity'], color='#A23B72', alpha=0.7)\n",
    "ax2.set_ylabel('Uniformity (%)', fontsize=12)\n",
    "ax2.set_xlabel('Chromosome', fontsize=12)\n",
    "ax2.set_title('Coverage Uniformity Across Chromosomes', \n",
    "              fontsize=14, fontweight='bold')\n",
    "ax2.axhline(y=85, color='red', linestyle='--', label='Target (85%)')\n",
    "ax2.legend()\n",
    "ax2.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization 4: Variant Classification Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT \n",
    "    clinical_significance,\n",
    "    variant_type,\n",
    "    COUNT(*) as count\n",
    "FROM variant_calls\n",
    "GROUP BY clinical_significance, variant_type;\n",
    "\"\"\"\n",
    "\n",
    "df = pd.read_sql(query, get_connection())\n",
    "pivot_df = df.pivot(index='clinical_significance', columns='variant_type', values='count').fillna(0)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "pivot_df.plot(kind='bar', stacked=True, ax=ax, \n",
    "              color=['#E63946', '#F1FA8C', '#A8DADC'])\n",
    "ax.set_ylabel('Variant Count', fontsize=12)\n",
    "ax.set_xlabel('Clinical Significance', fontsize=12)\n",
    "ax.set_title('Variant Distribution by Clinical Significance and Type', \n",
    "             fontsize=14, fontweight='bold')\n",
    "ax.legend(title='Variant Type', loc='upper right')\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=45, ha='right')\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization 5: QC Metrics Correlation Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT \n",
    "    total_reads,\n",
    "    mapped_reads::FLOAT / total_reads * 100 as mapping_pct,\n",
    "    duplicate_reads::FLOAT / mapped_reads * 100 as duplicate_pct,\n",
    "    q30_bases_pct,\n",
    "    contamination_pct,\n",
    "    mean_insert_size\n",
    "FROM sequencing_runs;\n",
    "\"\"\"\n",
    "\n",
    "df = pd.read_sql(query, get_connection())\n",
    "correlation = df.corr()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "sns.heatmap(correlation, annot=True, fmt='.2f', cmap='coolwarm', \n",
    "            center=0, square=True, linewidths=1, ax=ax,\n",
    "            cbar_kws={'label': 'Correlation Coefficient'})\n",
    "ax.set_title('QC Metrics Correlation Matrix', fontsize=14, fontweight='bold', pad=20)\n",
    "\n",
    "# Adjust labels\n",
    "labels = ['Total Reads', 'Mapping %', 'Duplicate %', 'Q30 %', 'Contamination %', 'Insert Size']\n",
    "ax.set_xticklabels(labels, rotation=45, ha='right')\n",
    "ax.set_yticklabels(labels, rotation=0)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization 6: Pathogenic Variants by Gene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT \n",
    "    gene_name,\n",
    "    COUNT(*) as pathogenic_count,\n",
    "    AVG(allele_frequency) as avg_af,\n",
    "    AVG(quality_score) as avg_qual\n",
    "FROM variant_calls\n",
    "WHERE clinical_significance IN ('Pathogenic', 'Likely pathogenic')\n",
    "GROUP BY gene_name\n",
    "ORDER BY pathogenic_count DESC;\n",
    "\"\"\"\n",
    "\n",
    "df = pd.read_sql(query, get_connection())\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Bar chart of pathogenic variant counts\n",
    "colors = plt.cm.Reds(np.linspace(0.4, 0.9, len(df)))\n",
    "ax1.barh(df['gene_name'], df['pathogenic_count'], color=colors)\n",
    "ax1.set_xlabel('Number of Pathogenic/Likely Pathogenic Variants', fontsize=12)\n",
    "ax1.set_ylabel('Gene', fontsize=12)\n",
    "ax1.set_title('Pathogenic Variant Burden by Gene', fontsize=14, fontweight='bold')\n",
    "ax1.grid(axis='x', alpha=0.3)\n",
    "\n",
    "# Scatter plot of AF vs Quality\n",
    "scatter = ax2.scatter(df['avg_af'], df['avg_qual'], s=df['pathogenic_count']*20,\n",
    "                     c=df['pathogenic_count'], cmap='Reds', alpha=0.6, edgecolors='black')\n",
    "ax2.set_xlabel('Average Allele Frequency', fontsize=12)\n",
    "ax2.set_ylabel('Average Quality Score', fontsize=12)\n",
    "ax2.set_title('Pathogenic Variant Quality Metrics', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Add gene labels\n",
    "for idx, row in df.iterrows():\n",
    "    ax2.annotate(row['gene_name'], (row['avg_af'], row['avg_qual']), \n",
    "                fontsize=9, alpha=0.7)\n",
    "\n",
    "plt.colorbar(scatter, ax=ax2, label='Variant Count')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization 7: Sample Processing Timeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT \n",
    "    s.sample_id,\n",
    "    s.collection_date,\n",
    "    sr.run_date,\n",
    "    sr.run_date - s.collection_date as turnaround_time,\n",
    "    sr.pass_qc\n",
    "FROM samples s\n",
    "JOIN sequencing_runs sr ON s.sample_id = sr.sample_id\n",
    "ORDER BY s.collection_date;\n",
    "\"\"\"\n",
    "\n",
    "df = pd.read_sql(query, get_connection())\n",
    "df['turnaround_days'] = df['turnaround_time'].dt.days\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 10))\n",
    "\n",
    "# Timeline plot\n",
    "colors = ['green' if qc else 'red' for qc in df['pass_qc']]\n",
    "ax1.scatter(df['collection_date'], df['turnaround_days'], \n",
    "           s=100, c=colors, alpha=0.6, edgecolors='black')\n",
    "ax1.set_ylabel('Turnaround Time (days)', fontsize=12)\n",
    "ax1.set_xlabel('Collection Date', fontsize=12)\n",
    "ax1.set_title('Sample Processing Turnaround Times', fontsize=14, fontweight='bold')\n",
    "ax1.axhline(y=df['turnaround_days'].mean(), color='blue', linestyle='--', \n",
    "           label=f\"Mean: {df['turnaround_days'].mean():.1f} days\")\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Distribution histogram\n",
    "ax2.hist(df['turnaround_days'], bins=15, color='#457B9D', alpha=0.7, edgecolor='black')\n",
    "ax2.axvline(df['turnaround_days'].median(), color='red', linestyle='--', linewidth=2,\n",
    "           label=f\"Median: {df['turnaround_days'].median():.0f} days\")\n",
    "ax2.set_xlabel('Turnaround Time (days)', fontsize=12)\n",
    "ax2.set_ylabel('Frequency', fontsize=12)\n",
    "ax2.set_title('Distribution of Processing Turnaround Times', fontsize=14, fontweight='bold')\n",
    "ax2.legend()\n",
    "ax2.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nTurnaround Time Statistics:\")\n",
    "print(f\"  Mean: {df['turnaround_days'].mean():.1f} days\")\n",
    "print(f\"  Median: {df['turnaround_days'].median():.0f} days\")\n",
    "print(f\"  Range: {df['turnaround_days'].min()}-{df['turnaround_days'].max()} days\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary\n",
    "\n",
    "You've completed 25 SQL warmup exercises covering:\n",
    "- Basic SELECT queries\n",
    "- WHERE clause filtering\n",
    "- Aggregation functions (COUNT, AVG, MIN, MAX)\n",
    "- GROUP BY operations\n",
    "- JOIN operations (2-table and 3-table joins)\n",
    "- Calculated fields\n",
    "- Subqueries\n",
    "- HAVING clause\n",
    "- Date/time operations\n",
    "- Complex multi-table analytics\n",
    "\n",
    "Plus 7 visualizations showing:\n",
    "1. QC pass rates by sequencer\n",
    "2. Read depth distributions\n",
    "3. Coverage uniformity across chromosomes\n",
    "4. Variant classification distributions\n",
    "5. QC metrics correlations\n",
    "6. Pathogenic variants by gene\n",
    "7. Sample processing timelines\n",
    "\n",
    "### Next Steps:\n",
    "- Practice modifying these queries\n",
    "- Try combining concepts from multiple exercises\n",
    "- Create your own queries to explore the data\n",
    "- Build custom visualizations\n",
    "- Connect this to real sequencing data pipelines!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
